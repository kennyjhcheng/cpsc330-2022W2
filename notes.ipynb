{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - Intro, what is supervised machine learning\n",
    "\n",
    "- **explain the motivation to study machine learning**\n",
    "    - Machine learning exists in many of the applications we use today\n",
    "    - ML is a software that figures out rules through models trained with data\n",
    "- **explain supervised machine learning**\n",
    "    - Training model from input data + corresponding targets (labels)\n",
    "    - observations $X$ + targets $y$, finds model function $f$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **02 - Terminology, Baselines, Decision Trees**\n",
    "\n",
    "**Definitions**\n",
    "\n",
    "- **identify whether a given problem could be solved using supervised machine learning or not**\n",
    "    - if we can separate $X$ and $y$, features and targets\n",
    "- **differentiate between supervised and unsupervised machine learning**\n",
    "    \n",
    "    \n",
    "    | Supervised | Unsupervised |\n",
    "    | --- | --- |\n",
    "    | training data: features ($X$), targets ($y$)  | training data: observations $X$, no targets |\n",
    "    | finds model function $f$ relating $X, y$ | used to\n",
    "    * group similar clusters\n",
    "    * summarize data\n",
    "    * learn patterns\n",
    "    * learn association rules |\n",
    "    | use $f$ to predict new examples |  |\n",
    "- **explain machine learning terminology such as features, targets, predictions, training, and error**\n",
    "    - ******************features:****************** relevant characteristics of problem.\n",
    "    - **************target:************** feature we want to predict\n",
    "    - **********************prediction:********************** output of algorithm that has learned a mapping to forecast target (or likelihood of target)\n",
    "    - ******************training:****************** process of learning mapping between features and targets ($X$ and $y$)\n",
    "    - **************sample:************** row of feature values\n",
    "    - ************error:************ used to evaluate machine learning models, identifies proportion of inaccurate predictions\n",
    "- **explain the difference between parameters and hyperparameters**\n",
    "    - **********************Parameters:********************** learned by algorithm during training (`fit`), used to predict\n",
    "    - ********************************Hyperparameters:******************************** “knobs” that control learning prior to training, specified by expert, heuristic, or optimization\n",
    "- **differentiate between classification and regression problems**\n",
    "    \n",
    "    \n",
    "    | Classification | Regression |\n",
    "    | --- | --- |\n",
    "    | predict among 2+ discrete classes | predict continuous value |\n",
    "    | e.g. whether patient has disease\n",
    "    e.g. whether student gets A+ | e.g. predict housing prices\n",
    "    e.g. predict student’s score |\n",
    "\n",
    "**ML Models**\n",
    "\n",
    "- **explain the `fit` and `predict` paradigm and use `score` method of ML models**\n",
    "    - `fit` : trains model using training features & targets\n",
    "    - `predict` : maps a feature to a corresponding target by patterns identified when model was trained\n",
    "    - `score` : evaluates how well model is doing (default is $accuracy=\\frac{\\#correct}{\\#total}$)\n",
    "\n",
    "**Decision Trees**\n",
    "\n",
    "- **describe how decision tree prediction works**\n",
    "    - Starts at top of decision tree asking binary question at each node\n",
    "    - follows path of tree until leaf node\n",
    "    - `fit` by minimizing impurity (e.g. **************************gini impurity**************************)\n",
    "        - $Gini(D)=1-\\sum_{i=1}^Cp_i^2$\n",
    "            - i.e. $1-$ sum of all probabilities for each class squared\n",
    "- **use `DecisionTreeClassifier` and `DecisionTreeRegressor` to build decision trees using `scikit-learn`**\n",
    "    \n",
    "    ```python\n",
    "    model = DecisionTreeClassifier() # Create decision tree\n",
    "    model.fit(X, y) # Fit decision tree\n",
    "    model.score(X, y) # Assess model\n",
    "    \n",
    "    # predict against new examples\n",
    "    new_example = np.array([[0, 1, 0, 0, 1, 1, 1]])\n",
    "    pd.DataFrame(data=new_exmple, columns=X.columns)\n",
    "    model.predict(new_example)\n",
    "    ```\n",
    "    \n",
    "    ```python\n",
    "    reg_model = DecisionTreeRegressor(max_depth=depth)\n",
    "    reg_model.fit(X, y)\n",
    "    reg_model.predict(X)\n",
    "    reg_model.score(X, y)\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - Machine Learning Fundamentals\n",
    "\n",
    "**Decision Boundaries:**\n",
    "\n",
    "- **Learn about Decision Boundaries**\n",
    "- **explain the concept of decision boundaries**\n",
    "    - Decision boundaries represent the geometric separation between classifications of data\n",
    "- **explain the relation between model complexity and decision boundaries.**\n",
    "    - The more complex the model, the more complex the decision boundary separates data\n",
    "- **explain how decision boundaries change with the `max_depth` hyperparameter**\n",
    "    - increasing `max_depth` increases complexity, the decision boundary becomes more accurate in separating classes\n",
    "\n",
    "**Generalizability:**\n",
    "\n",
    "- **explain the concept of generalization**\n",
    "    - Learn from past data that we have seen and apply it to data we have NOT seen\n",
    "        - generalize beyond training examples\n",
    "    - fundamental goal of ML\n",
    "- **appropriately split a dataset into train and test sets using `train_test_split` function**\n",
    "    \n",
    "    ```python\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=123,\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "- **explain the difference between train, validation, test, and \"deployment\" data**\n",
    "    - ************Train data:************ used to train the model and learn patterns, mapping function\n",
    "    - ********************************Validation data:******************************** used for hyperparameter tuning, choosing the best model, assert that model is correctly training\n",
    "    - ********************Test data:******************** used once to evaluate performance of the best performing model\n",
    "    - ********************************Deployment data:******************************** finalized model deployed to deal with data in wild, without access to target values\n",
    "        - assume that all data sampled from same distribution so that model generalizes to deployment data\n",
    "- **identify the difference between training error, validation error, and test error;**\n",
    "    - $E_{train}<E_{validation}\\leq E_{test}<E_{deployment}$\n",
    "- **explain cross-validation and use `cross_val_score` and `cross_validate` to calculate cross-validation error;**\n",
    "    - **********************************cross-validation:********************************** split data into $k$ folds, each with a chance to be validation set\n",
    "        - returns $k$ scores, average to find ********************************validation score********************************\n",
    "        - examining variation between fold scores measures error on unseen data\n",
    "        \n",
    "        ```python\n",
    "        # cross_val_score -> only access to validation scores\n",
    "        model = DecisionTreeClassifier(max_depth=4)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "        \n",
    "        # cross_validate -> validation + training scores, time to train\n",
    "        scores = cross_validate(mode, X_train, y_train, cv=10, return_train_score=True)\n",
    "        ```\n",
    "        \n",
    "\n",
    "**Overfitting:**\n",
    "\n",
    "- **recognize overfitting and/or underfitting by looking at train and test scores;**\n",
    "    - **************************Underfitting:************************** model too simple, not capturing useful patterns\n",
    "        - high train + validation error, low train + validation accuracy\n",
    "        - small gap between train and validation error\n",
    "        - $E_{best}<E_{train}<\\sim E_{valid}$\n",
    "    - ****************************Overfitting:**************************** model overcomplex, learned unreliable patterns just to get training examples correct\n",
    "        - low training error, high training accuracy\n",
    "        - big gap between training and validation error\n",
    "        - $E_{train}<E_{best}<E_{valid}$\n",
    "- **explain why it is generally not possible to get a perfect test score (zero test error) on a supervised learning problem;**\n",
    "- **describe the fundamental tradeoff between training score and the train-test gap (bias/variance tradeoff)**\n",
    "    - **********Bias:********** tendency in consistently making same mistake (underfitting)\n",
    "    - ******************Variance:****************** tendency to learn noise in data, irrespective of real signal (overfitting)\n",
    "    - ********************Tradeoff →******************** Model with very high training accuracy, likely has lower validation accuracy\n",
    "        - Common to balance tradeoff between bias-variance by minimizing cross-validation error\n",
    "- **state the golden rule**\n",
    "    - TEST DATA CANNOT influence TRAINING + MODELING PHASE\n",
    "\n",
    "**Standard recipe for supervised learning:**\n",
    "\n",
    "- **train/test split**\n",
    "    - split data to `X, y` → `X_train`, `X_test`, `y_train`, `y_test` with `train_test_split`\n",
    "- **hyperparameter tuning with cross-validation on validation data**\n",
    "    - cross-validation to select best hyperparameters\n",
    "- **test on test set.**\n",
    "    - score with test set to examine generalization performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 - kNN + SVM RBF\n",
    "\n",
    "- **explain the notion of similarity-based algorithms**\n",
    "    - Intuitive way to classify examples\n",
    "    - Find most “similar” example from training set, use label for test example\n",
    "- **broadly describe how kNN use distances**\n",
    "    - Given data point predict class → find **************closest************** data point (************************************similarity metric************************************)\n",
    "        - or majority vote of closest $k$ neighbors\n",
    "        - Euclidena distance: $distance(u,v)=\\sqrt{\\sum_{i=1}^n(u_i-v_i)^2}$\n",
    "- **discuss the effect of using a small/large value of the hyperparameter $k$ when using the $k$-NN algorithm**\n",
    "    - Small $k$ → considers fewer nearby points, overfits\n",
    "    - Large $k$ → considers many points, underfits\n",
    "    - Increasing $k$ increases validation accuracy until certain level before dropping\n",
    "    - tune with hyperparameter optimization\n",
    "- **describe the problem of curse of dimensionality**\n",
    "    - when more features HARM rather than help\n",
    "        - especially for similarity-based models\n",
    "    - $k$-NN works well when # dimensions $d$ is small\n",
    "        - $k$-NN cannot ignore features → irrelvant attributes can confuse them when finding similarity\n",
    "- **explain the general idea of SVMs and RBF kernel**\n",
    "    - ******************************Support Vector:****************************** samples on boundaries determing the **********************************margin hyperplane**********************************\n",
    "    - **********************Linear HARD SVM:********************** No misclassifications happen\n",
    "    - **Linear SOFT SVM:** misclassifications can happen, each will be penalized relative to `C`\n",
    "    - Similarity-based algorithm SVM with RBF kernel\n",
    "        - like weighted $k$NN → decision boundary defined by weighted similarity of positive and negative examples\n",
    "        - only remembers key examples (******************************support vectors******************************)\n",
    "        - similarity metric = Radial Basis Functions (RBF) kernel\n",
    "        - perform better than $k$NN\n",
    "- **broadly describe the relation of `gamma` and `C` hyperparameters of SVMs with the fundamental tradeoff.**\n",
    "    - `gamma` - controls complexity\n",
    "        - larger → more complex\n",
    "        - smaller → less complex\n",
    "    - `C` - affects fundamental tradeoff\n",
    "        - larger → more complex\n",
    "        - smaller → less complex\n",
    "- **********************************************************************Parametric vs Non-parametric models**********************************************************************\n",
    "    - **********************************Parametric Model:********************************** learns finite number of learnable parameters during training\n",
    "        - add more data → point where data doesn’t help (under/over fitting)\n",
    "        - e.g. DecisionTrees\n",
    "    - ****************************************Non-parametric Model:**************************************** number of parameters can be potentially infinite\n",
    "        - e.g. $k$-NN, model increases with size of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 - SVM, Preprocessing, `sklearn` pipelines\n",
    "\n",
    "- **have another glimpse at SVM**\n",
    "    - SVM for classification is ******SVC******\n",
    "    - SVM for regression is ******SVR******\n",
    "    - decision boundary → like “smooth $k$NN”\n",
    "    - `fit` determines support vectors, which determine decision boundary\n",
    "    - `gamma`: RBF hyperparameter, how far influence of single train example reaches\n",
    "        - large `gamma` → close/nearby influence, **************complex**************\n",
    "        - small `gamma` → far away influence, ************************less complex************************\n",
    "    - `C`: SVM hyperparameter, ********************************regularization********************************\n",
    "        - tradeoff: correct train classification vs max of decision margin\n",
    "        - Large `C` → less regularization (**complex** model)\n",
    "        - Simple `C` → more regularization (**simpler** function/model)\n",
    "- **explain motivation for preprocessing in supervised machine learning**\n",
    "    - models can be sensitive to scale of features (e.g. $k$NN for calculating distance)\n",
    "- **identify when to implement feature transformations such as imputation, scaling, and one-hot encoding in a machine learning model development pipeline;**\n",
    "    - ****************Scaling:**************** for numeric features, normalizes scale.\n",
    "        - standardization: `mean = 0` and `std = 1`\n",
    "    - **********************Imputation:********************** replace missing values with substitute\n",
    "    - **********************************One-hot encoding:********************************** numerical vectorization for categorical variables\n",
    "- **use `sklearn` transformers for applying feature transformations on your dataset**\n",
    "    \n",
    "    ```python\n",
    "    scaler = StandardScaler()  # create feature trasformer object\n",
    "    scaler.fit(X_train)  # fitting the transformer on the train split\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train)  # transforming the train split\n",
    "    X_test_scaled = scaler.transform(X_test)  # transforming the test split\n",
    "    ```\n",
    "    \n",
    "    ```python\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(X_train)\n",
    "    \n",
    "    X_train_imp = imputer.transform(X_train)\n",
    "    X_test_imp = imputer.transform(X_test)\n",
    "    ```\n",
    "    \n",
    "    ```python\n",
    "    enc = OrdinalEncoder()\n",
    "    enc.fit(X_toy)\n",
    "    X_toy_ord= enc.transform(X_toy)\n",
    "    ```\n",
    "    \n",
    "    ```python\n",
    "    class_attendance_levels = [\"Poor\", \"Average\", \"Good\", \"Excellent\"]\n",
    "    oe = OrdinalEncoder(categories=[class_attendance_levels], dtype=int)\n",
    "    oe.fit(X_toy[[\"class_attendance\"]])\n",
    "    ca_transformed = oe.transform(X_toy[[\"class_attendance\"]])\n",
    "    ```\n",
    "    \n",
    "- **discuss golden rule in the context of feature transformations**\n",
    "    - best to transform data after splitting to avoid breaking golden rule\n",
    "    - Do not `fit` transformers with test data\n",
    "        - `transform` train and test data with the same transform object for consistent transformation\n",
    "    - need `pipeline` to do transformation + cross  validation\n",
    "        - same preprocessing steps to both train/validation so validation set doesn’t leak into training\n",
    "- **use `sklearn.pipeline.Pipeline` and `sklearn.pipeline.make_pipeline` to build a preliminary machine learning pipeline.**\n",
    "    \n",
    "    ```python\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"regressor\", KNeighborsRegressor()),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipe = make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"), \n",
    "        StandardScaler(), \n",
    "        KNeighborsRegressor()\n",
    "    )\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.predict(X_train)\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - ColumnTransformer and Text features\n",
    "\n",
    "- **use `ColumnTransformer` to build all our transformations together into one object and use it with `sklearn` pipelines**\n",
    "    \n",
    "    ```python\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"MyScaling\", StandardScaler(), numeric_feats),\n",
    "            (\"MyOnehot\", OneHotEncoder(sparse=False), categorical_feats),\n",
    "            (\"MyPassthrough\", \"passthrough\", passthrough_feats),\n",
    "            # (\"MyDrop\", \"drop\", drop_feats), # not neeeded, drop is the default behaviour\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ct = make_column_transformer(    \n",
    "        (StandardScaler(), numeric_feats),  # scaling on numeric features\n",
    "        (\"passthrough\", passthrough_feats),  # no transformations on the binary features    \n",
    "        (OneHotEncoder(), categorical_feats),  # OHE on categorical features\n",
    "        # (\"drop\", drop_feats),   # not neeeded, drop is the default behaviour\n",
    "    )\n",
    "    column_names = (\n",
    "        numeric_feats\n",
    "        + passthrough_feats    \n",
    "        + ct.named_transformers_[\"onehotencoder\"].get_feature_names_out().tolist()\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "    ```python\n",
    "    # Same as before, just passing ColumnTransformer (ct) to pipeline\n",
    "    pipe = make_pipeline(ct, SVC())\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    # I don't care about results on train data; this is toy problem\n",
    "    pipe.predict(X)\n",
    "    ```\n",
    "    \n",
    "- **define `ColumnTransformer` where transformers contain more than one steps**\n",
    "    \n",
    "    ```python\n",
    "    ct = make_column_transformer(\n",
    "      # ---------- important -------------------\n",
    "        (      \n",
    "            make_pipeline(SimpleImputer(), StandardScaler()),\n",
    "            numeric_feats,\n",
    "        ),\n",
    "        # -------------------------------------------\n",
    "        (\"passthrough\", passthrough_feats),  # no transformations on the binary features    \n",
    "        (OneHotEncoder(), categorical_feats),  # OHE on categorical features\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "- **explain `handle_unknown=\"ignore\"` hyperparameter of `scikit-learn`'s `OneHotEncoder`**\n",
    "    - if there is only one instance of a class, it could appear in a cross_validation fold’s validation split but not training split, use `handle_unknown=\"ignore\"` to create row of zeros\n",
    "    - learning about all possible categories doesn’t break golden rule\n",
    "        - expect train and test data originate from same distribution\n",
    "- **explain `drop=\"if_binary\"` argument of `OneHotEncoder`**\n",
    "    - For categorical variables that are binary (have only two labels), use `drop=\"if_binary` to create one column (1’s + 0’s) instead of two columns.\n",
    "- **identify when it's appropriate to apply ordinal encoding vs one-hot encoding**\n",
    "    - Apply ordinal encoding when we know an order to the classification labels\n",
    "    - Apply one hot encoding when labels are unordered\n",
    "- **explain strategies to deal with categorical variables with too many categories**\n",
    "    - Are rare categories meaningful?\n",
    "    - Group categories into bigger categories\n",
    "    - create “other” category for rare cases\n",
    "\n",
    "**Text Data:**\n",
    "\n",
    "- **explain why text data needs a different treatment than categorical variables**\n",
    "    - If we encoded text data using OHE, we would have as many columns as there are unique texts\n",
    "        - doesn’t help us identify patterns since each text will likely be unique\n",
    "- **use `scikit-learn`'s `CountVectorizer` to encode text data**\n",
    "    \n",
    "    ```python\n",
    "    vec = CountVectorizer()\n",
    "    X_counts = vec.fit_transform(toy_df[\"sms\"])\n",
    "    ```\n",
    "    \n",
    "- **explain different hyperparameters of `CountVectorizer`.**\n",
    "    - `binary` : whether to use absence/presence feature values or counts\n",
    "        - i.e. all non zero counts set to 1, else 0 → useful for probabilistic models with binary events rather than integer count\n",
    "    - `max_features` : only consider top `max_features` features ordered by frequency\n",
    "    - `max_df`: ignore features which occur in more than `max_df` documents\n",
    "    - `min_df`: ignore features which occur in less than `min_df` documents\n",
    "    - `ngram_range` : consider word sequences in given range\n",
    "- **incorporate text features in a machine learning pipeline**\n",
    "    \n",
    "    ```python\n",
    "    pipe = make_pipeline(CountVectorizer(), SVC())\n",
    "    pipe.fit(toy_df[\"sms\"], toy_df[\"target\"])\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 - Linear Models\n",
    "\n",
    "- **Explain the general intuition behind linear models**\n",
    "    - Make prediction using ******************************linear function****************************** of input features\n",
    "- **Explain how `predict` works for linear regression;=**\n",
    "    - Prediction is weighted sum of input features + bias\n",
    "- **Use `scikit-learn`'s `Ridge` model**\n",
    "    - `Ridge` : L2 regularization Linear Regression model\n",
    "    - hyperparameters `alpha` controls regularization\n",
    "    \n",
    "    ```python\n",
    "    pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "    scores = cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    "    ```\n",
    "    \n",
    "- **Demonstrate how the `alpha` hyperparameter of `Ridge` is related to the fundamental tradeoff**\n",
    "    - large `alpha` → more regularization (******************underfit******************)\n",
    "        - → more bias\n",
    "        - → less variance\n",
    "        - → less complex\n",
    "        - → lower chance of overfitting\n",
    "    - small `alpha` → less regularization (**************overfit**************)\n",
    "- **Explain the difference between linear regression and logistic regression**\n",
    "    - ****************************************Logistic Regression:**************************************** linear model for classification\n",
    "        - also learns weight per feature + bias\n",
    "        - ******************threshold****************** on output to decide class label\n",
    "        - hyperparameter `C` → regularization coefficient (inverse of regularization strength)\n",
    "            - large `C` overfits\n",
    "            - small `C` underfits\n",
    "    - ************************************Linear regression:************************************ linear model for regression problems\n",
    "        - learns weight per feature + bias\n",
    "        - output weighted sum of input features and bias\n",
    "        - hyperparameters `alpha`\n",
    "- **Use `scikit-learn`'s `LogisticRegression` model and `predict_proba` to get probability scores**\n",
    "    \n",
    "    ```python\n",
    "    lr = LogisticRegression(random_state=123)\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr.predict([example])  # hard prediction\n",
    "    lr.predict_proba([example])  # soft prediction\n",
    "    lr.classes_\n",
    "    ```\n",
    "    \n",
    "- **Explain the advantages of getting probability scores instead of hard predictions during classification**\n",
    "    - Hard predictions only give the class\n",
    "    - Probability score tells us how confident model is with prediction\n",
    "        - useful in understanding the model\n",
    "        - Understanding\n",
    "            - overfitting → extremely confident but wrong\n",
    "            - underfitting → not very confident, more uncertain\n",
    "- **Broadly describe linear SVMs**\n",
    "    - pass `kernel=\"linear\"` to `SVC` which is normally non-linear using RBF kernels\n",
    "    - Creates linear decision boundary formed from support vectors\n",
    "        - determines weights and intercept\n",
    "- **Explain how can you interpret model predictions using coefficients learned by a linear model**\n",
    "    - Magnitude and sign of learned coefficients\n",
    "        - tell us what features drive prediction\n",
    "- **Explain the advantages and limitations of linear classifiers.**\n",
    "    - Strengths\n",
    "        - fast to train + predict\n",
    "        - scales well with data, works with sparse data\n",
    "        - easy to understand and interpret\n",
    "        - performs relatively well with large number of features\n",
    "    - Limitations\n",
    "        - only works well for linearly separable data\n",
    "            - can be separated by linear decision rule\n",
    "        - fail if data is complex and not linear separable\n",
    "            - no linear relationship between feature + target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08 - Hyperparameter Optimization & Optimization Bias\n",
    "\n",
    "- **explain the need for hyperparameter optimization**\n",
    "    - to improve generalization → find best values for hyperparameters\n",
    "        - prevent underfit/overfit model\n",
    "- **carry out hyperparameter optimization using `sklearn`'s `GridSearchCV` and `RandomizedSearchCV`**\n",
    "    \n",
    "    ```python\n",
    "    pipe_svm = make_pipeline(StandardScaler(), SVC())\n",
    "    \n",
    "    # ---------- ATTENTION TO __ -----------\n",
    "    param_grid = {\n",
    "        \"svc__gamma\": [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "        \"svc__C\": [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "    }\n",
    "    # --------------------------------------\n",
    "    \n",
    "    # ---------- NEW CODE -----------\n",
    "    grid_search = GridSearchCV(\n",
    "        pipe_svm, param_grid, cv=5, n_jobs=-1, return_train_score=True\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train) # all the work is done here\n",
    "    grid_search.score(X_test, y_test)\n",
    "    # ------------------------------\n",
    "    \n",
    "    grid_search.best_score_\n",
    "    grid_search.best_params_\n",
    "    grid_search.cv_results_\n",
    "    ```\n",
    "    \n",
    "    ```python\n",
    "    param_grid = {\n",
    "        \"svc__gamma\": [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "        \"svc__C\": np.linspace(2, 3, 6),\n",
    "    }\n",
    "    \n",
    "    # ---------- New Code ----------------\n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipe_svm, param_distributions=param_grid, n_jobs=-1, n_iter=20, cv=5, random_state=42\n",
    "    )\n",
    "    random_search.fit(X_train, y_train);\n",
    "    # ---------- New Code ----------------\n",
    "    ```\n",
    "    \n",
    "- **explain different hyperparameters of `GridSearchCV`**\n",
    "    - `n_jobs` : hyperparameter optimization can be done in parallel using multi-cores of CPU\n",
    "        - useful when scaling in cloud\n",
    "    - `__` syntax\n",
    "        - access parameters of “inner” objects of our pipelines\n",
    "- **explain different hyperparameters of `RandomSearchCV`**\n",
    "    - `n_iter` : number of searches done\n",
    "    - `random_state` : reproducibility\n",
    "    - Setting distribution of hyperparameters\n",
    "        - `uniform`, `norm`, `expon`, `loguniform`\n",
    "- **explain the importance of selecting a good range for the values.**\n",
    "    - hyperparameter range matters based on hyperparameter sensitivity\n",
    "    - for certain hyperparametrs, values need to be logarithmic otherwise slight changes make little to no difference.\n",
    "- **explain optimization bias**\n",
    "    - ************************************Optimization bias:************************************ overfitting validation set if it’s hit too many times\n",
    "    - Overfitting training\n",
    "        - e.g. training by searching over many different decision trees → find low training error by chance\n",
    "    - Overfitting validation\n",
    "        - e.g. optimize validation error over 1000 `max_depth`, one of trees may have low validation error by chance\n",
    "- **identify and reason when to trust and not trust reported accuracies**\n",
    "    - Trust if:\n",
    "        - model tuned with validation set\n",
    "        - validation set is a large enough proportion → not being hit too many times\n",
    "        - model evaluated with test set\n",
    "        - Large amount of data to train → closer to actual distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09 - Classification Metrics\n",
    "\n",
    "- **Explain why accuracy is not always the best metric in ML.**\n",
    "    - For example, when there is a class imbalance (significantly more of one class than others), accuracy favors predictions of that class more.\n",
    "        - Dummy model may have very good accuracy\n",
    "- **Explain components of a confusion matrix.**\n",
    "    - Confusion matrix contains types of errors\n",
    "        - ****************************Type I errors (FP):**************************** model incorrectly spots example as positive classification\n",
    "        - **************************************Type II error (FN):************************************** model misses spotting a positive example (spots it negative)\n",
    "- **Define precision, recall, and f1-score and use them to evaluate different classifiers.**\n",
    "    - **************Recall:************** how many found, proportion of positive examples identified\n",
    "        - $recall = \\frac{TP}{TP + FN}=\\frac{TP}{\\# positives}$\n",
    "    - ********************Precision:******************** proportion of correctly identified positive, of all identified positive\n",
    "        - $precision = \\frac{TP}{TP + FP}=\\frac{TP}{\\#detected\\_positives}$\n",
    "    - ******************F1-score:****************** combinats precision and recall\n",
    "        - $f1=2\\times \\frac{precision \\times recall}{precision + recall}$\n",
    "        - measures quality of `predict`\n",
    "- **Broadly explain macro-average, weighted average.**\n",
    "    - ****************************Macro average:**************************** equal important to all classes, average over all classes\n",
    "        - e.g. if recall of non-fraud $= 1.0$, recall of fraud $= 0.63$, macroaverage $= 1.63/2 = 0.81$\n",
    "            \n",
    "            $0.5 * 1.0 + 0.5 * 0.63 = 0.81$\n",
    "            \n",
    "    - **********************************Weighted average:********************************** weighted by proportion of examples in class\n",
    "        - e.g. if $3/5$ targets were class 0 with recall 1.00, $2/5$ were class 1 with recall 0.50\n",
    "            \n",
    "            $3/5*1.00+2/5*0.5=0.80$\n",
    "            \n",
    "    - usage depends on if each class deserves same weight or not\n",
    "- **Interpret and use precision-recall curves.**\n",
    "    \n",
    "    ```python\n",
    "    precision_lr, recall_lr, thresholds_lr = precision_recall_curve(\n",
    "        y_valid, pipe_lr.predict_proba(X_valid)[:, 1]\n",
    "    )\n",
    "    PrecisionRecallCurveDisplay.from_estimator(pipe_lr, X_valid, y_valid);\n",
    "    \n",
    "    ap_lr = average_precision_score(y_valid, y_predict)\n",
    "    ```\n",
    "    \n",
    "    - precision-recall tradeoff\n",
    "        - identify more positives, recall increases, precision decreases\n",
    "            - i.e. finds more positives, but also finds more negatives\n",
    "    - ************************************decrease threshold************************************ → lower bar to predict positive\n",
    "        - increase recall, decrease precision\n",
    "        - precision may increase, if all new examples are TP\n",
    "    - increase ********************************************threshold →******************************************** higher bar to predict fraud\n",
    "        - decrease or stay same recall, increase precision\n",
    "        - precision may decrease (denominator of precision is TP + FP)\n",
    "    \n",
    "    ![Untitled](./img-notes/9-precisionrecallcurve.jpg)\n",
    "    \n",
    "    - top-left\n",
    "        - 1.0 recall, 0 precision\n",
    "            - finds all positive, but very low precision\n",
    "        - threshold = 0 → everything classified positively\n",
    "    - bottom-right\n",
    "        - 0 recall, 1.0 precision\n",
    "            - all found are positive, but found very few positives out of all\n",
    "        - threshold = 1 → very strict requirements to classify positively\n",
    "    - **********goal:********** keep recall high, as we increase precision\n",
    "- **Explain average precision score**\n",
    "    - **AP score:** Area under PR curve betwee 0, 1 (worst, best)\n",
    "        - summarizes PR plot\n",
    "        - summarizes weighted (previous recall increase) mean precision at each threshold\n",
    "        - evaluates quality of `predict_proba`\n",
    "- **Interpret and use ROC curves and ROC AUC using `scikit-learn`.**\n",
    "    \n",
    "    ```python\n",
    "    fpr, tpr, thresholds = roc_curve(\n",
    "    \ty_valid, pipe_lr.predict_proba(X_valid)[:, 1]\n",
    "    )\n",
    "    RocCurveDisplay.from_estimator(pipe_lr, X_valid, y_valid);\n",
    "    \n",
    "    roc_lr = roc_auc_score(y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
    "    ```\n",
    "    \n",
    "    - ROC curve → looks at\n",
    "        - **************************************************False positive rate (FPR):************************************************** negative classified as positive, over all negatives\n",
    "            \n",
    "            $FPR=\\frac{FP}{FP+ TN}$\n",
    "            \n",
    "        - **************************************************************True positive rate (TPR/recall):************************************************************** proportion of correctly classified positives, over all positives\n",
    "            \n",
    "            $TPR=\\frac{TP}{TP + FN}$\n",
    "            \n",
    "    - **********goal:********** high recall, while keeping low false positive rate\n",
    "        - top-left is ideal\n",
    "    - ****************ROC AUC:**************** single meaningful number for performance\n",
    "        - evaluates ranking of positive examples\n",
    "            - probability that random positive class has higher confidence than random negative class\n",
    "        - $0.5$ = random chance\n",
    "        - $1.0$ = all positive points higher score than negative\n",
    "- **Identify whether there is class imbalance and whether you need to deal with it.**\n",
    "    - training set contains many more of one class than others\n",
    "    - Why do I have class imbalance?\n",
    "        - class more naturally rare?\n",
    "        - data collection methods?\n",
    "    - may be fine to ignore\n",
    "- **Explain and use `class_weight` to deal with data imbalance.**\n",
    "    \n",
    "    ```python\n",
    "    pipe_lr_weight = make_pipeline(\n",
    "        StandardScaler(), \n",
    "        LogisticRegression(\n",
    "            max_iter=500, \n",
    "            class_weight={0:1, 1:10}  # ---> notice the weights\n",
    "        )\n",
    "    )\n",
    "    pipe_lr_weight.fit(X_train, y_train)\n",
    "    ```\n",
    "    \n",
    "    - rather than change threshold, change training procedure\n",
    "    - Change the weight of the classes\n",
    "    - can use `class_weight=\"balanced\"` so classes are equal\n",
    "    - Changing class weight\n",
    "        - generally reduces accuracy → by default maximizes accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Regression Evaluation Metrics\n",
    "\n",
    "- **Carry out feature transformations on somewhat complicated dataset.**\n",
    "    - use ****************************SimpleImputer**************************** with proper strategy\n",
    "    - ********************************Numeric features********************************\n",
    "        - apply ****************************StandardScaler****************************\n",
    "        - may not all be numeric just because datatype is `float`\n",
    "        - some are categorical, or ordinal represented as numbers\n",
    "    - ********************************Ordinal features********************************\n",
    "        - apply **OrdinalEncoder**\n",
    "        - group all ordinal features with same scale and different scales\n",
    "    - ****************************************Categorical features****************************************\n",
    "        - apply OHE with `handle_unknown=”ignore”`\n",
    "    - combine pipelines with `make_column_transformer`\n",
    "- **Visualize transformed features as a dataframe.**\n",
    "    - create new list of feature names, getting OHE column names\n",
    "    \n",
    "    ```python\n",
    "    preprocessor.named_transformers_\n",
    "    ohe_columns = list(\n",
    "        preprocessor.named_transformers_[\"pipeline-4\"]\n",
    "        .named_steps[\"onehotencoder\"]\n",
    "        .get_feature_names_out(categorical_features)\n",
    "    )\n",
    "    \n",
    "    new_columns = numeric_features + ordinal_features_reg + ordinal_features_oth + ohe_columns\n",
    "    \n",
    "    X_train_enc = pd.DataFrame(\n",
    "        preprocessor.transform(X_train), index=X_train.index, columns=new_columns\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "- **Use `Ridge` and `RidgeCV`.**\n",
    "    \n",
    "    ```python\n",
    "    lr_pipe = make_pipeline(preprocessor, Ridge())\n",
    "    pd.DataFrame(cross_validate(lr_pipe, X_train, y_train, cv=10, return_train_score=True))\n",
    "    ```\n",
    "    \n",
    "    ```python\n",
    "    alphas = 10.0 ** np.arange(-5, 5, 1)\n",
    "    # tunes alpha with cross validation\n",
    "    ridgecv_pipe = make_pipeline(preprocessor, RidgeCV(alphas=alphas, cv=10))\n",
    "    ridgecv_pipe.fit(X_train, y_train);\n",
    "    best_alpha = ridgecv_pipe.named_steps['ridgecv'].alpha_\n",
    "    best_alpha\n",
    "    # 100.0\n",
    "    ```\n",
    "    \n",
    "- **Explain how `alpha` hyperparameter of `Ridge` relates to the fundamental tradeoff.**\n",
    "    - small `alpha` → overfitting, low validation error\n",
    "    - large `alpha` → underfitting, low train & validation error\n",
    "- **Examine coefficients of transformed features.**\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"features\": new_columns,\n",
    "            \"coefficients\": lr_tuned.named_steps[\"ridge\"].coef_,\n",
    "        }\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "- **Appropriately select a scoring metric given a regression problem.**\n",
    "- **Interpret and communicate the meanings of different scoring metrics on regression problems.**\n",
    "    - **MSE:** degree to which predictions are wrong, units^2\n",
    "        \n",
    "        ```python\n",
    "        np.mean((y_train - preds) ** 2)\n",
    "        ```\n",
    "        \n",
    "    - **RMSE:** degree to which predictions are wrong, relable units\n",
    "        \n",
    "        ```python\n",
    "        np.sqrt(mean_squared_error(y_train, lr_tuned.predict(X_train)))\n",
    "        ```\n",
    "        \n",
    "    - $**R^2$:** how good the prediction, normalized with $1=$ perfect prediction\n",
    "        \n",
    "        ```python\n",
    "        r2_score(y_train, preds)\n",
    "        ```\n",
    "        \n",
    "    - ************MAPE:************ percentage of error\n",
    "        \n",
    "        ```python\n",
    "        np.mean(np.abs((pred - true) / true))\n",
    "        mean_absolute_percentage_error(y_test, ttr_pipe.predict(X_test))\n",
    "        ```\n",
    "        \n",
    "- **Apply log-transform on the target values in a regression problem with `TransformedTargetRegressor`.**\n",
    "    - get `fit` to use MAPE rather than Least Squares Error\n",
    "        \n",
    "        ```python\n",
    "        ttr = TransformedTargetRegressor(\n",
    "            Ridge(alpha=best_alpha), func=np.log1p, inverse_func=np.expm1\n",
    "        ) # transformer for log transforming the target\n",
    "        \n",
    "        ttr_pipe = make_pipeline(preprocessor, ttr)\n",
    "        \n",
    "        ttr_pipe.fit(X_train, y_train); # y_train automatically transformed\n",
    "        ttr_pipe.predict(X_train)  # predictions automatically un-transformed\n",
    "        \n",
    "        mean_absolute_percentage_error(y_test, ttr_pipe.predict(X_test))\n",
    "        ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table summarizing hyperparameters\n",
    "\n",
    "| Model | Hyperparameter | Overfit | Underfit |\n",
    "| --- | --- | --- | --- |\n",
    "| Decision Tree | max_depth | Large (max) | Low (1 stump) |\n",
    "| kNN | k (# neighbors) | Small  | Large |\n",
    "| SVM RBF/\n",
    "Linear SVM | C | Large | Small |\n",
    "| SVM RBF/\n",
    "Linear SVM | gamma | Large | Small |\n",
    "| Linear Regression/Ridge | alpha (regularization) | Small | Large |\n",
    "| Logistic Regression | C (inverse regularization) | Large | Small |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-ensembles\n",
    "\n",
    "> **Use `scikit-learn`’s `RandomForestClassifier` and explain its main hyperparameters.**\n",
    "> \n",
    "\n",
    "```python\n",
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(random_state=123, n_jobs=-1)\n",
    ")\n",
    "```\n",
    "\n",
    "- `n_estimators`: number of decision trees (higher = **increases complexity**)\n",
    "- `max_depth`: max depth of each decision tree (higher = **increases complexity**)\n",
    "- `max_features`: the number of features you get to look at each split (higher = **increases complexity**)\n",
    "- setting `random_state` is important for reproducibility\n",
    "- **Explain randomness in random forest algorithm.**\n",
    "    - **************************************************************************randomness in classifier construction**************************************************************************\n",
    "        1. **********Data:********** tree built on bootstrap sample (with replacement)\n",
    "        2. ****************Feature:**************** each node select **************************************************random subset of features************************************************** + best possible test involving themxdisplay\n",
    "\n",
    "> **Use other tree-based models such as as `XGBoost` and `LGBM`.**\n",
    "> \n",
    "\n",
    "```python\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMClassifier(random_state=123))\n",
    "pipe_xgb = make_pipeline(\n",
    "    preprocessor, XGBClassifier(random_state=123, eval_metric=\"logloss\", verbosity=0)\n",
    ")\n",
    "```\n",
    "\n",
    "> **Employ ensemble classifier approaches, in particular model averaging and stacking.\n",
    "\n",
    "Use `scikit-learn` implementations of these ensemble methods.**\n",
    "> \n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "classifiers = {\n",
    "    \"logistic regression\": pipe_lr,\n",
    "    \"decision tree\": pipe_dt,\n",
    "    \"random forest\": pipe_rf,\n",
    "    #\"XGBoost\": pipe_xgb,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_catboost,\n",
    "}\n",
    "averaging_model = VotingClassifier(\n",
    "    list(classifiers.items()), voting=\"soft\"\n",
    ")  # need the list() here for cross_val to work!\n",
    "\n",
    "averaging_model.fit(X_train, y_train);\n",
    "```\n",
    "\n",
    "- `voting='hard'`\n",
    "    - output of `predict` and actually votes\n",
    "- `voting='soft'`\n",
    "    - averages output of `predict_proba` from base classifier, uses threshold/larger\n",
    "    - assumes we trust `predict_proba`\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# remove cat boost for time\n",
    "classifiers_nocat = classifiers.copy()\n",
    "del classifiers_nocat[\"CatBoost\"]\n",
    "\n",
    "stacking_model = StackingClassifier(list(classifiers_nocat.items()))\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(\n",
    "    data=stacking_model.final_estimator_.coef_[0],\n",
    "    index=classifiers_nocat.keys(),\n",
    "    columns=[\"Coefficient\"],\n",
    ")\n",
    "\n",
    "stacking_model.final_estimator_.intercept_\n",
    "```\n",
    "\n",
    "- default `final_estimator` is `LogisticRegression` for classification\n",
    "- does cross-validation by default\n",
    "    - fit base estimators on training fold → predicts on validation fold → fit meta-estimator on output (validation fold)\n",
    "    - `estimators_` fitted on full `X`\n",
    "    - `final_estimator_` trained using cross-validation predictions of base estimators using `cross_val_predict`\n",
    "\n",
    "> **Explain voting and stacking and the differences between them.**\n",
    "> \n",
    "\n",
    "| Voting | Stacking |\n",
    "| --- | --- |\n",
    "| Multiple models either soft vote (average) or hard vote to produce final classification | outputs of one model used as input to another |\n",
    "|  | outputs coefficients + intercept for each base classifier |\n",
    "| Takes long time to fit/predict | Takes very long time to fit/predict |\n",
    "| reduces interpretability |  |\n",
    "| reduces maintainability | reduces maintainability |\n",
    "|  | better accuracy generally than voting |\n",
    "- Voting\n",
    "    - Cons\n",
    "        - `fit` `predict` time\n",
    "        - reduces interpretability\n",
    "        - reduces maintainability\n",
    "- **Stacking:** one models output is input to another model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Feature Importances\n",
    "\n",
    "> **Interpret the coefficients of linear regression for ordinal, one-hot encoded categorical, and scaled numeric features.**\n",
    "> \n",
    "\n",
    "```python\n",
    "lr = make_pipeline(preprocessor, Ridge())\n",
    "lr.fit(X_train, y_train)\n",
    "lr.named_steps['ridge'].coef_\n",
    "```\n",
    "\n",
    "- **********************************Ordinal features:**********************************\n",
    "    - easier to interpret\n",
    "    - increasing by one “ordered” category increases prediction by coefficient value\n",
    "- ************************Categorical:************************ use a ************************************reference category************************************\n",
    "    - subtracting all OHE coefficients of a category by one of the category coefficients\n",
    "    - coefficients explain difference between reference category and others\n",
    "- ********************************Scaled Numeric Features:******************************** Increase feature by 1 scaled unit changes prediction by coefficient value\n",
    "    - careful of scale when interpreting coefficients\n",
    "- coefficients tell about the ******************************************model, not accurately reflecting data******************************************\n",
    "\n",
    "> **Explain why interpretability is important in ML.**\n",
    "> \n",
    "- diagnosing errors in ML systems\n",
    "- not mindlessly trusting model with high accuracy\n",
    "- reasoning about predictions\n",
    "\n",
    "> **Use `feature_importances_` attribute of `sklearn` models and interpret its output.**\n",
    "> \n",
    "\n",
    "```python\n",
    "pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier(max_depth=3))\n",
    "pipe_dt.fit(X_train, y_train)\n",
    "pipe_dt.named_steps[\"decisiontreeclassifier\"].feature_importances_,\n",
    "```\n",
    "\n",
    "- `feature_importances_` don’t have sign\n",
    "    - ********************increasing******************** feature may cause prediction to go **up, then down**\n",
    "\n",
    "> **Use `eli5` to get feature importances of non `sklearn` models and interpret its output.**\n",
    "> \n",
    "\n",
    "```python\n",
    "conda install -c conda-forge eli5\n",
    "import eli5\n",
    "\n",
    "#LightGBM\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMClassifier(random_state=123))\n",
    "pipe_lgbm.fit(X_train, y_train)\n",
    "eli5.explain_weights(\n",
    "    pipe_lgbm.named_steps[\"lgbmclassifier\"], \n",
    "    feature_names=feature_names\n",
    ")\n",
    "```\n",
    "\n",
    "![Untitled](./img-notes/12-eli5.jpg)\n",
    "\n",
    "- tell us globally what features are important\n",
    "\n",
    "> **Apply SHAP to assess feature importances and interpret model predictions.**\n",
    "> \n",
    "- ******************************Shapley values:****************************** for each example & feature → explain prediction by computing contribution of each feature to prediction\n",
    "- For tree-based models\n",
    "    \n",
    "    ```python\n",
    "    import shap\n",
    "    \n",
    "    pipe_lgbm = make_pipeline(preprocessor, LGBMClassifier(random_state=123))\n",
    "    pipe_lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    lgbm_explainer = shap.TreeExplainer(pipe_lgbm.named_steps[\"lgbmclassifier\"])\n",
    "    # for each example & each feature\n",
    "    train_lgbm_shap_values = lgbm_explainer.shap_values(X_train_enc)\n",
    "    ```\n",
    "    \n",
    "\n",
    "> **Explain force plot, summary plot, and dependence plot produced with shapely values.**\n",
    "> \n",
    "- **Force plot**\n",
    "    \n",
    "    ```python\n",
    "    ex_l50k_index = # index of one value that is classified as <50k salary\n",
    "    shap.force_plot(\n",
    "        lgbm_explainer.expected_value[1],\n",
    "        test_lgbm_shap_values[1][ex_l50k_index, :],\n",
    "        X_test_enc.iloc[ex_l50k_index, :],\n",
    "        matplotlib=True,\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "    ![Untitled](./img-notes/12-force.jpg)\n",
    "    \n",
    "    - from ********************base value******************** → average over dataset\n",
    "        - red → features pushing prediction towards higher score\n",
    "        - blue → features pushign prediction towards lower score\n",
    "    - feature importances sum to prediction\n",
    "- ************************Summary plot************************\n",
    "    \n",
    "    ```python\n",
    "    shap.summary_plot(train_lgbm_shap_values[1], X_train_enc, plot_type=\"bar\")\n",
    "    \n",
    "    shap.summary_plot(train_lgbm_shap_values[1], X_train_enc)\n",
    "    ```\n",
    "    \n",
    "\n",
    "![Untitled](./img-notes/12-summary1.jpg)\n",
    "\n",
    "![Untitled](./img-notes/12-summary2.jpg)\n",
    "\n",
    "- `married-civ-spouse` = bigger SHAP values for class 1\n",
    "- higher education = bigger SHAP\n",
    "- ******************************Dependency Plot******************************\n",
    "    \n",
    "    ```python\n",
    "    shap.dependence_plot(\"age\", train_lgbm_shap_values[1], X_train_enc)\n",
    "    ```\n",
    "    \n",
    "    ![Untitled](./img-notes/12-dependence.jpg)\n",
    "    \n",
    "    - X-axis = scaled `age` values\n",
    "    - Y-axis = SHAP values\n",
    "    - smaller age = smaller SHAP values\n",
    "    - optimal age value with highest SHAP around (scaled) `"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 - K-Means Clustering\n",
    "\n",
    "> **Explain the unsupervised paradigm.**\n",
    "> \n",
    "- train model to find **patterns** in dataset that is typically ********unlabeled********\n",
    "\n",
    "> **Explain the motivation and potential applications of clustering.**\n",
    "> \n",
    "- Partition data into groups called clusters to ****************************************************discover underlying groups****************************************************\n",
    "    - labels arbitrarily identify clusters\n",
    "    - meaning depends on application and prior knowledge about data\n",
    "- Applications\n",
    "    1. ********************************Data exploration********************************\n",
    "    2. ******************************************Customer segmentation******************************************\n",
    "    3. **************************************Document clustering**************************************\n",
    "\n",
    "> **Define the clustering problem**\n",
    "> \n",
    "\n",
    "> **Broadly explain the K-Means algorithm.**\n",
    "> \n",
    "- Input: `X` data points, `K` clusters\n",
    "- initialization of `K` cluster centers\n",
    "- Iterate\n",
    "    1. assign example to closest center\n",
    "    2. estimate new center as **********************************************average of observations**********************************************\n",
    "- may not converge or converge sub-optimally\n",
    "\n",
    "> **Apply `sklearn`’s `KMeans` algorithm.**\n",
    "> \n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "# We are only passing X because this is unsupervised learning\n",
    "\n",
    "kmeans.predict(X)\n",
    "\n",
    "kmeans.cluster_centers_\n",
    "```\n",
    "\n",
    "> **Point out pros and cons of K-Means and the difficulties associated with choosing the right number of clusters.**\n",
    "> \n",
    "\n",
    "Pros\n",
    "\n",
    "- allows clustering\n",
    "- simple to understand, easy to implement\n",
    "- fast + scales to large data\n",
    "- choose clusters using elbow and silhouette method\n",
    "\n",
    "Cons\n",
    "\n",
    "- Stochastic initialization → can start poorly\n",
    "- may converge suboptimally\n",
    "- must specify clusters in advance\n",
    "- each example must be assigned to one cluster\n",
    "\n",
    "> **Create the Elbow plot and Silhouette plots for a given dataset.**\n",
    "> \n",
    "- **************Elbow Method:************** looks at **************inertia**************, the sum of **********************************************************intra-cluster distances********************************************************** between points and their cluster center\n",
    "    \n",
    "    ```python\n",
    "    from yellowbrick.cluster import KElbowVisualizer\n",
    "    \n",
    "    model = KMeans()\n",
    "    visualizer = KElbowVisualizer(model, k=(1, 10))\n",
    "    \n",
    "    visualizer.fit(X)  # Fit the data to the visualizer\n",
    "    visualizer.finalize()\n",
    "    \n",
    "    visualizer.draw()\n",
    "    ```\n",
    "    \n",
    "    ![Untitled](./img-notes/13-elbow.jpg)\n",
    "    \n",
    "    - elbow at `k=3` → more clusters doesn’t bring improvement in decreasing inertia\n",
    "- ********************************Silhouette plot:******************************** calculated using\n",
    "    - **mean intra-cluster distance $a$:** distance from a point to other points in same cluster\n",
    "    - **mean nearest-cluster distance $b$:** distance from point to other points in nearest cluster\n",
    "    - ****************************************silhouette distance:**************************************** difference between $b-a$ normalized by maximum value\n",
    "        - $[-1, 1]$\n",
    "        - $0$ means overlapping clusters\n",
    "    - **********************************Silhouette score:********************************** average of silhouette score for all samples\n",
    "    \n",
    "    ```python\n",
    "    from yellowbrick.cluster import SilhouetteVisualizer\n",
    "    ```\n",
    "    \n",
    "\n",
    "```python\n",
    "model = KMeans(2, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(model, colors=\"yellowbrick\")\n",
    "visualizer.fit(X)  # Fit the data to the visualizer\n",
    "visualizer.show();\n",
    "# Finalize and render the figure\n",
    "```\n",
    "\n",
    "```python\n",
    "model = KMeans(3, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(model, colors=\"yellowbrick\")\n",
    "visualizer.fit(X)  # Fit the data to the visualizer\n",
    "visualizer.show();\n",
    "# Finalize and render the figure\n",
    "```\n",
    "\n",
    "```python\n",
    "model = KMeans(5, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(model, colors=\"yellowbrick\")\n",
    "visualizer.fit(X)  # Fit the data to the visualizer\n",
    "visualizer.show();\n",
    "# Finalize and render the figure\n",
    "```\n",
    "\n",
    "![Untitled](./img-notes/13-silhouette2.jpg)\n",
    "\n",
    "![Untitled](./img-notes/13-silhouette3.jpg)\n",
    "\n",
    "![Untitled](./img-notes/13-silhouette5.jpg)\n",
    "\n",
    "- Silhouette score for each sample in cluster\n",
    "    - ********************************higher value →******************************** well-separated\n",
    "    - size → # samples\n",
    "- ****************************************more rectangular →**************************************** points are happy in cluster\n",
    "\n",
    "> **Visualize clusters in low dimensional space.**\n",
    "> \n",
    "\n",
    "```python\n",
    "import umap\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(data_df)\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=15)\n",
    "Z = reducer.fit_transform(data_df)\n",
    "umap_df = pd.DataFrame(data=Z, columns=[\"dim1\", \"dim2\"])\n",
    "umap_df[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "labels = np.unique(umap_df[\"cluster\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.set_title(\"K-means with k = 3\")\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    umap_df[\"dim1\"],\n",
    "    umap_df[\"dim2\"],\n",
    "    c=umap_df[\"cluster\"],\n",
    "    cmap=\"tab20b\",\n",
    "    s=50,\n",
    "    edgecolors=\"k\",\n",
    "    linewidths=0.1,\n",
    ")\n",
    "\n",
    "legend = ax.legend(*scatter.legend_elements(), loc=\"best\", title=\"Clusters\")\n",
    "ax.add_artist(legend)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "![k=3](./img-notes/13-lowdim.jpg)\n",
    "\n",
    "k=3\n",
    "\n",
    "> **Use clustering for customer segmentation problem.**\n",
    "> \n",
    "- ********************************************Customer segmentation:******************************************** understand landscape of market in business to tailor products to each group\n",
    "    - uses demographic, geographic, psychographic, behavioral data\n",
    "1. Preprocess, EDA, and build pipeline\n",
    "2. analyze which `k` to use using elbow or silhouette plots\n",
    "3. build model\n",
    "    \n",
    "    ```python\n",
    "    kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "    kmeans.fit(transformed_df)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    cluster_centers = pd.DataFrame(\n",
    "        data=kmeans.cluster_centers_, columns=[transformed_df.columns]\n",
    "    )\n",
    "    cluster_centers\n",
    "    ```\n",
    "    \n",
    "4. ********************************************************************************************inverse transform to unscale cluster centers********************************************************************************************\n",
    "    \n",
    "    ```python\n",
    "    data = (\n",
    "        preprocessor.named_transformers_[\"pipeline\"]\n",
    "        .named_steps[\"standardscaler\"]\n",
    "        .inverse_transform(cluster_centers[numeric_features])\n",
    "    )\n",
    "    ```\n",
    "    \n",
    "\n",
    "> **Interpret the clusters discovered by K-Means.**\n",
    ">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 - DBSCAN & Hierchical Clustering\n",
    "\n",
    "> **Identify limitations of K-Means.**\n",
    "> \n",
    "- Stochastic initialization → can start poorly\n",
    "- may converge suboptimally\n",
    "- must specify clusters in advance\n",
    "- each example must be assigned to one cluster\n",
    "- ********************************************************fails to identify complexity******************************************************** in shape of data\n",
    "    - ******************************************boundaries are linear******************************************\n",
    "\n",
    "> **Explain the difference between core points, border points, and noise points in the context of DBSCAN.**\n",
    "> \n",
    "- Iterative algorithm using 3 kinds of points to identify dense regions\n",
    "    1. **********************Core point:********************** points with `min_samples` points within `eps` distance\n",
    "    2. **************************Border point:************************** connected to core point within `eps` distance, but fewer than `min_samples`\n",
    "    3. ************************Noise point:************************ points don’t belong to cluster \n",
    "\n",
    "> **Broadly explain how DBSCAN works.**\n",
    "> \n",
    "- ****************DBSCAN:**************** Density-Based Spatial Clustering of Applications with Noise\n",
    "    - ****************************************************identify crowded regions:**************************************************** clusters form dense regions in data\n",
    "- algorithm\n",
    "    1. pick random point $p$\n",
    "    2. check whether $p$ is ********************core point******************** (at least `min_samples` neighbors within `eps`)\n",
    "    3. if core point, give label\n",
    "    4. for neighbors of $p$, check if ********************core point******************** → continue spreading label if core point\n",
    "    5. once no more core points to spread label, pick new unlabelled $p$ and repeat\n",
    "\n",
    "> **Apply DBSCAN using `sklearn`.**\n",
    "> \n",
    "\n",
    "```python\n",
    "dbscan = DBSCAN(eps=0.2)\n",
    "dbscan.fit(X)\n",
    "```\n",
    "\n",
    "> **Explain the effect of epsilon and minimum samples hyperparameters in DBSCAN.**\n",
    "> \n",
    "- `eps` : determines ******************closeness****************** of points\n",
    "    - small eps → difficult to find neighbors\n",
    "    - good eps → detects neighbors forming some clusters\n",
    "    - high eps → points all in one cluster\n",
    "- `min_samples` : determines # neighboring points to consider as part of cluster\n",
    "    - low min_samples → few outliers, many clusters\n",
    "    - good min_samples → some outliers, fewer clusters\n",
    "    - high min_samples → many outliers, very few clusters\n",
    "\n",
    "> **Identify DBSCAN limitations.**\n",
    "> \n",
    "\n",
    " Pros\n",
    "\n",
    "- doesn’t require # clusters in advance\n",
    "- identifies points not part of any cluster\n",
    "- captures complex shapes\n",
    "- use silhouette method\n",
    "\n",
    "Cons\n",
    "\n",
    "- must tune hyperparameter `esp` and `min_samples`\n",
    "- doesn’t `predict` new points (only existing)\n",
    "- cannot use elbow method\n",
    "- fails for varying density\n",
    "\n",
    "> **Explain the idea of hierarchical clustering.**\n",
    "> \n",
    "- get picture of similarity before picking # clusters\n",
    "- ******************Algorithm******************\n",
    "    1. start with every point in own cluster\n",
    "    2. ****************************greedily merge**************************** similar clusters\n",
    "    3. repeat until only one cluster ($n-1$ times)\n",
    "\n",
    "> **Visualize dendrograms using `scipy.cluster.hierarchy.dendrogram`.**\n",
    "> \n",
    "\n",
    "```python\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "ax = plt.gca()\n",
    "dendrogram(linkage_array, ax=ax)\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Cluster distance\");\n",
    "```\n",
    "\n",
    "- `truncate_mode` to control dendrogram length\n",
    "    - `lastp` = # leaves\n",
    "    - `level` = max depth\n",
    "    \n",
    "    ```python\n",
    "    dendrogram(Z, p=6, truncate_mode=\"lastp\", ax=ax, labels=data.index)\n",
    "    dendrogram(Z, p=6, truncate_mode=\"level\", ax=ax, labels=data.index);\n",
    "    ```\n",
    "    \n",
    "- `fcluster` to flatten\n",
    "    \n",
    "    ```python\n",
    "    from scipy.cluster.hierarchy import fcluster\n",
    "    \n",
    "    cluster_labels = fcluster(Z, 6, criterion=\"maxclust\")\n",
    "    \n",
    "    pd.DataFrame(cluster_labels, data.index)\n",
    "    ```\n",
    "    \n",
    "\n",
    "> **Explain the advantages and disadvantages of different clustering methods.**\n",
    "> \n",
    "\n",
    "|  | K-means | DBSCAN | hierarchical |\n",
    "| --- | --- | --- | --- |\n",
    "| Advantage | - easy implement\n",
    "- fast/efficient for large data\n",
    "- works well for linearly separated data\n",
    "- variety of distance metrics | - automatically identifies # clusters\n",
    "- identifies irregular shapes\n",
    "- robust to outliers | - hierarchy of clusters, range of solutions\n",
    "- doesn’t require specifying # clusters\n",
    "- distance metrics & linkage methods\n",
    "- identify clusters at varying granularity |\n",
    "| Disadvantage | - pre-specified # clusters\n",
    "- sensitive to initial selection → different results\n",
    "- can converge sub-optimally\n",
    "- not suitable for irregular shaped data | - sensitivity to hyperparameters\n",
    "- computationally expensive for large data\n",
    "- requires tuning\n",
    "- doesn’t work for varying density | - computationally expensive for large data\n",
    "- sensitive to distance/linkage choice\n",
    "- difficult to determine optimal number clusters\n",
    "- suffer from chaining effect (merging too early) |\n",
    "\n",
    "> **Apply clustering algorithms on image datasets and interpret clusters.**\n",
    "> \n",
    "\n",
    "> **Recognize the impact of distance measure and representation in clustering methods.**\n",
    "> \n",
    "\n",
    "```python\n",
    "from scipy.cluster.hierarchy import (\n",
    "    average,\n",
    "    complete,\n",
    "    dendrogram,\n",
    "    fcluster,\n",
    "    single,\n",
    "    ward,\n",
    ")\n",
    "\n",
    "Z = single(X)\n",
    "Z = average(X)\n",
    "Z = complete(X)\n",
    "Z = ward(X)\n",
    "dendrogram(Z)\n",
    "```\n",
    "\n",
    "- similarity/********************************linkage criteria******************************** between clusters\n",
    "    1. ******************************single linkage:****************************** smallest, min-distance between two clusters\n",
    "    2. ********************************average linkage:******************************** smallest, avg-distance between two clusters\n",
    "    3. ******************************************complete/max linkage:****************************************** smallest, max-distance between points of two clusters\n",
    "    4. **************************ward linkage:************************** merge clusters to minimize increase in cluster variance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 - Recommender Systems\n",
    "\n",
    "> **State the problem of recommender systems.**\n",
    "> \n",
    "- **************************************Recommender system:************************************** Recommend particular product/service to users that are likely to consume\n",
    "    - requires user ratings, features related to items + users, customer purchase history\n",
    "- **************ratings************** for set of $M$ items for $N$ users\n",
    "\n",
    "> **Describe components of a utility matrix.**\n",
    "> \n",
    "- ******************************Utility matrix:****************************** iteration between $N$ users, $M$ items\n",
    "    - e.g. ratings, clicks, purchases\n",
    "    - complete utility matrix to recommend items they will rate higher\n",
    "\n",
    "> **Create a utility matrix given ratings data.**\n",
    "> \n",
    "\n",
    "```python\n",
    "# Maps user/item to a number\n",
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "# Maps number to user/item\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))\n",
    "\n",
    "user_key = \"userId\"\n",
    "item_key = \"productId\"\n",
    "Y = np.zeros((N, M))\n",
    "Y.fill(np.nan)\n",
    "for index, val in data.iterrows():\n",
    "    n = user_mapper[val[user_key]]\n",
    "    m = item_mapper[val[item_key]]\n",
    "    Y[n, m] = val[\"rating\"]\n",
    "```\n",
    "\n",
    "> **Describe a common approach to evaluate recommender systems.**\n",
    "> \n",
    "- ********************Diversity:******************** how different are recommendations\n",
    "- ********************Freshness:******************** people like new/surprising things, tradeoff is trust issues and explaining recommendations\n",
    "- ************************Persistence:************************ how long recommendation lasts\n",
    "- ********************************************Social recommendation:******************************************** what did friends watch\n",
    "\n",
    "> **Implement some baseline approaches to complete the utility matrix.**\n",
    "> \n",
    "\n",
    "```python\n",
    "X = ratings.copy()\n",
    "# will not use y\n",
    "y = ratings[user_key]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_valid.shape\n",
    "# ((113089, 3), (28273, 3))\n",
    "\n",
    "# Create training and validation utility matrices\n",
    "train_mat = create_Y_from_ratings(X_train, N, M, user_mapper, item_mapper)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M, user_mapper, item_mapper)\n",
    "train_mat.shape, valid_mat.shape\n",
    "# ((3635, 140), (3635, 140))\n",
    "# same shape, but each only contain a proportion of all ratings\n",
    "```\n",
    "\n",
    "```python\n",
    "def error(X1, X2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((X1 - X2) ** 2))\n",
    "\n",
    "def evaluate(pred_X, train_X, valid_X, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_X, train_X)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_X, valid_X)))\n",
    "```\n",
    "\n",
    "- predict as global average\n",
    "    \n",
    "    ```python\n",
    "    avg = np.nanmean(train_mat)\n",
    "    pred_g = np.zeros(train_mat.shape) + avg\n",
    "    \n",
    "    evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")\n",
    "    '''\n",
    "    Global average train RMSE: 5.75\n",
    "    Global average valid RMSE: 5.77\n",
    "    '''\n",
    "    ```\n",
    "    \n",
    "- KNN imputation: imputate using ********************mean value******************** of kNN in training set, distances between existing values\n",
    "    \n",
    "    ```python\n",
    "    from sklearn.impute import KNNImputer\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=10)\n",
    "    train_mat_imp = imputer.fit_transform(train_mat)\n",
    "    \n",
    "    evaluate(train_mat_imp, train_mat, valid_mat, model_name=\"KNN imputer\")\n",
    "    '''\n",
    "    KNN imputer train RMSE: 0.00\n",
    "    KNN imputer valid RMSE: 4.79\n",
    "    '''\n",
    "    ```\n",
    "    \n",
    "\n",
    "> **Explain the idea of collaborative filtering.**\n",
    "> \n",
    "- ****************************************************unsupervised learning →**************************************************** learn features using sparse labels\n",
    "- **intuition**: similar users and items help predict entries → leveraging ************************************social information************************************\n",
    "- can use ********************************cross-validation******************************** and ************grid search************\n",
    "\n",
    "```python\n",
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings, reader)  # Load the data\n",
    "\n",
    "# I'm being sloppy here. Probably there is a way to create validset from our already split data.\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.2, random_state=42\n",
    ")  # Split the data\n",
    "\n",
    "k = 10\n",
    "algo = SVD(n_factors=k, random_state=42)\n",
    "algo.fit(trainset)\n",
    "svd_preds = algo.test(validset)\n",
    "accuracy.rmse(svd_preds, verbose=True)\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "pd.DataFrame(cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True))\n",
    "```\n",
    "\n",
    "> **Explain the idea of content-based filtering.**\n",
    "> \n",
    "- e.g. for movie recommendation\n",
    "    - we know movie ratings\n",
    "    - we know movie features\n",
    "    - we can create profile for each user based on the movies they like\n",
    "- rating prediction → **********************************************************supervised regressoin problem**********************************************************\n",
    "    - given movie info, create profile\n",
    "    - build regression model for each user, learn regression weights\n",
    "    - each user has personalized regression model\n",
    "\n",
    "********Pros********\n",
    "\n",
    "- don’t need many users to provide rating\n",
    "- each user modeled separately → uniqueness of taste\n",
    "- can obtain **features of items**, can immediately recommend new items\n",
    "    - not possible with collaborative filtering\n",
    "- recommendations **************************interpretable************************** by weights\n",
    "\n",
    "********Cons********\n",
    "\n",
    "- feature acquisition & feature engineering\n",
    "    - what features should we use to explain difference in ratings?\n",
    "    - obtaining features for each item may be expensive\n",
    "- ************************************less diversity →************************************ hardly recommend item outside profile\n",
    "- ****************************cold start →**************************** new users, no information\n",
    "\n",
    "> **Explain some serious consequences of recommendation systems.**\n",
    "> \n",
    "- User exposed to information **reinforcing beliefs and biases**\n",
    "    - increases **polarization**, **lessens diversity** in perspective\n",
    "- maximizing user engagement by **reinforcing harmful ideas**\n",
    "- perpetuate/amplify ******************************************bias & discrimination****************************************** by learning them and recommending the products/content\n",
    "- ************************************privacy violations************************************ by relying on personal user data without consent\n",
    "- **********************************************************misinformation and propoganda********************************************************** if recommendations spread false information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 - NLP Intro\n",
    "\n",
    "> **Broadly explain what is natural language processing (NLP).**\n",
    "> \n",
    "- ******NLP:****** making computers understand what humans say\n",
    "    - requires common sense and reasoning\n",
    "        - ************************************lexical ambiguity:************************************ e.g. panini means a sandwich and a person’s name\n",
    "        - ********************************************referential ambiguity:******************************************** e.g. the word “it” could refer to multiple nouns in a sentence\n",
    "\n",
    "> **Name some common NLP applications.**\n",
    "> \n",
    "- Voice assistants\n",
    "- auto-complete\n",
    "- translation\n",
    "\n",
    "> **Explain the general idea of a vector space model.**\n",
    "> \n",
    "- represent text as a ********************************************************************************numeric vector in high-dimensional space********************************************************************************\n",
    "    - each word represented as a point\n",
    "    - distance between points represents ********************similarity********************\n",
    "        - i.e. normalized dot product between word vectors or **********************************cosine similarity**********************************\n",
    "\n",
    "> **Explain the difference between different `word representations`: term-term co-occurrence matrix representation and Word2Vec representation.**\n",
    "> \n",
    "\n",
    "| term-term co-occurrence matrix | Word2Vec representation. |\n",
    "| --- | --- |\n",
    "| in text, counts words within a context window | dense word embedding trained with ML models |\n",
    "| long, sparse representation to capture relationship between words | short, dense vectors |\n",
    "|  | training is expensive |\n",
    "|  | pre-trained word embedding |\n",
    "| BoW is document-term co-occurrence matrix |  |\n",
    "\n",
    "> **Describe the reasons and benefits of using pre-trained embeddings.**\n",
    "> \n",
    "- pre-computed word/phrase representations trained on large amount of data useful when\n",
    "    1. ************************Data scarce:************************ data available is limited\n",
    "    2. ****************************Time efficient**************************** to skip step of training own word embedding\n",
    "    3. ****************************************improved performance**************************************** with good initialization point to capture semantic and syntactic information to learn better representations downstream\n",
    "    4. ************************************transfer learning:************************************ model trained on one task fine-tuned on new task\n",
    "    5. ******************************************multilingual support******************************************\n",
    "\n",
    "> **Load and use pre-trained word embeddings to find word similarities and analogies.**\n",
    "> \n",
    "\n",
    "```python\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "google_news_vectors = api.load('word2vec-google-news-300')\n",
    "\n",
    "google_news_vectors.most_similar(\"UBC\")\n",
    "google_news_vectors.similarity(\"Japan\", \"hockey\")\n",
    "\n",
    "# analogy\n",
    "print(\"%s : %s :: %s : ?\" % (word1, word2, word3))\n",
    "sim_words = model.most_similar(positive=[word3, word2], negative=[word1])\n",
    "return pd.DataFrame(sim_words, columns=[\"Analogy word\", \"Score\"])\n",
    "```\n",
    "\n",
    "> **Demonstrate biases in embeddings and learn to watch out for such biases in pre-trained embeddings.**\n",
    "> \n",
    "\n",
    "> **Use word embeddings in text classification and document clustering using `spaCy`.**\n",
    "> \n",
    "\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"pineapple\") # extract all interesting information about the document\n",
    "\n",
    "#Average Embedding\n",
    "doc = nlp(\"All empty promises\")\n",
    "avg_sent_emb = doc.vector\n",
    "\n",
    "# document similarity\n",
    "doc1 = nlp(\"Deep learning is very popular these days.\")\n",
    "doc2 = nlp(\"Machine learning is dominated by neural networks.\")\n",
    "doc3 = nlp(\"A home-made fresh bread with butter and cheese.\")\n",
    "doc1.similarity(doc2)\n",
    "```\n",
    "\n",
    "Airline sentiment analysis\n",
    "\n",
    "- Split data\n",
    "    \n",
    "    ```python\n",
    "    from sklearn.model_selection import cross_validate, train_test_split\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=123)\n",
    "    X_train, y_train = train_df[\"text\"], train_df[\"airline_sentiment\"]\n",
    "    X_test, y_test = test_df[\"text\"], test_df[\"airline_sentiment\"]\n",
    "    ```\n",
    "    \n",
    "- BoW representation\n",
    "    \n",
    "    ```python\n",
    "    pipe = make_pipeline(\n",
    "        CountVectorizer(stop_words=\"english\"), LogisticRegression(max_iter=1000)\n",
    "    )\n",
    "    pipe.named_steps[\"countvectorizer\"].fit(X_train)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.score(X_train, y_train)\n",
    "    pipe.score(X_test, y_test)\n",
    "    ```\n",
    "    \n",
    "- Average Embedding\n",
    "    \n",
    "    ```python\n",
    "    # get word vectors by creating average embedding representation for examples\n",
    "    X_train_embeddings = pd.DataFrame([text.vector for text in nlp.pipe(X_train)])\n",
    "    X_test_embeddings = pd.DataFrame([text.vector for text in nlp.pipe(X_test)])\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lgr = LogisticRegression(max_iter=2000)\n",
    "    lgr.fit(X_train_embeddings, y_train)\n",
    "    lgr.score(X_train_embeddings, y_train)\n",
    "    lgr.score(X_test_embeddings, y_test)\n",
    "    ```\n",
    "    \n",
    "\n",
    "> **Explain the general idea of topic modeling.**\n",
    "> \n",
    "- **********************************Topic modelling:********************************** summarize major themes in collection of documents (corpus)\n",
    "    - organize and categorize documents on variety of topics\n",
    "    - commonly using ****************************************unsupervised methods****************************************\n",
    "- application\n",
    "    - EDA to get sense of large corpus\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_topics = 3 # number of topics\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics, learning_method=\"batch\", max_iter=10, random_state=0\n",
    ")\n",
    "lda.fit(toy_X) \n",
    "# document-topic association\n",
    "document_topics = lda.transform(toy_X)\n",
    "\n",
    "# word-topic association: weight associated with each word\n",
    "lda.components_\n",
    "```\n",
    "\n",
    "> **Describe the input and output of topic modeling.**\n",
    "> \n",
    "- ************Input:************\n",
    "    - collection of documents\n",
    "    - hyperparameter for number of topics/clusters $K$\n",
    "- **************Output:**************\n",
    "    1. **********************************************Topic-word association:********************************************** for each topic, what words describe it\n",
    "    2. **************Document-topics association:************** what topic expressed by each document\n",
    "\n",
    "> **Carry out basic text preprocessing using `spaCy`.**\n",
    "> \n",
    "\n",
    "```python\n",
    "clean_text = []\n",
    "min_token_len = 2\n",
    "irrelevant_pos=[\"ADV\", \"PRON\", \"CCONJ\", \"PUNCT\", \"PART\", \"DET\", \"ADP\", \"SPACE\"]\n",
    "\n",
    "for token in nlp.pipe(text_df[\"text\"]):\n",
    "    if (\n",
    "        token.is_stop == False  # Check if it's not a stopword\n",
    "        and len(token) > min_token_len  # Check if the word meets minimum threshold\n",
    "        and token.pos_ not in irrelevant_pos\n",
    "    ):  # Check if the POS is in the acceptable POS tags\n",
    "        lemma = token.lemma_  # Take the lemma of the word\n",
    "        clean_text.append(lemma.lower())\n",
    "return \" \".join(clean_text)\n",
    "```\n",
    "\n",
    "- **************************tokenization:**************************\n",
    "    - sentence segmentation (text into sentences)\n",
    "        \n",
    "        ```python\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        sent_tokenized = sent_tokenize(text)\n",
    "        ```\n",
    "        \n",
    "    - word tokenization (sentences into words)\n",
    "        \n",
    "        ```python\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        \n",
    "        word_tokenized = [word_tokenize(sent) for sent in sent_tokenized]\n",
    "        ```\n",
    "        \n",
    "- Punctuation and stopword removal\n",
    "- lemmatization: convert inflected form of words into base form\n",
    "- stemming: chopping affixes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17 - Multi-class classification\n",
    "\n",
    "> **Apply classifiers to multi-class classification algorithms.**\n",
    "> \n",
    "1. **********************One vs Rest:********************** For each class, binary model separating it from all others (imbalanced) → scores from all binary classifiers determines winner\n",
    "    \n",
    "    ```python\n",
    "    lr = LogisticRegression(max_iter=2000, multi_class=\"ovr\")\n",
    "    ```\n",
    "    \n",
    "2. ********************One vs One:******************** binary model for each pair of classes, $\\frac{n\\times (n-1)}{2}$ binary classifiers → apply all classifiers, most votes wins\n",
    "- Wrappers for any binary classifier\n",
    "    - **`[OneVsRestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)`**\n",
    "    - **`[OneVsOneClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html)`**\n",
    "    \n",
    "    ```python\n",
    "    model = OneVsOneClassifier(LogisticRegression())\n",
    "    ```\n",
    "    \n",
    "\n",
    "> **Explain the role of neural networks in machine learning, and the pros/cons of using them.**\n",
    "> \n",
    "- ********************************Neural networks:******************************** sequence of transformations on input data\n",
    "- **Perceptron**: single layer neural network with input/output layer and adjustable weights\n",
    "- ********************************************************Multi Layer Perceptron (MLP)********************************************************: multi-layers of perceptrons\n",
    "    - layers can apply non-linear functions\n",
    "    - can specify number of features after each transormation\n",
    "\n",
    "********Pros********\n",
    "\n",
    "- Learn **complex** functions\n",
    "- tradeoff controlls by # layers & layer size\n",
    "- more/bigger layers → more complexity\n",
    "- can get **model that won’t underfit**\n",
    "- Works well for **structured** data\n",
    "    - 1D sequences (e.g. timeseries, language)\n",
    "    2D image\n",
    "    - 3D image or video\n",
    "- **Transfer** **learning** is useful\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- requires lots of **data**\n",
    "- requires high **compute time**, and GPUs to be faster\n",
    "- **huge** number of **hyperparameters** → difficult to tune\n",
    "    - each layer has hyperparameters + overall hyperparameters\n",
    "- **not interpretable**\n",
    "- `fit` **not** guaranteed to be **optimal**\n",
    "    - hyperparameters specific to `fit`\n",
    "    - don’t know if it was successful\n",
    "    - never know how long to run `fit`\n",
    "\n",
    "> **Explain why the methods we’ve learned previously would not be effective on image data.**\n",
    "> \n",
    "- Previous methods require flattening data for images into vector of features → ********************************************************************************removes structured information of images********************************************************************************\n",
    "- ********************************Convolutional neural networks (CNN):******************************** use images without flattening\n",
    "\n",
    "> **Apply pre-trained neural networks to classification and regression problems.**\n",
    "> \n",
    "\n",
    "```python\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "clf = vgg16(weights='VGG16_Weights.DEFAULT') \n",
    "preprocess = transforms.Compose([\n",
    "                 transforms.Resize(299),\n",
    "                 transforms.CenterCrop(299),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                     std=[0.229, 0.224, 0.225]),])\n",
    "\n",
    "img_t = preprocess(img)\n",
    "batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "clf.eval()\n",
    "  output = clf(batch_t)\n",
    "  _, indices = torch.sort(output, descending=True)\n",
    "  probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "  d = {'Class': [classes[idx] for idx in indices[0][:topn]], \n",
    "       'Probability score': [np.round(probabilities[0, idx].item(),3) for idx in indices[0][:topn]]}\n",
    "  df = pd.DataFrame(d, columns = ['Class','Probability score'])\n",
    "```\n",
    "\n",
    "> **Utilize pre-trained networks as feature extractors and combine them with models we’ve learned previously.**\n",
    "> \n",
    "\n",
    "```python\n",
    "# Attribution: [Code from PyTorch docs](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html?highlight=transfer%20learning)\n",
    "\n",
    "IMAGE_SIZE = 200\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            # transforms.RandomResizedCrop(224),\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),     \n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),            \n",
    "        ]\n",
    "    ),\n",
    "    \"valid\": transforms.Compose(\n",
    "        [\n",
    "            # transforms.Resize(256),\n",
    "            # transforms.CenterCrop(224),\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),                        \n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),                        \n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "data_dir = \"data/animal-faces\"\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in [\"train\", \"valid\"]\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [\"train\", \"valid\"]\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_features(model, train_loader, valid_loader):\n",
    "    \"\"\"Extract output of squeezenet model\"\"\"\n",
    "    with torch.no_grad():  # turn off computational graph stuff\n",
    "        Z_train = torch.empty((0, 1024))  # Initialize empty tensors\n",
    "        y_train = torch.empty((0))\n",
    "        Z_valid = torch.empty((0, 1024))\n",
    "        y_valid = torch.empty((0))\n",
    "        for X, y in train_loader:\n",
    "            Z_train = torch.cat((Z_train, model(X)), dim=0)\n",
    "            y_train = torch.cat((y_train, y))\n",
    "        for X, y in valid_loader:\n",
    "            Z_valid = torch.cat((Z_valid, model(X)), dim=0)\n",
    "            y_valid = torch.cat((y_valid, y))\n",
    "    return Z_train.detach(), y_train.detach(), Z_valid.detach(), y_valid.detach()\n",
    "\n",
    "densenet = models.densenet121(weights=\"DenseNet121_Weights.IMAGENET1K_V1\")\n",
    "densenet.classifier = nn.Identity()  # remove that last \"classification\" layer\n",
    "\n",
    "Z_train, y_train, Z_valid, y_valid = get_features(\n",
    "    densenet, dataloaders[\"train\"], dataloaders[\"valid\"]\n",
    ")\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000))\n",
    "pipe.fit(Z_train, y_train)\n",
    "pipe.score(Z_train, y_train)\n",
    "# 1.0\n",
    "pipe.score(Z_valid, y_valid)\n",
    "# 0.9\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18 - Time Series\n",
    "\n",
    "> **Recognize when it is appropriate to use time series.**\n",
    "> \n",
    "- Data indexed in time order\n",
    "\n",
    "> **Explain the pitfalls of train/test splitting with time series data.**\n",
    "> \n",
    "- cannot split randomly → ****************************************************************forecasting must not know future****************************************************************\n",
    "    - split by time threshold\n",
    "\n",
    "> **Appropriately split time series data, both train/test split and cross-validation.**\n",
    "> \n",
    "\n",
    "```python\n",
    "rain_df[\"Date\"].min()\n",
    "# Timestamp('2007-11-01 00:00:00')\n",
    "rain_df[\"Date\"].max()\n",
    "# Timestamp('2017-06-25 00:00:00')\n",
    "\n",
    "# then split by time in the middle\n",
    "```\n",
    "\n",
    "`TimeSeriesSplit` - sort dataframe by date for ********************************cross-validation********************************\n",
    "\n",
    "```python\n",
    "lr_pipe = make_pipeline(\n",
    "\tpreprocessor, \n",
    "\tLogisticRegression(max_iter=1000)\n",
    ")\n",
    "cross_val_score(\n",
    "\tlr_pipe, train_df_ordered, y_train_ordered, \n",
    "\tcv=TimeSeriesSplit()).mean()\n",
    ")\n",
    "```\n",
    "\n",
    "> **Perform time series feature engineering:**\n",
    "> \n",
    "\n",
    "> **Encode time as various features in a tabular dataset**\n",
    "> \n",
    "\n",
    "```python\n",
    "# Encodes days as number\n",
    "first_day = train_df[\"Date\"].min()\n",
    "\n",
    "train_df = train_df.assign(\n",
    "    Days_since=train_df[\"Date\"].apply(lambda x: (x - first_day).days)\n",
    ")\n",
    "# OHE of month\n",
    "train_df = train_df.assign(\n",
    "    Month=train_df[\"Date\"].apply(lambda x: x.month_name())\n",
    ")\n",
    "```\n",
    "\n",
    "> **Create lag-based features**\n",
    "> \n",
    "\n",
    "```python\n",
    "orig_feature = \"Rainfall\"\n",
    "lag = -1\n",
    "new_df = df.copy()\n",
    "new_feature_name = f\"{orig_feature}_lag{lag}\"\n",
    "\n",
    "# if there are multiple time series by category\n",
    "for location, df_location in new_df.groupby(\n",
    "        \"Location\"\n",
    "):  # Each location is its own time series\n",
    "  new_df.loc[df_location.index[-lag:], new_feature_name] = df_location.iloc[:lag][\n",
    "      orig_feature\n",
    "  ].values\n",
    "\n",
    "```\n",
    "\n",
    "> **Explain how can you forecast multiple time steps into the future.**\n",
    "> \n",
    "- Approaches to predict into future\n",
    "    1. Train separate model for ******************each time step******************\n",
    "        - e.g. predict next month, predict two months\n",
    "    2. multi-output model jointly predicting multiple time steps\n",
    "    3. One model predicts one time step, and uses it to predict next time step… `for` loop\n",
    "\n",
    "> **Explain the challenges of time series data with unequally spaced time points.**\n",
    "> \n",
    "- if unequally spaced\n",
    "    - can still do feature engineering\n",
    "    - lags would not make sense\n",
    "        - could group into equal bins\n",
    "\n",
    "> **At a high level, explain the concept of trend.**\n",
    "> \n",
    "- patterns that emerge over continuous time\n",
    "    - usually consistent upward/downward movement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19 - Survival Analysis\n",
    "\n",
    "> **Explain what is right-censored data.**\n",
    "> \n",
    "- his method suffers from *right-censoring* in which the method is biased towards the window of data collection\n",
    "    - data that isn’t fully captured within the window is biased as it is incomplete\n",
    "\n",
    "> **Explain the problem with treating right-censored data the same as “regular” data.**\n",
    "> \n",
    "- Not all the data points are complete, the end of data capture window is a cut-off\n",
    "    - data will tend to under-estimate\n",
    "\n",
    "> **Determine whether survival analysis is an appropriate tool for a given problem.**\n",
    "> \n",
    "- helps answer questions such as\n",
    "    1. how long customers stay\n",
    "    2. for customer, predict how long they may stay\n",
    "    3. factors influencing churn time\n",
    "\n",
    "> **Apply survival analysis in Python using the `lifelines` package.**\n",
    "> \n",
    "> \n",
    "> > **Interpret a survival curve, such as the Kaplan-Meier curve.**\n",
    "> > \n",
    "\n",
    "```python\n",
    "kmf = lifelines.KaplanMeierFitter()\n",
    "kmf.fit(train_df_surv[\"tenure\"], train_df_surv[\"Churn\"])\n",
    "kmf.survival_function_.plot();\n",
    "# or with error \n",
    "# kmf.plot();\n",
    "plt.title(\"Survival function of customer churn\")\n",
    "plt.xlabel(\"Time with service (months)\")\n",
    "plt.ylabel(\"Survival probability\");\n",
    "```\n",
    "\n",
    "- can look at KM curves for different groups\n",
    "    - e.g. market segments\n",
    "\n",
    "> **Interpret the coefficients of a fitted Cox proportional hazards model.**\n",
    "> \n",
    "- ************************************************************Cox proportional hazard model:************************************************************ interpret how features influence censor duration\n",
    "    - ****coefficient**** for each feature → influence on survival\n",
    "    - **************************************************************proportional hazards assumption**************************************************************\n",
    "\n",
    "```python\n",
    "cph = lifelines.CoxPHFitter(penalizer=0.1)\n",
    "cph.fit(train_df_surv, duration_col=\"tenure\", event_col=\"Churn\");\n",
    "\n",
    "cph_params = pd.DataFrame(cph.params_).sort_values(by=\"coef\", ascending=False)\n",
    "cph_params\n",
    "\n",
    "cph.summary\n",
    "\n",
    "# confidence intervals\n",
    "cph.plot();\n",
    "```\n",
    "\n",
    "> **Make predictions for existing individuals and interpret these predictions.**\n",
    "> \n",
    "\n",
    "```python\n",
    "cph.predict_expectation(test_df_surv)\n",
    "\n",
    "# survival function for individuals\n",
    "cph.predict_survival_function(test_df_surv).plot()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 - Ethics\n",
    "\n",
    "> **Sources of bias**\n",
    "> \n",
    "- ************Historical Bias:************ training data reflects biases/prejudices from past\n",
    "- **********************************Measurement Bias:********************************** data not accurately measured for intention\n",
    "- ****************************************Representation bias:**************************************** data doesn’t accurately represent population/phenomenon of interest\n",
    "\n",
    "> **Why algorithmic bias matter and how can it impacts us**\n",
    "> \n",
    "- marginalized groups\n",
    "- can emphasize existing biases/stereotypes/prejudice\n",
    "\n",
    "> **Different fairness metrics**\n",
    "> \n",
    "- ************************************demographic/statistical parity:************************************ population percentage reflected in output classes\n",
    "- **************************************Equality of False Negatives or equalized odds:************************************** constant-false-negative rates across groups\n",
    "- ************************************Equal opportunity:************************************ equal True Positive Rate for all groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21 - Communication\n",
    "\n",
    "> **When communicating about applied ML, tailor an explanation to the intended audience.**\n",
    "> \n",
    "\n",
    "> **Apply best practices of technical communication, such as bottom-up explanations and reader-centric writing.**\n",
    "> \n",
    "\n",
    "> **Given an ML problem, analyze the decision being made and the objectives.**\n",
    "> \n",
    "\n",
    "> **Avoid the pitfall of thinking about ML as coding in isolation; build the habit of relating your work to the surrounding context and stakeholders.**\n",
    "> \n",
    "\n",
    "> **Interpret a confidence score or credence, e.g. what does it mean to be 5% confident that a statement is true.**\n",
    "> \n",
    "- ****************************************credence in practice****************************************\n",
    "    1. ********************************************************************I would accept a bet at these odds********************************************************************\n",
    "        - e.g. 99% → to win 1, I would bet 99\n",
    "        - e.g. 75% → to win 25, I would bet 75\n",
    "    2. ********Long-run frequency of correctness********\n",
    "        - e.g. 99% → for every 100 predictions, I expect 1 to be incorrect\n",
    "        - e.g. 75% → for every 100 predictions, I expect 25 to be incorrect\n",
    "\n",
    "> **Maintain a healthy skepticism of `predict_proba` scores and their possible interpretation as credences.**\n",
    "> \n",
    "\n",
    "> **Be careful and precise when communicating confidence to stakeholders in an ML project.**\n",
    "> \n",
    "\n",
    "> **Identify misleading visualizations.**\n",
    "> \n",
    "- Things to watch out for\n",
    "    - Chopping off the x-axis\n",
    "    - Saturate the axes\n",
    "    - Bar chart for a cherry-picked values\n",
    "    - Different y-axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
