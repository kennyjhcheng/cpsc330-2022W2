{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics\n",
    "### Associated lectures: [Lectures 9, 10](https://ubc-cs.github.io/cpsc330/README.html) \n",
    "\n",
    "**Due date: Monday, Feb 27, 2023 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of predicting whether a patient has cancer or not. It is important to catch this disease early to reduce mortality rate; late diagnosis will result in metastasis to other organs, which adversely impacts patient's prognosis. Below are confusion matrices of two machine learning models: Model A and Model B. \n",
    "\n",
    "- Model A\n",
    "\n",
    "|         | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 48 | 32 |\n",
    "| **Actual no disease**       | 20 | 100 |\n",
    "\n",
    "\n",
    "- Model B\n",
    "\n",
    "|        | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 43 | 22 |\n",
    "| **Actual no disease**       | 35 | 100 |\n",
    "- \n",
    "|        | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | TP | FN |\n",
    "| **Actual no disease**       | FP | TN |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Because in the above problem, it is important to \"catch this disease early\", we are trying to spot patients ***with cancer***, and therefore the positive class is ***Predicted Disease***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A's accuracy: 0.74\n",
      "Model B's accuracy: 0.715\n"
     ]
    }
   ],
   "source": [
    "results_dict[\"A\"][\"accuracy\"] = (48 + 100) / (48 + 100 + 32 + 20)\n",
    "results_dict[\"B\"][\"accuracy\"] = (43 + 100) / (43 + 22 + 35 + 100)\n",
    "print(f'Model A\\'s accuracy: {results_dict[\"A\"][\"accuracy\"]}')\n",
    "print(f'Model B\\'s accuracy: {results_dict[\"B\"][\"accuracy\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Simply based on accuracy, I would pick ***Model A*** because the accuracy of its predictions is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without using `scikit-learn` tools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = 48/ (48 + 20)\n",
    "results_dict[\"B\"][\"precision\"] = 43 / (43 + 35)\n",
    "results_dict[\"A\"][\"recall\"] = 48 / (48 + 32)\n",
    "results_dict[\"B\"][\"recall\"] = 43 / (43 + 22)\n",
    "results_dict[\"A\"][\"f1\"] = 2 * (results_dict[\"A\"][\"precision\"] * results_dict[\"A\"][\"recall\"]) / (results_dict[\"A\"][\"precision\"] + results_dict[\"A\"][\"recall\"])\n",
    "results_dict[\"B\"][\"f1\"] = 2 * (results_dict[\"B\"][\"precision\"] * results_dict[\"B\"][\"recall\"]) / (results_dict[\"B\"][\"precision\"] + results_dict[\"B\"][\"recall\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.601399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.740000  0.715000\n",
       "precision  0.705882  0.551282\n",
       "recall     0.600000  0.661538\n",
       "f1         0.648649  0.601399"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Given the type of problem (early cancer diagnosis), which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Answer:** Given the type of problem is early cancer diagnosis, and it would be better for the patient to be predicted to have cancer and actually not have cancer (FP) rather than the opposite, recall would be the more informative metric. We want to identify as many people that actualy have cancer as possible.\n",
    "\n",
    "2. **Answer:** I would pick ***Model B*** based on this information for its higher recall score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1.6 \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Provide 2 to 3 example classification datasets (with links) where accuracy metric would be misleading. Discuss which evaluation metric would be more appropriate for each dataset. You may consider datasets we have used in this course so far. You could also look up datasets on Kaggle. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Random Sample of NIH Chest X-ray Dataset](https://www.kaggle.com/datasets/nih-chest-xrays/sample): Predicts disease classification based on chest x-ray. Imbalanced classes with a majority of x-rays having `No Finding` classification. A better evaluation metric may be recall since it would favor the patient to correctly identify disease.\n",
    "\n",
    "2. [EMNIST (Extended MNIST)](https://www.kaggle.com/datasets/crawford/emnist?select=emnist-byclass-train.csv): 28x28 pixel images mapping to handwritten characters. In the ByClass dataset, there is a significant imbalance towards lower value numerical characters. Precision of each character may be a better measurement than overall accuracy because a model being able to identify one character consistently, but not other (more infrequent) characters, may have a high accuracy, but poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis and we'll be talking about it later in the course. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>NE</td>\n",
       "      <td>70</td>\n",
       "      <td>415</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.4</td>\n",
       "      <td>86</td>\n",
       "      <td>36.28</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>17.40</td>\n",
       "      <td>256.6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>WI</td>\n",
       "      <td>67</td>\n",
       "      <td>510</td>\n",
       "      <td>417-2265</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>134</td>\n",
       "      <td>18.55</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>12.10</td>\n",
       "      <td>91.2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NJ</td>\n",
       "      <td>122</td>\n",
       "      <td>415</td>\n",
       "      <td>327-9341</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>34</td>\n",
       "      <td>146.4</td>\n",
       "      <td>104</td>\n",
       "      <td>24.89</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>7.62</td>\n",
       "      <td>220.0</td>\n",
       "      <td>91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NV</td>\n",
       "      <td>107</td>\n",
       "      <td>510</td>\n",
       "      <td>419-9688</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>234.1</td>\n",
       "      <td>91</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>13.86</td>\n",
       "      <td>282.5</td>\n",
       "      <td>100</td>\n",
       "      <td>12.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>HI</td>\n",
       "      <td>105</td>\n",
       "      <td>510</td>\n",
       "      <td>364-8128</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>116</td>\n",
       "      <td>21.32</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>22.23</td>\n",
       "      <td>241.6</td>\n",
       "      <td>104</td>\n",
       "      <td>10.87</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>WY</td>\n",
       "      <td>126</td>\n",
       "      <td>408</td>\n",
       "      <td>339-9798</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>126</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.95</td>\n",
       "      <td>285.3</td>\n",
       "      <td>104</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>WV</td>\n",
       "      <td>70</td>\n",
       "      <td>510</td>\n",
       "      <td>348-3777</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>143.4</td>\n",
       "      <td>72</td>\n",
       "      <td>24.38</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.45</td>\n",
       "      <td>127.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5.76</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>NJ</td>\n",
       "      <td>125</td>\n",
       "      <td>415</td>\n",
       "      <td>406-6400</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>182.3</td>\n",
       "      <td>64</td>\n",
       "      <td>30.99</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>11.88</td>\n",
       "      <td>171.6</td>\n",
       "      <td>96</td>\n",
       "      <td>7.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NE</td>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>189.1</td>\n",
       "      <td>105</td>\n",
       "      <td>32.15</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>20.92</td>\n",
       "      <td>242.0</td>\n",
       "      <td>106</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>PA</td>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>403-9167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>45</td>\n",
       "      <td>22.73</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>15.96</td>\n",
       "      <td>181.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number international plan  \\\n",
       "1402    NE              70        415     421-8535                 no   \n",
       "1855    WI              67        510     417-2265                 no   \n",
       "633     NJ             122        415     327-9341                 no   \n",
       "1483    NV             107        510     419-9688                yes   \n",
       "2638    HI             105        510     364-8128                 no   \n",
       "...    ...             ...        ...          ...                ...   \n",
       "2154    WY             126        408     339-9798                yes   \n",
       "3089    WV              70        510     348-3777                 no   \n",
       "1766    NJ             125        415     406-6400                 no   \n",
       "1122    NE             159        415     362-5111                 no   \n",
       "1346    PA             106        408     403-9167                yes   \n",
       "\n",
       "     voice mail plan  number vmail messages  total day minutes  \\\n",
       "1402              no                      0              213.4   \n",
       "1855              no                      0              109.1   \n",
       "633              yes                     34              146.4   \n",
       "1483              no                      0              234.1   \n",
       "2638              no                      0              125.4   \n",
       "...              ...                    ...                ...   \n",
       "2154              no                      0              197.6   \n",
       "3089             yes                     30              143.4   \n",
       "1766              no                      0              182.3   \n",
       "1122              no                      0              189.1   \n",
       "1346              no                      0              133.7   \n",
       "\n",
       "      total day calls  total day charge  ...  total eve calls  \\\n",
       "1402               86             36.28  ...               77   \n",
       "1855              134             18.55  ...               76   \n",
       "633               104             24.89  ...              103   \n",
       "1483               91             39.80  ...              105   \n",
       "2638              116             21.32  ...               95   \n",
       "...               ...               ...  ...              ...   \n",
       "2154              126             33.59  ...              112   \n",
       "3089               72             24.38  ...               92   \n",
       "1766               64             30.99  ...              121   \n",
       "1122              105             32.15  ...              147   \n",
       "1346               45             22.73  ...              107   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402             17.40                256.6                101   \n",
       "1855             12.10                 91.2                 86   \n",
       "633               7.62                220.0                 91   \n",
       "1483             13.86                282.5                100   \n",
       "2638             22.23                241.6                104   \n",
       "...                ...                  ...                ...   \n",
       "2154             20.95                285.3                104   \n",
       "3089             14.45                127.9                 68   \n",
       "1766             11.88                171.6                 96   \n",
       "1122             20.92                242.0                106   \n",
       "1346             15.96                181.9                 89   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402               11.55                 5.7                 4   \n",
       "1855                4.10                10.9                 5   \n",
       "633                 9.90                15.6                 4   \n",
       "1483               12.71                10.0                 3   \n",
       "2638               10.87                11.4                 9   \n",
       "...                  ...                 ...               ...   \n",
       "2154               12.84                12.5                 8   \n",
       "3089                5.76                 9.4                 4   \n",
       "1766                7.72                11.6                 7   \n",
       "1122               10.89                10.4                 5   \n",
       "1346                8.19                10.7                 2   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "1402               1.54                       1  False  \n",
       "1855               2.94                       2  False  \n",
       "633                4.21                       2  False  \n",
       "1483               2.70                       1  False  \n",
       "2638               3.08                       2  False  \n",
       "...                 ...                     ...    ...  \n",
       "2154               3.38                       2  False  \n",
       "3089               2.54                       3  False  \n",
       "1766               3.13                       2  False  \n",
       "1122               2.81                       1   True  \n",
       "1346               2.89                       1   True  \n",
       "\n",
       "[2333 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split. Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    ">  `churn` is a binary class with  `False` in $1984/2333$ examples. It is also our target class.\n",
    "\n",
    "We need to deal with these class imbalances such as to not overemphasize certain target classes. This is especially important since the `churn` class has an imbalance towards `False`, while the `True` prediction may be more significant since we would like to find cases in which customers <ins>left</ins> the subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2333</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333</td>\n",
       "      <td>2333</td>\n",
       "      <td>2333</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>WV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2106</td>\n",
       "      <td>1695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.434634</td>\n",
       "      <td>436.324046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.028290</td>\n",
       "      <td>179.655679</td>\n",
       "      <td>100.567081</td>\n",
       "      <td>30.542015</td>\n",
       "      <td>201.175782</td>\n",
       "      <td>99.885555</td>\n",
       "      <td>17.100210</td>\n",
       "      <td>201.211745</td>\n",
       "      <td>99.988856</td>\n",
       "      <td>9.054591</td>\n",
       "      <td>10.269567</td>\n",
       "      <td>4.503215</td>\n",
       "      <td>2.773365</td>\n",
       "      <td>1.551650</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39.642470</td>\n",
       "      <td>41.854200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.665229</td>\n",
       "      <td>54.546284</td>\n",
       "      <td>20.202414</td>\n",
       "      <td>9.272847</td>\n",
       "      <td>50.449386</td>\n",
       "      <td>19.788878</td>\n",
       "      <td>4.288194</td>\n",
       "      <td>50.888058</td>\n",
       "      <td>19.406455</td>\n",
       "      <td>2.290012</td>\n",
       "      <td>2.777601</td>\n",
       "      <td>2.507555</td>\n",
       "      <td>0.749929</td>\n",
       "      <td>1.328702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.400000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.380000</td>\n",
       "      <td>167.300000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>14.220000</td>\n",
       "      <td>166.900000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.510000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.200000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>30.460000</td>\n",
       "      <td>202.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>201.600000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.070000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>216.300000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>36.770000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>20.060000</td>\n",
       "      <td>236.600000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>350.800000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>59.640000</td>\n",
       "      <td>354.200000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>30.110000</td>\n",
       "      <td>377.500000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>16.990000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  account length    area code phone number international plan  \\\n",
       "count   2333     2333.000000  2333.000000         2333               2333   \n",
       "unique    51             NaN          NaN         2333                  2   \n",
       "top       WV             NaN          NaN     421-8535                 no   \n",
       "freq      70             NaN          NaN            1               2106   \n",
       "mean     NaN      100.434634   436.324046          NaN                NaN   \n",
       "std      NaN       39.642470    41.854200          NaN                NaN   \n",
       "min      NaN        1.000000   408.000000          NaN                NaN   \n",
       "25%      NaN       73.000000   408.000000          NaN                NaN   \n",
       "50%      NaN      100.000000   415.000000          NaN                NaN   \n",
       "75%      NaN      127.000000   415.000000          NaN                NaN   \n",
       "max      NaN      243.000000   510.000000          NaN                NaN   \n",
       "\n",
       "       voice mail plan  number vmail messages  total day minutes  \\\n",
       "count             2333            2333.000000        2333.000000   \n",
       "unique               2                    NaN                NaN   \n",
       "top                 no                    NaN                NaN   \n",
       "freq              1695                    NaN                NaN   \n",
       "mean               NaN               8.028290         179.655679   \n",
       "std                NaN              13.665229          54.546284   \n",
       "min                NaN               0.000000           0.000000   \n",
       "25%                NaN               0.000000         143.400000   \n",
       "50%                NaN               0.000000         179.200000   \n",
       "75%                NaN              19.000000         216.300000   \n",
       "max                NaN              51.000000         350.800000   \n",
       "\n",
       "        total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "count       2333.000000       2333.000000        2333.000000      2333.000000   \n",
       "unique              NaN               NaN                NaN              NaN   \n",
       "top                 NaN               NaN                NaN              NaN   \n",
       "freq                NaN               NaN                NaN              NaN   \n",
       "mean         100.567081         30.542015         201.175782        99.885555   \n",
       "std           20.202414          9.272847          50.449386        19.788878   \n",
       "min            0.000000          0.000000           0.000000         0.000000   \n",
       "25%           87.000000         24.380000         167.300000        87.000000   \n",
       "50%          101.000000         30.460000         202.400000       100.000000   \n",
       "75%          114.000000         36.770000         236.000000       113.000000   \n",
       "max          165.000000         59.640000         354.200000       168.000000   \n",
       "\n",
       "        total eve charge  total night minutes  total night calls  \\\n",
       "count        2333.000000          2333.000000        2333.000000   \n",
       "unique               NaN                  NaN                NaN   \n",
       "top                  NaN                  NaN                NaN   \n",
       "freq                 NaN                  NaN                NaN   \n",
       "mean           17.100210           201.211745          99.988856   \n",
       "std             4.288194            50.888058          19.406455   \n",
       "min             0.000000            23.200000          33.000000   \n",
       "25%            14.220000           166.900000          87.000000   \n",
       "50%            17.200000           201.600000         100.000000   \n",
       "75%            20.060000           236.600000         113.000000   \n",
       "max            30.110000           377.500000         164.000000   \n",
       "\n",
       "        total night charge  total intl minutes  total intl calls  \\\n",
       "count          2333.000000         2333.000000       2333.000000   \n",
       "unique                 NaN                 NaN               NaN   \n",
       "top                    NaN                 NaN               NaN   \n",
       "freq                   NaN                 NaN               NaN   \n",
       "mean              9.054591           10.269567          4.503215   \n",
       "std               2.290012            2.777601          2.507555   \n",
       "min               1.040000            0.000000          0.000000   \n",
       "25%               7.510000            8.500000          3.000000   \n",
       "50%               9.070000           10.400000          4.000000   \n",
       "75%              10.650000           12.100000          6.000000   \n",
       "max              16.990000           20.000000         20.000000   \n",
       "\n",
       "        total intl charge  customer service calls  churn  \n",
       "count         2333.000000             2333.000000   2333  \n",
       "unique                NaN                     NaN      2  \n",
       "top                   NaN                     NaN  False  \n",
       "freq                  NaN                     NaN   1984  \n",
       "mean             2.773365                1.551650    NaN  \n",
       "std              0.749929                1.328702    NaN  \n",
       "min              0.000000                0.000000    NaN  \n",
       "25%              2.300000                1.000000    NaN  \n",
       "50%              2.810000                1.000000    NaN  \n",
       "75%              3.270000                2.000000    NaN  \n",
       "max              5.400000                9.000000    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2333, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2333 entries, 1402 to 1346\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   2333 non-null   object \n",
      " 1   account length          2333 non-null   int64  \n",
      " 2   area code               2333 non-null   int64  \n",
      " 3   phone number            2333 non-null   object \n",
      " 4   international plan      2333 non-null   object \n",
      " 5   voice mail plan         2333 non-null   object \n",
      " 6   number vmail messages   2333 non-null   int64  \n",
      " 7   total day minutes       2333 non-null   float64\n",
      " 8   total day calls         2333 non-null   int64  \n",
      " 9   total day charge        2333 non-null   float64\n",
      " 10  total eve minutes       2333 non-null   float64\n",
      " 11  total eve calls         2333 non-null   int64  \n",
      " 12  total eve charge        2333 non-null   float64\n",
      " 13  total night minutes     2333 non-null   float64\n",
      " 14  total night calls       2333 non-null   int64  \n",
      " 15  total night charge      2333 non-null   float64\n",
      " 16  total intl minutes      2333 non-null   float64\n",
      " 17  total intl calls        2333 non-null   int64  \n",
      " 18  total intl charge       2333 non-null   float64\n",
      " 19  customer service calls  2333 non-null   int64  \n",
      " 20  churn                   2333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 385.0+ KB\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 2.2 EDA \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Come up with **two** exploratory questions you would like to answer and explore those. Briefly discuss your results in 1-3 sentences.\n",
    "\n",
    "You are welcome to use `pandas_profiling` (see Lecture 10) but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** Two exploratory questions\n",
    "1. Are there any numeric-looking columns that aren't actually numeric? \n",
    "    - `area code` seems to be a categorical feature related to the location that the phone number is from.\n",
    "    - `customer service calls` seemed to possibly be an ordinal feature at first because it only had values from 0-9, however, judging by the name and the context, it is probably the number of customer service calls that a customer received, which at max, is 9. So this is actually a numeric feature.\n",
    "2. Are there any ordinal features?\n",
    "    - There doesn't seem to be any ordinal features of all the categorical features, although there are several binary categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['account length', 'area code', 'number vmail messages', 'total day minutes', 'total day calls', 'total day charge', 'total eve minutes', 'total eve calls', 'total eve charge', 'total night minutes', 'total night calls', 'total night charge', 'total intl minutes', 'total intl calls', 'total intl charge', 'customer service calls']\n",
      "{'state', 'churn', 'phone number', 'voice mail plan', 'international plan'}\n"
     ]
    }
   ],
   "source": [
    "numeric_looking_columns = train_df.select_dtypes(include=np.number).columns.tolist()\n",
    "non_numeric_looking_cols = set(train_df.columns.tolist()) - set(numeric_looking_columns)\n",
    "print(numeric_looking_columns)\n",
    "print(non_numeric_looking_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account length             205\n",
      "area code                    3\n",
      "number vmail messages       45\n",
      "total day minutes         1402\n",
      "total day calls            115\n",
      "total day charge          1402\n",
      "total eve minutes         1337\n",
      "total eve calls            115\n",
      "total eve charge          1215\n",
      "total night minutes       1360\n",
      "total night calls          111\n",
      "total night charge         852\n",
      "total intl minutes         154\n",
      "total intl calls            21\n",
      "total intl charge          154\n",
      "customer service calls      10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df[numeric_looking_columns].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique area code: [415 510 408]\n",
      "unique customer service calls: [1 2 0 5 3 4 8 6 7 9]\n"
     ]
    }
   ],
   "source": [
    "possible_categorical_numeric_looking_cols = ['area code', 'customer service calls']\n",
    "for n in possible_categorical_numeric_looking_cols:\n",
    "    print(f'unique {n}: {train_df[n].unique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state                   51\n",
      "churn                    2\n",
      "phone number          2333\n",
      "voice mail plan          2\n",
      "international plan       2\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7z/3s70y8y14bg5pg8xh_qrpctr0000gn/T/ipykernel_6499/1962911450.py:1: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  print(train_df[non_numeric_looking_cols].nunique())\n"
     ]
    }
   ],
   "source": [
    "print(train_df[non_numeric_looking_cols].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique international plan: ['no' 'yes']\n",
      "unique voice mail plan: ['no' 'yes']\n",
      "unique churn: [False  True]\n"
     ]
    }
   ],
   "source": [
    "for n in ['international plan', 'voice mail plan', 'churn']:\n",
    "    print(f'unique {n}: {train_df[n].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Column transformer \n",
    "rubric={points:14}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "For each group of features (e.g. numeric, categorical or else) explain why you are applying the particular transformation. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc.\n",
    "\n",
    "Finally, fit `ColumnTransformer` on your training set; and use the `ColumnTransformer` to transform your train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** In my EDA, I did not find that any columns were missing values (i.e. they all had $2333$ counts), so I will not be using imputation.\n",
    "\n",
    "- **DROP:** I have decided to drop the `phone number` column. Because phone number is categorical and is different for every customer, there will not be useful patterns found by training a model using it. Although `area code` relates to the phone number, I did not drop it because it is specific to location that may be different than `state`.\n",
    "\n",
    "- **NUMERIC:** I will be scaling all numerical features because by standardizing their values, numeric features that have larger values won't influence models that are scale-sensitive.\n",
    "\n",
    "- **CATEGORICAL:** I will be applying one-hot encoding to categorical features to represent them numerically for models that require numerical representation for predictor features. \n",
    "    - Additionally, I will be using the options `handle_unknown=ignore` for cases such as in cross-validation if there is a class that is split entirely in the validation set, and not trained on, errors do not occur. \n",
    "    - Finally I will pass the `drop=if_binary` option so that binary categorical features are represented using one numeric column rather than two.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'account length', 'number vmail messages', 'total day minutes', \n",
    "    'total day calls', 'total day charge', 'total eve minutes', 'total eve calls', \n",
    "    'total eve charge', 'total night minutes', 'total night calls', 'total night charge', \n",
    "    'total intl minutes', 'total intl calls', 'total intl charge', 'customer service calls'\n",
    "]\n",
    "\n",
    "categorical_non_binary_features = [\n",
    "    'state', 'area code'\n",
    "]\n",
    "\n",
    "categorical_binary_features = [\n",
    "    'international plan', 'voice mail plan'\n",
    "]\n",
    "\n",
    "categorical_features = categorical_non_binary_features + categorical_binary_features\n",
    "\n",
    "drop_features = [\n",
    "    'phone number'\n",
    "]\n",
    "\n",
    "assert(20 == len(numeric_features) + len(categorical_features) + len(drop_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False, drop=\"if_binary\"),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\"drop\", drop_features),\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;drop&#x27;, &#x27;drop&#x27;, [&#x27;phone number&#x27;]),\n",
       "                                (&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;account length&#x27;, &#x27;number vmail messages&#x27;,\n",
       "                                  &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;,\n",
       "                                  &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;,\n",
       "                                  &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;,\n",
       "                                  &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;,\n",
       "                                  &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;,\n",
       "                                  &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;,\n",
       "                                  &#x27;customer service calls&#x27;]),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 [&#x27;state&#x27;, &#x27;area code&#x27;, &#x27;international plan&#x27;,\n",
       "                                  &#x27;voice mail plan&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;drop&#x27;, &#x27;drop&#x27;, [&#x27;phone number&#x27;]),\n",
       "                                (&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;account length&#x27;, &#x27;number vmail messages&#x27;,\n",
       "                                  &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;,\n",
       "                                  &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;,\n",
       "                                  &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;,\n",
       "                                  &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;,\n",
       "                                  &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;,\n",
       "                                  &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;,\n",
       "                                  &#x27;customer service calls&#x27;]),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 [&#x27;state&#x27;, &#x27;area code&#x27;, &#x27;international plan&#x27;,\n",
       "                                  &#x27;voice mail plan&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>[&#x27;phone number&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-1</label><div class=\"sk-toggleable__content\"><pre>[&#x27;account length&#x27;, &#x27;number vmail messages&#x27;, &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;, &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;, &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;, &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;, &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;, &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;, &#x27;customer service calls&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-2</label><div class=\"sk-toggleable__content\"><pre>[&#x27;state&#x27;, &#x27;area code&#x27;, &#x27;international plan&#x27;, &#x27;voice mail plan&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('drop', 'drop', ['phone number']),\n",
       "                                ('pipeline-1',\n",
       "                                 Pipeline(steps=[('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['account length', 'number vmail messages',\n",
       "                                  'total day minutes', 'total day calls',\n",
       "                                  'total day charge', 'total eve minutes',\n",
       "                                  'total eve calls', 'total eve charge',\n",
       "                                  'total night minutes', 'total night calls',\n",
       "                                  'total night charge', 'total intl minutes',\n",
       "                                  'total intl calls', 'total intl charge',\n",
       "                                  'customer service calls']),\n",
       "                                ('pipeline-2',\n",
       "                                 Pipeline(steps=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='if_binary',\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                sparse=False))]),\n",
       "                                 ['state', 'area code', 'international plan',\n",
       "                                  'voice mail plan'])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drop': 'drop',\n",
       " 'pipeline-1': Pipeline(steps=[('standardscaler', StandardScaler())]),\n",
       " 'pipeline-2': Pipeline(steps=[('onehotencoder',\n",
       "                  OneHotEncoder(drop='if_binary', handle_unknown='ignore',\n",
       "                                sparse=False))])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Lecture 10\n",
    "# get the new list of columns after preprocessing\n",
    "ohe_columns = list(\n",
    "    preprocessor.named_transformers_[\"pipeline-2\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names_out(categorical_features)\n",
    ")\n",
    "\n",
    "new_columns = numeric_features + ohe_columns\n",
    "\n",
    "# create transformed training set\n",
    "X_train_enc = pd.DataFrame(\n",
    "    preprocessor.transform(X_train), index=X_train.index, columns=new_columns\n",
    ")\n",
    "# create transformed testing set\n",
    "X_test_enc = pd.DataFrame(\n",
    "    preprocessor.transform(X_test), index=X_test.index, columns=new_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>state_AK</th>\n",
       "      <th>state_AL</th>\n",
       "      <th>state_AR</th>\n",
       "      <th>state_AZ</th>\n",
       "      <th>state_CA</th>\n",
       "      <th>state_CO</th>\n",
       "      <th>state_CT</th>\n",
       "      <th>state_DC</th>\n",
       "      <th>state_DE</th>\n",
       "      <th>state_FL</th>\n",
       "      <th>state_GA</th>\n",
       "      <th>state_HI</th>\n",
       "      <th>state_IA</th>\n",
       "      <th>state_ID</th>\n",
       "      <th>state_IL</th>\n",
       "      <th>state_IN</th>\n",
       "      <th>state_KS</th>\n",
       "      <th>state_KY</th>\n",
       "      <th>state_LA</th>\n",
       "      <th>state_MA</th>\n",
       "      <th>state_MD</th>\n",
       "      <th>state_ME</th>\n",
       "      <th>state_MI</th>\n",
       "      <th>state_MN</th>\n",
       "      <th>state_MO</th>\n",
       "      <th>state_MS</th>\n",
       "      <th>state_MT</th>\n",
       "      <th>state_NC</th>\n",
       "      <th>state_ND</th>\n",
       "      <th>state_NE</th>\n",
       "      <th>state_NH</th>\n",
       "      <th>state_NJ</th>\n",
       "      <th>state_NM</th>\n",
       "      <th>state_NV</th>\n",
       "      <th>state_NY</th>\n",
       "      <th>state_OH</th>\n",
       "      <th>state_OK</th>\n",
       "      <th>state_OR</th>\n",
       "      <th>state_PA</th>\n",
       "      <th>state_RI</th>\n",
       "      <th>state_SC</th>\n",
       "      <th>state_SD</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>area code_408</th>\n",
       "      <th>area code_415</th>\n",
       "      <th>area code_510</th>\n",
       "      <th>international plan_yes</th>\n",
       "      <th>voice mail plan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>-0.767893</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.618769</td>\n",
       "      <td>-0.721211</td>\n",
       "      <td>0.618927</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>-1.156734</td>\n",
       "      <td>0.069926</td>\n",
       "      <td>1.088667</td>\n",
       "      <td>0.052115</td>\n",
       "      <td>1.089926</td>\n",
       "      <td>-1.645501</td>\n",
       "      <td>-0.200722</td>\n",
       "      <td>-1.644994</td>\n",
       "      <td>-0.415269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>-0.843585</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-1.293778</td>\n",
       "      <td>1.655252</td>\n",
       "      <td>-1.293517</td>\n",
       "      <td>-1.167277</td>\n",
       "      <td>-1.207278</td>\n",
       "      <td>-1.166291</td>\n",
       "      <td>-2.162302</td>\n",
       "      <td>-0.720990</td>\n",
       "      <td>-2.164029</td>\n",
       "      <td>0.227019</td>\n",
       "      <td>0.198158</td>\n",
       "      <td>0.222249</td>\n",
       "      <td>0.337507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.544113</td>\n",
       "      <td>1.900976</td>\n",
       "      <td>-0.609809</td>\n",
       "      <td>0.169963</td>\n",
       "      <td>-0.609654</td>\n",
       "      <td>-2.210130</td>\n",
       "      <td>0.157417</td>\n",
       "      <td>-2.211244</td>\n",
       "      <td>0.369287</td>\n",
       "      <td>-0.463288</td>\n",
       "      <td>0.369252</td>\n",
       "      <td>1.919489</td>\n",
       "      <td>-0.200722</td>\n",
       "      <td>1.916105</td>\n",
       "      <td>0.337507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>0.165650</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.998345</td>\n",
       "      <td>-0.473663</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>-0.754894</td>\n",
       "      <td>0.258506</td>\n",
       "      <td>-0.755774</td>\n",
       "      <td>1.597736</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>1.596582</td>\n",
       "      <td>-0.097071</td>\n",
       "      <td>-0.599603</td>\n",
       "      <td>-0.097850</td>\n",
       "      <td>-0.415269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>0.115188</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-0.994886</td>\n",
       "      <td>0.764078</td>\n",
       "      <td>-0.994731</td>\n",
       "      <td>1.195994</td>\n",
       "      <td>-0.246937</td>\n",
       "      <td>1.196515</td>\n",
       "      <td>0.793839</td>\n",
       "      <td>0.206736</td>\n",
       "      <td>0.792921</td>\n",
       "      <td>0.407069</td>\n",
       "      <td>1.793679</td>\n",
       "      <td>0.408973</td>\n",
       "      <td>0.337507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      account length  number vmail messages  total day minutes  \\\n",
       "1402       -0.767893              -0.587624           0.618769   \n",
       "1855       -0.843585              -0.587624          -1.293778   \n",
       "633         0.544113               1.900976          -0.609809   \n",
       "1483        0.165650              -0.587624           0.998345   \n",
       "2638        0.115188              -0.587624          -0.994886   \n",
       "\n",
       "      total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "1402        -0.721211          0.618927           0.069871        -1.156734   \n",
       "1855         1.655252         -1.293517          -1.167277        -1.207278   \n",
       "633          0.169963         -0.609654          -2.210130         0.157417   \n",
       "1483        -0.473663          0.998611          -0.754894         0.258506   \n",
       "2638         0.764078         -0.994731           1.195994        -0.246937   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402          0.069926             1.088667           0.052115   \n",
       "1855         -1.166291            -2.162302          -0.720990   \n",
       "633          -2.211244             0.369287          -0.463288   \n",
       "1483         -0.755774             1.597736           0.000574   \n",
       "2638          1.196515             0.793839           0.206736   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402            1.089926           -1.645501         -0.200722   \n",
       "1855           -2.164029            0.227019          0.198158   \n",
       "633             0.369252            1.919489         -0.200722   \n",
       "1483            1.596582           -0.097071         -0.599603   \n",
       "2638            0.792921            0.407069          1.793679   \n",
       "\n",
       "      total intl charge  customer service calls  state_AK  state_AL  state_AR  \\\n",
       "1402          -1.644994               -0.415269       0.0       0.0       0.0   \n",
       "1855           0.222249                0.337507       0.0       0.0       0.0   \n",
       "633            1.916105                0.337507       0.0       0.0       0.0   \n",
       "1483          -0.097850               -0.415269       0.0       0.0       0.0   \n",
       "2638           0.408973                0.337507       0.0       0.0       0.0   \n",
       "\n",
       "      state_AZ  state_CA  state_CO  state_CT  state_DC  state_DE  state_FL  \\\n",
       "1402       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1855       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "633        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1483       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2638       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_GA  state_HI  state_IA  state_ID  state_IL  state_IN  state_KS  \\\n",
       "1402       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1855       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "633        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1483       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2638       0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_KY  state_LA  state_MA  state_MD  state_ME  state_MI  state_MN  \\\n",
       "1402       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1855       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "633        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1483       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2638       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_MO  state_MS  state_MT  state_NC  state_ND  state_NE  state_NH  \\\n",
       "1402       0.0       0.0       0.0       0.0       0.0       1.0       0.0   \n",
       "1855       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "633        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1483       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2638       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_NJ  state_NM  state_NV  state_NY  state_OH  state_OK  state_OR  \\\n",
       "1402       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1855       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "633        1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1483       0.0       0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "2638       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_PA  state_RI  state_SC  state_SD  state_TN  state_TX  state_UT  \\\n",
       "1402       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1855       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "633        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1483       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2638       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_VA  state_VT  state_WA  state_WI  state_WV  state_WY  \\\n",
       "1402       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1855       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "633        0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1483       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2638       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      area code_408  area code_415  area code_510  international plan_yes  \\\n",
       "1402            0.0            1.0            0.0                     0.0   \n",
       "1855            0.0            0.0            1.0                     0.0   \n",
       "633             0.0            1.0            0.0                     0.0   \n",
       "1483            0.0            0.0            1.0                     1.0   \n",
       "2638            0.0            0.0            1.0                     0.0   \n",
       "\n",
       "      voice mail plan_yes  \n",
       "1402                  0.0  \n",
       "1855                  0.0  \n",
       "633                   1.0  \n",
       "1483                  0.0  \n",
       "2638                  0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 area code feature\n",
    "rubric={points:4}\n",
    "\n",
    "The original dataset had a feature called `area code`.\n",
    "\n",
    "1. The area codes are numbers. Does it make sense to encode them as one-hot-endoded (OHE) or not? Please justify your response.\n",
    "2. What were the possible values of `area code`? \n",
    "3. If area code is encoded with OHE, how many new features are created to replace it?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "1. `area code` makes sense to be encoded using OHE, as it provides location information that is different than the `state` feature and isn't unique to each example like the `phone number` feature. There are discrete, finite categories of the `area code` feature such that each example is classified into one of them, therefore it can be considered a categorical feature.\n",
    "2. There are 3 possible values of `area code = {415, 510, 408}`\n",
    "3. Because there are 3 possible values of `area code`, the OHE of the feature will create 3 columns to replace it: `area code_415`, `area code_510`, `area code_408`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Logistic regression\n",
    "rubric={points:12} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Report the cross-validation results of a `LogisticRegression` model, with default Hparams, on the following metrics: `\"accuracy\", \"precision\", \"recall\", \"f1\"`\n",
    "2. Are you satisfied with the results? Explain why or why not. Discuss in a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026966</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.869379</td>\n",
       "      <td>0.864416</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.332454</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018294</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.852248</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.362694</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.250896</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.654206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.867095</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.364103</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.254480</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.639640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013851</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.869099</td>\n",
       "      <td>0.863953</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.345361</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.239286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014914</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.839056</td>\n",
       "      <td>0.868773</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.373402</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.261649</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.026966    0.003187       0.869379        0.864416  0.371134  0.332454   \n",
       "1  0.018294    0.003801       0.852248        0.868167  0.273684  0.362694   \n",
       "2  0.016614    0.003366       0.850107        0.867095  0.255319  0.364103   \n",
       "3  0.013851    0.003115       0.869099        0.863953  0.371134  0.345361   \n",
       "4  0.014914    0.003194       0.839056        0.868773  0.242424  0.373402   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.257143      0.225806        0.666667         0.630000  \n",
       "1     0.185714      0.250896        0.520000         0.654206  \n",
       "2     0.171429      0.254480        0.500000         0.639640  \n",
       "3     0.260870      0.239286        0.642857         0.620370  \n",
       "4     0.171429      0.261649        0.413793         0.651786  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = [\n",
    "    \"accuracy\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "]\n",
    "\n",
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression())\n",
    "scores = cross_validate(\n",
    "    pipe_lr, X_train, y_train, return_train_score=True, scoring=scoring\n",
    ")\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.018128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <td>0.855978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <td>0.866481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_f1</th>\n",
       "      <td>0.302739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_f1</th>\n",
       "      <td>0.355603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_recall</th>\n",
       "      <td>0.209317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_recall</th>\n",
       "      <td>0.246423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_precision</th>\n",
       "      <td>0.548663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_precision</th>\n",
       "      <td>0.639200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "mean_fit_time         0.018128\n",
       "mean_score_time       0.003333\n",
       "mean_test_accuracy    0.855978\n",
       "mean_train_accuracy   0.866481\n",
       "mean_test_f1          0.302739\n",
       "mean_train_f1         0.355603\n",
       "mean_test_recall      0.209317\n",
       "mean_train_recall     0.246423\n",
       "mean_test_precision   0.548663\n",
       "mean_train_precision  0.639200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dict = {\n",
    "    \"mean_fit_time\": [scores[\"fit_time\"].mean()],\n",
    "    \"mean_score_time\": [scores[\"score_time\"].mean()],\n",
    "    \"mean_test_accuracy\": [scores[\"test_accuracy\"].mean()],\n",
    "    \"mean_train_accuracy\": [scores[\"train_accuracy\"].mean()],\n",
    "    \"mean_test_f1\": [scores[\"test_f1\"].mean()],\n",
    "    \"mean_train_f1\": [scores[\"train_f1\"].mean()],\n",
    "    \"mean_test_recall\": [scores[\"test_recall\"].mean()],\n",
    "    \"mean_train_recall\": [scores[\"train_recall\"].mean()],\n",
    "    \"mean_test_precision\": [scores[\"test_precision\"].mean()],\n",
    "    \"mean_train_precision\": [scores[\"train_precision\"].mean()]\n",
    "}\n",
    "pd.DataFrame(scores_dict).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pipe_lr.fit(X_train, y_train)\n",
    "model.classes_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "2. I am not satisfied with the results of `LogisticRegression` using default HParams due to the low `f1 score` and low `recall`. Although the result achieves high accuracy, most likely due to correctly classifying many non-churn customers, it does not perform well classifying churned customers which is revealed despite the class balance by the `recall` and `f1 score`. A mean validation recall of `0.209` means that only $20.9\\%$ of churned customers were correctly identified by the model. Additionally, the `f1 score` is proportional to the `recall` which is also quite low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Logistic regression with `class_weight`\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences while comparing the metrics of this model and the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.785867</td>\n",
       "      <td>0.769561</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.497664</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.369151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030239</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.768737</td>\n",
       "      <td>0.771168</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.372852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.764454</td>\n",
       "      <td>0.774384</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.511034</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.788530</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.378007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026326</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.779325</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.517564</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.789286</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.385017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029974</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.786824</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.531765</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.810036</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.395797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.021760    0.003383       0.785867        0.769561  0.489796  0.497664   \n",
       "1  0.030239    0.004820       0.768737        0.771168  0.490566  0.504065   \n",
       "2  0.021488    0.003156       0.764454        0.774384  0.455446  0.511034   \n",
       "3  0.026326    0.004756       0.751073        0.779325  0.462963  0.517564   \n",
       "4  0.029974    0.003912       0.733906        0.786824  0.436364  0.531765   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.685714      0.763441        0.380952         0.369151  \n",
       "1     0.742857      0.777778        0.366197         0.372852  \n",
       "2     0.657143      0.788530        0.348485         0.378007  \n",
       "3     0.724638      0.789286        0.340136         0.385017  \n",
       "4     0.685714      0.810036        0.320000         0.395797  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression(class_weight='balanced'))\n",
    "scores = cross_validate(\n",
    "    pipe_lr, X_train, y_train, return_train_score=True, scoring=scoring\n",
    ")\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.025957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.004005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <td>0.760807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <td>0.776252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_f1</th>\n",
       "      <td>0.467027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_f1</th>\n",
       "      <td>0.512418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_recall</th>\n",
       "      <td>0.699213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_recall</th>\n",
       "      <td>0.785814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_precision</th>\n",
       "      <td>0.351154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_precision</th>\n",
       "      <td>0.380165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "mean_fit_time         0.025957\n",
       "mean_score_time       0.004005\n",
       "mean_test_accuracy    0.760807\n",
       "mean_train_accuracy   0.776252\n",
       "mean_test_f1          0.467027\n",
       "mean_train_f1         0.512418\n",
       "mean_test_recall      0.699213\n",
       "mean_train_recall     0.785814\n",
       "mean_test_precision   0.351154\n",
       "mean_train_precision  0.380165"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dict = {\n",
    "    \"mean_fit_time\": [scores[\"fit_time\"].mean()],\n",
    "    \"mean_score_time\": [scores[\"score_time\"].mean()],\n",
    "    \"mean_test_accuracy\": [scores[\"test_accuracy\"].mean()],\n",
    "    \"mean_train_accuracy\": [scores[\"train_accuracy\"].mean()],\n",
    "    \"mean_test_f1\": [scores[\"test_f1\"].mean()],\n",
    "    \"mean_train_f1\": [scores[\"train_f1\"].mean()],\n",
    "    \"mean_test_recall\": [scores[\"test_recall\"].mean()],\n",
    "    \"mean_train_recall\": [scores[\"train_recall\"].mean()],\n",
    "    \"mean_test_precision\": [scores[\"test_precision\"].mean()],\n",
    "    \"mean_train_precision\": [scores[\"train_precision\"].mean()]\n",
    "}\n",
    "pd.DataFrame(scores_dict).T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "2. I definitely prefer this model as opposed to the previous one. By balancing the class weights, we are correctly predicting more churned customers. Although this decreases `accuracy` due to increasing false positives, it greatly increases `recall` which is a more important metric in our case due to the problem context and class imbalance. The mean test recall in this case is almost $70\\%$ which is approximately a $50\\%$ increase from the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "1. Jointly optimize `C` and `class_weight` with `GridSearchCV` and `scoring=\"f1\"`.\n",
    "  - For `class_weight`, consider 3 values: \n",
    "    - `None` (no weight)\n",
    "    - \"weight of class 0 = 1\"  and  \"weight of class 1 = 3\"\n",
    "    - '`balanced`'\n",
    "  - For `C`, choose some reasonable values\n",
    "2. What values of `C` and `class_weight` are chosen and what is the best cross-validation f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kennyjhcheng/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;drop&#x27;,\n",
       "                                                                         &#x27;drop&#x27;,\n",
       "                                                                         [&#x27;phone &#x27;\n",
       "                                                                          &#x27;number&#x27;]),\n",
       "                                                                        (&#x27;pipeline-1&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         [&#x27;account &#x27;\n",
       "                                                                          &#x27;length&#x27;,\n",
       "                                                                          &#x27;number &#x27;\n",
       "                                                                          &#x27;vmail &#x27;\n",
       "                                                                          &#x27;messages&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;...\n",
       "                                                                                                        handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         [&#x27;state&#x27;,\n",
       "                                                                          &#x27;area &#x27;\n",
       "                                                                          &#x27;code&#x27;,\n",
       "                                                                          &#x27;international &#x27;\n",
       "                                                                          &#x27;plan&#x27;,\n",
       "                                                                          &#x27;voice &#x27;\n",
       "                                                                          &#x27;mail &#x27;\n",
       "                                                                          &#x27;plan&#x27;])])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;logisticregression__class_weight&#x27;: [None,\n",
       "                                                              {0: 1, 1: 3},\n",
       "                                                              &#x27;balanced&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;drop&#x27;,\n",
       "                                                                         &#x27;drop&#x27;,\n",
       "                                                                         [&#x27;phone &#x27;\n",
       "                                                                          &#x27;number&#x27;]),\n",
       "                                                                        (&#x27;pipeline-1&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         [&#x27;account &#x27;\n",
       "                                                                          &#x27;length&#x27;,\n",
       "                                                                          &#x27;number &#x27;\n",
       "                                                                          &#x27;vmail &#x27;\n",
       "                                                                          &#x27;messages&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;...\n",
       "                                                                                                        handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         [&#x27;state&#x27;,\n",
       "                                                                          &#x27;area &#x27;\n",
       "                                                                          &#x27;code&#x27;,\n",
       "                                                                          &#x27;international &#x27;\n",
       "                                                                          &#x27;plan&#x27;,\n",
       "                                                                          &#x27;voice &#x27;\n",
       "                                                                          &#x27;mail &#x27;\n",
       "                                                                          &#x27;plan&#x27;])])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;logisticregression__class_weight&#x27;: [None,\n",
       "                                                              {0: 1, 1: 3},\n",
       "                                                              &#x27;balanced&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;drop&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;phone number&#x27;]),\n",
       "                                                 (&#x27;pipeline-1&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;account length&#x27;,\n",
       "                                                   &#x27;number vmail messages&#x27;,\n",
       "                                                   &#x27;total day minutes&#x27;,\n",
       "                                                   &#x27;total day calls&#x27;,\n",
       "                                                   &#x27;total day charge&#x27;,\n",
       "                                                   &#x27;total eve minutes&#x27;,\n",
       "                                                   &#x27;total eve calls&#x27;,\n",
       "                                                   &#x27;total eve charge&#x27;,\n",
       "                                                   &#x27;total night minutes&#x27;,\n",
       "                                                   &#x27;total night calls&#x27;,\n",
       "                                                   &#x27;total night charge&#x27;,\n",
       "                                                   &#x27;total intl minutes&#x27;,\n",
       "                                                   &#x27;total intl calls&#x27;,\n",
       "                                                   &#x27;total intl charge&#x27;,\n",
       "                                                   &#x27;customer service calls&#x27;]),\n",
       "                                                 (&#x27;pipeline-2&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [&#x27;state&#x27;, &#x27;area code&#x27;,\n",
       "                                                   &#x27;international plan&#x27;,\n",
       "                                                   &#x27;voice mail plan&#x27;])])),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;drop&#x27;, &#x27;drop&#x27;, [&#x27;phone number&#x27;]),\n",
       "                                (&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;account length&#x27;, &#x27;number vmail messages&#x27;,\n",
       "                                  &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;,\n",
       "                                  &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;,\n",
       "                                  &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;,\n",
       "                                  &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;,\n",
       "                                  &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;,\n",
       "                                  &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;,\n",
       "                                  &#x27;customer service calls&#x27;]),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 [&#x27;state&#x27;, &#x27;area code&#x27;, &#x27;international plan&#x27;,\n",
       "                                  &#x27;voice mail plan&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>[&#x27;phone number&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-1</label><div class=\"sk-toggleable__content\"><pre>[&#x27;account length&#x27;, &#x27;number vmail messages&#x27;, &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;, &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;, &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;, &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;, &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;, &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;, &#x27;customer service calls&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-2</label><div class=\"sk-toggleable__content\"><pre>[&#x27;state&#x27;, &#x27;area code&#x27;, &#x27;international plan&#x27;, &#x27;voice mail plan&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('drop',\n",
       "                                                                         'drop',\n",
       "                                                                         ['phone '\n",
       "                                                                          'number']),\n",
       "                                                                        ('pipeline-1',\n",
       "                                                                         Pipeline(steps=[('standardscaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['account '\n",
       "                                                                          'length',\n",
       "                                                                          'number '\n",
       "                                                                          'vmail '\n",
       "                                                                          'messages',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'calls',\n",
       "                                                                          '...\n",
       "                                                                                                        handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         ['state',\n",
       "                                                                          'area '\n",
       "                                                                          'code',\n",
       "                                                                          'international '\n",
       "                                                                          'plan',\n",
       "                                                                          'voice '\n",
       "                                                                          'mail '\n",
       "                                                                          'plan'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'logisticregression__class_weight': [None,\n",
       "                                                              {0: 1, 1: 3},\n",
       "                                                              'balanced']},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"logisticregression__class_weight\": [None, { 0:1, 1:3}, 'balanced'],\n",
    "    \"logisticregression__C\": np.logspace(-3, 3, 7),\n",
    "}\n",
    "\n",
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression())\n",
    "grid_search = GridSearchCV(\n",
    "    pipe_lr, param_grid, cv=5, n_jobs=-1, return_train_score=True, scoring='f1'\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.4901064071511795\n",
      "best param: {'logisticregression__C': 0.1, 'logisticregression__class_weight': {0: 1, 1: 3}}\n"
     ]
    }
   ],
   "source": [
    "print(f'best score: {grid_search.best_score_}')\n",
    "print(f'best param: {grid_search.best_params_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The best value of..\n",
    "    - `C`: 0.1\n",
    "    - `class_weight`: class 0 = 1 + class 1 = 3\n",
    "    - cross-validation `f1 score`: 0.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Test results\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Plot Confusion matrix\n",
    "    - Plot Precision-recall curve \n",
    "    - Calculate average precision score\n",
    "    - Plot ROC curve\n",
    "    - Report AUC score\n",
    "3. Comment on the AUC score and give an intuitive explanation of what this value of AUC means for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_lr_best = make_pipeline(preprocessor, LogisticRegression(C=0.1, class_weight={0:1, 1:3}))\n",
    "pipe_lr_best.fit(X_train, y_train)\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe_lr_best,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"Non Churn\", \"Churned\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    "    colorbar=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160c19000>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, pipe_lr_best.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "plt.plot(precision, recall, label=\"logistic regression: PR curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_test, pipe_lr_best.predict(X_test)),\n",
    "    recall_score(y_test, pipe_lr_best.predict(X_test)),\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate AP Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision of logistic regression: 0.465\n"
     ]
    }
   ],
   "source": [
    "ap_lr = average_precision_score(y_test, pipe_lr_best.predict_proba(X_test)[:, 1])\n",
    "print(\"Average precision of logistic regression: {:.3f}\".format(ap_lr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160913310>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, pipe_lr_best.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for LR: 0.824\n"
     ]
    }
   ],
   "source": [
    "roc_lr = roc_auc_score(y_test, pipe_lr_best.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC for LR: {:.3f}\".format(roc_lr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment on AUC Score\n",
    "**ANSWER:**\n",
    "\n",
    "2. The `AUC score` evaluates the probability that a randomly picked positive (churned) customer is ranked more positively (more confident that the customer has churned) than a randomly picked negative (non-churned) customer. Our `AUC score` of $0.824$ indicates our models predicts that a majority of our churned customers are more confidently positive (ranked positively) than the majority of our non-churned customers which means our model is performing well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Data spitting and exploration \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (75%) and test (25%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` to train and test splits. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 + 3 Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(housing_df, test_size=0.25, random_state=123)\n",
    "X_train = train_df.drop(columns=[\"MedHouseVal\"])\n",
    "X_test = test_df.drop(columns=[\"MedHouseVal\"])\n",
    "\n",
    "y_train = train_df[\"MedHouseVal\"]\n",
    "y_test = test_df[\"MedHouseVal\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15480, 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
       "       'Latitude', 'Longitude', 'MedHouseVal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1.0349</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.165217</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>734.0</td>\n",
       "      <td>3.191304</td>\n",
       "      <td>36.19</td>\n",
       "      <td>-119.35</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17889</th>\n",
       "      <td>4.7625</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.265207</td>\n",
       "      <td>1.002433</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>2.644769</td>\n",
       "      <td>37.41</td>\n",
       "      <td>-121.95</td>\n",
       "      <td>1.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>3.5192</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.747475</td>\n",
       "      <td>1.845118</td>\n",
       "      <td>796.0</td>\n",
       "      <td>2.680135</td>\n",
       "      <td>38.61</td>\n",
       "      <td>-120.44</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861</th>\n",
       "      <td>2.8672</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.635616</td>\n",
       "      <td>1.090411</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>3.095890</td>\n",
       "      <td>34.06</td>\n",
       "      <td>-118.13</td>\n",
       "      <td>1.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>4.1276</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.429936</td>\n",
       "      <td>0.963376</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>2.785032</td>\n",
       "      <td>33.81</td>\n",
       "      <td>-118.00</td>\n",
       "      <td>1.538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "19995  1.0349       6.0  4.165217   0.982609       734.0  3.191304     36.19   \n",
       "17889  4.7625      13.0  5.265207   1.002433      1087.0  2.644769     37.41   \n",
       "1977   3.5192       9.0  8.747475   1.845118       796.0  2.680135     38.61   \n",
       "6861   2.8672      30.0  4.635616   1.090411      1130.0  3.095890     34.06   \n",
       "11247  4.1276      13.0  4.429936   0.963376      1749.0  2.785032     33.81   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "19995    -119.35        0.678  \n",
       "17889    -121.95        1.375  \n",
       "1977     -120.44        0.980  \n",
       "6861     -118.13        1.985  \n",
       "11247    -118.00        1.538  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15480 entries, 19995 to 19966\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       15480 non-null  float64\n",
      " 1   HouseAge     15480 non-null  float64\n",
      " 2   AveRooms     15480 non-null  float64\n",
      " 3   AveBedrms    15480 non-null  float64\n",
      " 4   Population   15480 non-null  float64\n",
      " 5   AveOccup     15480 non-null  float64\n",
      " 6   Latitude     15480 non-null  float64\n",
      " 7   Longitude    15480 non-null  float64\n",
      " 8   MedHouseVal  15480 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "# No missing values, total 15480\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.875935</td>\n",
       "      <td>28.550000</td>\n",
       "      <td>5.421818</td>\n",
       "      <td>1.095860</td>\n",
       "      <td>1437.431137</td>\n",
       "      <td>3.073942</td>\n",
       "      <td>35.626601</td>\n",
       "      <td>-119.568380</td>\n",
       "      <td>2.074085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.900729</td>\n",
       "      <td>12.546577</td>\n",
       "      <td>2.519280</td>\n",
       "      <td>0.492851</td>\n",
       "      <td>1131.575270</td>\n",
       "      <td>10.971330</td>\n",
       "      <td>2.135537</td>\n",
       "      <td>2.001982</td>\n",
       "      <td>1.156051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "      <td>0.149990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.562500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.433750</td>\n",
       "      <td>1.005778</td>\n",
       "      <td>791.000000</td>\n",
       "      <td>2.429227</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "      <td>1.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534300</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.228714</td>\n",
       "      <td>1.048412</td>\n",
       "      <td>1173.000000</td>\n",
       "      <td>2.815468</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>-118.490000</td>\n",
       "      <td>1.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.750375</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.047297</td>\n",
       "      <td>1.099043</td>\n",
       "      <td>1742.000000</td>\n",
       "      <td>3.278071</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "      <td>2.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>28566.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "      <td>5.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  15480.000000  15480.000000  15480.000000  15480.000000  15480.000000   \n",
       "mean       3.875935     28.550000      5.421818      1.095860   1437.431137   \n",
       "std        1.900729     12.546577      2.519280      0.492851   1131.575270   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.562500     18.000000      4.433750      1.005778    791.000000   \n",
       "50%        3.534300     29.000000      5.228714      1.048412   1173.000000   \n",
       "75%        4.750375     37.000000      6.047297      1.099043   1742.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  28566.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude   MedHouseVal  \n",
       "count  15480.000000  15480.000000  15480.000000  15480.000000  \n",
       "mean       3.073942     35.626601   -119.568380      2.074085  \n",
       "std       10.971330      2.135537      2.001982      1.156051  \n",
       "min        0.750000     32.540000   -124.350000      0.149990  \n",
       "25%        2.429227     33.930000   -121.800000      1.203000  \n",
       "50%        2.815468     34.250000   -118.490000      1.805000  \n",
       "75%        3.278071     37.710000   -118.010000      2.655000  \n",
       "max     1243.333333     41.950000   -114.310000      5.000010  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all features are numeric -> Scaling\n",
    "train_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "There are no missing values in our dataset. Additionally, all values are numeric with different scales so we must apply standardization. Because this is the only transformation and our data set is all numeric, we don't need a column transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = StandardScaler()\n",
    "X_train_enc = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_train), index=X_train.index, columns=X_train.columns\n",
    "    )\n",
    "X_test_enc = pd.DataFrame(\n",
    "    preprocessor.transform(X_test), index=X_test.index, columns=X_test.columns\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>-1.494756</td>\n",
       "      <td>-1.797361</td>\n",
       "      <td>-0.498810</td>\n",
       "      <td>-0.229795</td>\n",
       "      <td>-0.621659</td>\n",
       "      <td>0.010697</td>\n",
       "      <td>0.263829</td>\n",
       "      <td>0.109086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17889</th>\n",
       "      <td>0.466449</td>\n",
       "      <td>-1.239422</td>\n",
       "      <td>-0.062167</td>\n",
       "      <td>-0.189570</td>\n",
       "      <td>-0.309694</td>\n",
       "      <td>-0.039119</td>\n",
       "      <td>0.835132</td>\n",
       "      <td>-1.189669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>-0.187689</td>\n",
       "      <td>-1.558244</td>\n",
       "      <td>1.320125</td>\n",
       "      <td>1.520300</td>\n",
       "      <td>-0.566866</td>\n",
       "      <td>-0.035895</td>\n",
       "      <td>1.397070</td>\n",
       "      <td>-0.435392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861</th>\n",
       "      <td>-0.530727</td>\n",
       "      <td>0.115573</td>\n",
       "      <td>-0.312084</td>\n",
       "      <td>-0.011056</td>\n",
       "      <td>-0.271693</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>-0.733610</td>\n",
       "      <td>0.718501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>0.132409</td>\n",
       "      <td>-1.239422</td>\n",
       "      <td>-0.393729</td>\n",
       "      <td>-0.268820</td>\n",
       "      <td>0.275350</td>\n",
       "      <td>-0.026334</td>\n",
       "      <td>-0.850681</td>\n",
       "      <td>0.783439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "19995 -1.494756 -1.797361 -0.498810  -0.229795   -0.621659  0.010697   \n",
       "17889  0.466449 -1.239422 -0.062167  -0.189570   -0.309694 -0.039119   \n",
       "1977  -0.187689 -1.558244  1.320125   1.520300   -0.566866 -0.035895   \n",
       "6861  -0.530727  0.115573 -0.312084  -0.011056   -0.271693  0.002001   \n",
       "11247  0.132409 -1.239422 -0.393729  -0.268820    0.275350 -0.026334   \n",
       "\n",
       "       Latitude  Longitude  \n",
       "19995  0.263829   0.109086  \n",
       "17889  0.835132  -1.189669  \n",
       "1977   1.397070  -0.435392  \n",
       "6861  -0.733610   0.718501  \n",
       "11247 -0.850681   0.783439  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline: Linear Regression \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `sklearn.linear_model.LinearRegression` with default scoring. \n",
    "2. What metric is used for scoring by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017970</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.603298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005749</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.599240</td>\n",
       "      <td>0.607080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004931</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.616816</td>\n",
       "      <td>0.602606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.607928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>0.612855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.017970    0.004593    0.608602     0.603298\n",
       "1  0.005749    0.001230    0.599240     0.607080\n",
       "2  0.004931    0.000655    0.616816     0.602606\n",
       "3  0.003939    0.000564    0.592949     0.607928\n",
       "4  0.003777    0.000741    0.015128     0.612855"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(preprocessor, LinearRegression())\n",
    "scores = cross_validate(pipe_lr, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.007273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.486547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.606753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "fit_time     0.007273\n",
       "score_time   0.001557\n",
       "test_score   0.486547\n",
       "train_score  0.606753"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.DataFrame(scores).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "2. The default method used for scoring is the $R^2$ score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest Regressor\n",
    "rubric={points:7}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for two model (`models`) and five evaluation metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"neg_mean_absolute_percentage_error\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. cross validation with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {\n",
    "    \"models\": models.keys(),\n",
    "    \"test_mean_neg_mse\": list(),\n",
    "    \"train_mean_neg_mse\": list(),\n",
    "    \"test_mean_neg_rmse\": list(),\n",
    "    \"train_mean_neg_rmse\": list(),\n",
    "    \"test_mean_neg_mean_absolute_error\": list(),\n",
    "    \"train_mean_neg_mean_absolute_error\": list(),\n",
    "    \"test_mean_r2\": list(),\n",
    "    \"train_mean_r2\": list(),\n",
    "    \"test_mean_neg_mape\": list(),\n",
    "    \"train_mean_neg_mape\": list(),\n",
    "}\n",
    "\n",
    "for m in res_dict['models']:\n",
    "    pipe = make_pipeline(preprocessor, models[m])\n",
    "    scores = cross_validate(\n",
    "        pipe, X_train, y_train, return_train_score=True, scoring=score_types_reg\n",
    "        )\n",
    "    res_dict[\"test_mean_neg_mse\"].append(scores['test_neg_mean_squared_error'].mean())\n",
    "    res_dict[\"train_mean_neg_mse\"].append(scores['train_neg_mean_squared_error'].mean())\n",
    "    res_dict[\"test_mean_neg_rmse\"].append(scores['test_neg_root_mean_squared_error'].mean())\n",
    "    res_dict[\"train_mean_neg_rmse\"].append(scores['train_neg_root_mean_squared_error'].mean())\n",
    "    res_dict[\"test_mean_neg_mean_absolute_error\"].append(scores['test_neg_mean_absolute_error'].mean())\n",
    "    res_dict[\"train_mean_neg_mean_absolute_error\"].append(scores['train_neg_mean_absolute_error'].mean())\n",
    "    res_dict[\"test_mean_r2\"].append(scores['test_r2'].mean())\n",
    "    res_dict[\"train_mean_r2\"].append(scores['train_r2'].mean())\n",
    "    res_dict[\"test_mean_neg_mape\"].append(scores['test_neg_mean_absolute_percentage_error'].mean())\n",
    "    res_dict[\"train_mean_neg_mape\"].append(scores['train_neg_mean_absolute_percentage_error'].mean())\n",
    "\n",
    "results = pd.DataFrame(res_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Show as frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mean_neg_mse</th>\n",
       "      <td>-0.678763</td>\n",
       "      <td>-0.268434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mean_neg_mse</th>\n",
       "      <td>-0.525484</td>\n",
       "      <td>-0.037726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mean_neg_rmse</th>\n",
       "      <td>-0.808948</td>\n",
       "      <td>-0.517994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mean_neg_rmse</th>\n",
       "      <td>-0.7249</td>\n",
       "      <td>-0.194225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mean_neg_mean_absolute_error</th>\n",
       "      <td>-0.536109</td>\n",
       "      <td>-0.338477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mean_neg_mean_absolute_error</th>\n",
       "      <td>-0.531897</td>\n",
       "      <td>-0.126466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mean_r2</th>\n",
       "      <td>0.486522</td>\n",
       "      <td>0.798816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mean_r2</th>\n",
       "      <td>0.606753</td>\n",
       "      <td>0.971765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mean_neg_mape</th>\n",
       "      <td>-0.319265</td>\n",
       "      <td>-0.191235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mean_neg_mape</th>\n",
       "      <td>-0.316948</td>\n",
       "      <td>-0.071181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0              1\n",
       "models                                 Ridge  Random Forest\n",
       "test_mean_neg_mse                  -0.678763      -0.268434\n",
       "train_mean_neg_mse                 -0.525484      -0.037726\n",
       "test_mean_neg_rmse                 -0.808948      -0.517994\n",
       "train_mean_neg_rmse                  -0.7249      -0.194225\n",
       "test_mean_neg_mean_absolute_error  -0.536109      -0.338477\n",
       "train_mean_neg_mean_absolute_error -0.531897      -0.126466\n",
       "test_mean_r2                        0.486522       0.798816\n",
       "train_mean_r2                       0.606753       0.971765\n",
       "test_mean_neg_mape                 -0.319265      -0.191235\n",
       "train_mean_neg_mape                -0.316948      -0.071181"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Interpretation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these metrics: `neg_mse`, `neg_rmse`, `mean_absolute_error`, and `neg_mape` we want a higher score (more positive or closer to 0) because a lower magnitude of these scores is better. For $R^2$ we would like a higher score.\n",
    "\n",
    "In comparison to the $R^2$ score of the baseline `Linear Regression` model, the `Ridge` model performs similarly to the baseline both with validation $R^2\\approx 0.486$. However, the `Random Forest` model performs significantly better than the baseline with a validation %R^2=0.799$\n",
    "\n",
    "According to all of the metrics we are using, `Random forest` seems to perform better than `Ridge`. All of the scoring metrics have higher values for the `Random forest` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Hyperparameter optimization \n",
    "rubric={points:1}\n",
    "\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose `neg_mean_absolute_percentage_error` as the HParam optimization metric.\n",
    "\n",
    "2. What was the best `alpha` hyper-parameter found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                              StandardScaler()),\n",
       "                                             (&#x27;ridge&#x27;, Ridge())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;ridge__alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x160e277c0&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=&#x27;neg_mean_absolute_percentage_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                              StandardScaler()),\n",
       "                                             (&#x27;ridge&#x27;, Ridge())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;ridge__alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x160e277c0&gt;},\n",
       "                   random_state=42,\n",
       "                   scoring=&#x27;neg_mean_absolute_percentage_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()), (&#x27;ridge&#x27;, Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('standardscaler',\n",
       "                                              StandardScaler()),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'ridge__alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x160e277c0>},\n",
       "                   random_state=42,\n",
       "                   scoring='neg_mean_absolute_percentage_error')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ridge = make_pipeline(preprocessor, Ridge())\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe_ridge, param_distributions=param_dist, n_jobs=-1, n_iter=20, cv=5, random_state=42, scoring='neg_mean_absolute_percentage_error'\n",
    ")\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: -0.31912256083232415\n",
      "best param: {'ridge__alpha': 24.658329458549098}\n"
     ]
    }
   ],
   "source": [
    "print(f'best score: {random_search.best_score_}')\n",
    "print(f'best param: {random_search.best_params_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best `alpha = 24.658`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Test the best model (from 3.4) on the test set based on the `neg_mean_absolute_percentage_error` score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31622866932971816"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_best_ridge = make_pipeline(preprocessor, Ridge(alpha=24.658))\n",
    "pipe_best_ridge.fit(X_train, y_train)\n",
    "y_pred = pipe_best_ridge.predict(X_test)\n",
    "best_ridge_mape = -1 * mean_absolute_percentage_error(y_test, y_pred)\n",
    "best_ridge_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:4}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Explore coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: \n",
    "   - features \n",
    "   - coefficients\n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MedInc</td>\n",
       "      <td>0.834305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AveBedrms</td>\n",
       "      <td>0.307090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HouseAge</td>\n",
       "      <td>0.119846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Population</td>\n",
       "      <td>-0.002463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AveOccup</td>\n",
       "      <td>-0.042213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AveRooms</td>\n",
       "      <td>-0.271125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-0.844381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-0.874981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  coefficients\n",
       "0      MedInc      0.834305\n",
       "3   AveBedrms      0.307090\n",
       "1    HouseAge      0.119846\n",
       "4  Population     -0.002463\n",
       "5    AveOccup     -0.042213\n",
       "2    AveRooms     -0.271125\n",
       "7   Longitude     -0.844381\n",
       "6    Latitude     -0.874981"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adapted from Lecture 10\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"features\": X_train.columns,\n",
    "        \"coefficients\": pipe_best_ridge.named_steps[\"ridge\"].coef_,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.sort_values(\"coefficients\",ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "Increasing the `MedInc`, `AveBedrms`, and `HouseAge` features would result in higher housing prices according to the coefficients learned by my `Ridge` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3accb63b70d21bf705ea80e34779637f5c0ae9dc4fca2ea745cc2dd096b78fd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
