{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33c5b0c-d0f1-40c0-b794-3b3471ac73d2",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 7: Clustering and recommender systems\n",
    "### Associated lectures: Lectures 14 and 15\n",
    "\n",
    "**Due date: Wednesday, March 22, 11:59pm**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4651888-484b-42a0-95e1-d273e5069205",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086914c2-5de1-414a-8770-23bef9f312d0",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe22cb5-f825-4dba-b5e3-3538f4afe703",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work on this homework in a group and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be5b2d-1854-4c63-bcc6-9b6258b7293a",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d8d363-7c31-4381-8a1d-2b2556108916",
   "metadata": {},
   "source": [
    "## Exercise 1: Document clustering toy example <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "In lecture 14, we looked at a popular application of clustering: customer segmentation. In this homework, we will work on a toy example of another popular application: [**document clustering**](https://en.wikipedia.org/wiki/Document_clustering). A large amount of unlabeled text data is available out there (e.g., news, recipes, online Q&A), and clustering is a commonly used technique to organize this data in a meaningful way. \n",
    "\n",
    "In this exercise, we will create a toy dataset with sentences from Wikipedia articles and cluster these sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7b268-4b0a-4d01-9009-a33312f65d33",
   "metadata": {},
   "source": [
    "### 1.1 Sample sentences from Wikipedia articles\n",
    "rubric={points:2}\n",
    "\n",
    "The code below extracts first sentences of Wikipedia articles on a set of queries. You will need the `wikipedia` package installed in the course environment to run the code below. \n",
    "\n",
    "```\n",
    "conda activate cpsc330\n",
    "conda install -c conda-forge wikipedia\n",
    "```\n",
    "\n",
    "You also need `nltk` library in the course environment. \n",
    "\n",
    "```\n",
    "conda install -c anaconda nltk \n",
    "```        \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following question. \n",
    "\n",
    "1. Given this dataset, how many clusters would you expect a clustering algorithm to identify? How would you manually label these clusters?   \n",
    "\n",
    "> *Note: Feel free to experiment with queries of your choice. But stick to the provided list for the final submission so that it's easier for the TAs when they grade your submission.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374e514b-8b4d-40cf-bcb9-2dbfd4558121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kennyjhcheng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c71b2eb-caf0-40f7-b7b0-93f1fadbc548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki query</th>\n",
       "      <th>text</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mount Everests</td>\n",
       "      <td>Mount Everest (Nepali: सगरमाथा, romanized: Sagarmāthā; Tibetan: Chomolungma ཇོ་མོ་གླང་མ; Chinese: 珠穆朗玛峰; pinyin: Zhūmùlǎngmǎ Fēng) is Earth's highest mountain above sea level, located in the Mahalangur Himal sub-range of the Himalayas.</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raspberry</td>\n",
       "      <td>The raspberry is the edible fruit of a multitude of plant species in the genus Rubus of the rose family, most of which are in the subgenus Idaeobatus.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mount Denali</td>\n",
       "      <td>Denali (; also known as Mount McKinley, its former official name) is the highest mountain peak in North America, with a summit elevation of 20,310 feet (6,190 m) above sea level.</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arithmetic</td>\n",
       "      <td>Arithmetic (from Ancient Greek  ἀριθμός (arithmós) 'number', and  τική [τέχνη] (tikḗ [tékhnē]) 'art, craft') is an elementary part of mathematics that consists of the study of the properties of the traditional operations on numbers—addition, subtraction, multiplication, division, exponentiation, and extraction of roots.</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Topology</td>\n",
       "      <td>In mathematics, topology (from the Greek words τόπος, 'place, location', and λόγος, 'study') is concerned with the properties of a geometric object that are preserved under continuous deformations, such as stretching, twisting, crumpling, and bending; that is, without closing holes, opening holes, tearing, gluing, or passing through itself.</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseball</td>\n",
       "      <td>Basketball is a team sport in which two teams, most commonly of five players each, opposing one another on a rectangular court, compete with the primary objective of shooting a basketball (approximately 9.4 inches (24 cm) in diameter) through the defender's hoop (a basket 18 inches (46 cm) in diameter mounted 10 feet (3.048 m) high to a backboard at each end of the court), while preventing the opposing team from shooting through their own hoop.</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hockey</td>\n",
       "      <td>Hockey is a term used to denote a family of various types of both summer and winter team sports which originated on either an outdoor field, sheet of ice, or dry floor such as in a gymnasium.</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mango_fruit</td>\n",
       "      <td>A mango is an edible stone fruit produced by the tropical tree Mangifera indica.</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mount Kenya</td>\n",
       "      <td>Mount Kenya (Kikuyu: Kĩrĩnyaga, Kamba, Ki Nyaa) is the highest mountain in Kenya and the second-highest in Africa, after Kilimanjaro.</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Football</td>\n",
       "      <td>Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wiki query  \\\n",
       "0  Mount Everests   \n",
       "1  Raspberry        \n",
       "2  Mount Denali     \n",
       "3  Arithmetic       \n",
       "4  Topology         \n",
       "5  Baseball         \n",
       "6  Hockey           \n",
       "7  Mango_fruit      \n",
       "8  Mount Kenya      \n",
       "9  Football         \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \\\n",
       "0  Mount Everest (Nepali: सगरमाथा, romanized: Sagarmāthā; Tibetan: Chomolungma ཇོ་མོ་གླང་མ; Chinese: 珠穆朗玛峰; pinyin: Zhūmùlǎngmǎ Fēng) is Earth's highest mountain above sea level, located in the Mahalangur Himal sub-range of the Himalayas.                                                                                                                                                                                                                        \n",
       "1  The raspberry is the edible fruit of a multitude of plant species in the genus Rubus of the rose family, most of which are in the subgenus Idaeobatus.                                                                                                                                                                                                                                                                                                             \n",
       "2  Denali (; also known as Mount McKinley, its former official name) is the highest mountain peak in North America, with a summit elevation of 20,310 feet (6,190 m) above sea level.                                                                                                                                                                                                                                                                                 \n",
       "3  Arithmetic (from Ancient Greek  ἀριθμός (arithmós) 'number', and  τική [τέχνη] (tikḗ [tékhnē]) 'art, craft') is an elementary part of mathematics that consists of the study of the properties of the traditional operations on numbers—addition, subtraction, multiplication, division, exponentiation, and extraction of roots.                                                                                                                                  \n",
       "4  In mathematics, topology (from the Greek words τόπος, 'place, location', and λόγος, 'study') is concerned with the properties of a geometric object that are preserved under continuous deformations, such as stretching, twisting, crumpling, and bending; that is, without closing holes, opening holes, tearing, gluing, or passing through itself.                                                                                                             \n",
       "5  Basketball is a team sport in which two teams, most commonly of five players each, opposing one another on a rectangular court, compete with the primary objective of shooting a basketball (approximately 9.4 inches (24 cm) in diameter) through the defender's hoop (a basket 18 inches (46 cm) in diameter mounted 10 feet (3.048 m) high to a backboard at each end of the court), while preventing the opposing team from shooting through their own hoop.   \n",
       "6  Hockey is a term used to denote a family of various types of both summer and winter team sports which originated on either an outdoor field, sheet of ice, or dry floor such as in a gymnasium.                                                                                                                                                                                                                                                                    \n",
       "7  A mango is an edible stone fruit produced by the tropical tree Mangifera indica.                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "8  Mount Kenya (Kikuyu: Kĩrĩnyaga, Kamba, Ki Nyaa) is the highest mountain in Kenya and the second-highest in Africa, after Kilimanjaro.                                                                                                                                                                                                                                                                                                                              \n",
       "9  Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.                                                                                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "   n_words  \n",
       "0  44       \n",
       "1  30       \n",
       "2  38       \n",
       "3  62       \n",
       "4  68       \n",
       "5  92       \n",
       "6  40       \n",
       "7  15       \n",
       "8  27       \n",
       "9  22       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "queries = [\n",
    "    \"Mount Everests\",\n",
    "    \"Raspberry\",\n",
    "    \"Mount Denali\",\n",
    "    \"Arithmetic\",\n",
    "    \"Topology\",\n",
    "    \"Baseball\",\n",
    "    \"Hockey\",\n",
    "    \"Mango_fruit\",\n",
    "    \"Mount Kenya\",\n",
    "    \"Football\"\n",
    "]\n",
    "\n",
    "wiki_dict = {\"wiki query\": [], \"text\": [], \"n_words\": []}\n",
    "for i in range(len(queries)):\n",
    "    sent = sent_tokenize(wikipedia.page(queries[i]).content)[0]\n",
    "    wiki_dict[\"text\"].append(sent)\n",
    "    wiki_dict[\"n_words\"].append(len(word_tokenize(sent)))\n",
    "    wiki_dict[\"wiki query\"].append(queries[i])\n",
    "\n",
    "wiki_df = pd.DataFrame(wiki_dict)\n",
    "wiki_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1506b150-103f-4500-883c-1a85a903061e",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "I would select 4 clusters based on the queries\n",
    "\n",
    "1. Mountains: `Mount Denali`, `Mount Kenya`, `Mount Everests`\n",
    "2. Fruit: `Raspberry`, `Mango_fruit`\n",
    "3. Sports: `Baseball`, `Hockey`, `Football`\n",
    "4. Field of study: `Arithmetic`, `Topology`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f82cba-4642-4872-8b15-e49eab897821",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574346ba-94a4-4949-9be3-9ff8ea77488e",
   "metadata": {},
   "source": [
    "### 1.2 `KMeans` with bag-of-words representation \n",
    "rubric={points:10}\n",
    "\n",
    "We have seen that before we pass text to machine learning models, we need to encode it into a numeric representation. So let's encode our toy dataset above (`wiki_df`) to a numeric representation. \n",
    "\n",
    "First, let's try our good old friend: bag-of-words representation. The code below creates dense bag-of-words representation of Wikipedia sentences from question 1.1 using a [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following questions. \n",
    "\n",
    "1. Run `KMeans` clustering on the transformed data (`bow_sents`) with K = the number of clusters you identified in question 1.1. Examine clustering labels assigned by `KMeans`.\n",
    "2. Repeat after modifying the `CountVectorizer` to ignore words appearing in only one sentence (or document, one row of `wiki_df`).\n",
    "3. Keeping the new `CountVectorizer`, examine clustering labels assigned by `KMeans` under an off-by-1 value of K.\n",
    "4. Briefly describe and analyze the behavoir of `KMeans`. Is `KMeans` doing a reasonable job in clustering the sentences? \n",
    "\n",
    "> You can access cluster label assignments using `labels_` attribute of the clustering object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09628f3b-0608-441a-af31-6f8f33ef46d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>048</th>\n",
       "      <th>10</th>\n",
       "      <th>18</th>\n",
       "      <th>190</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>310</th>\n",
       "      <th>46</th>\n",
       "      <th>addition</th>\n",
       "      <th>africa</th>\n",
       "      <th>...</th>\n",
       "      <th>winter</th>\n",
       "      <th>words</th>\n",
       "      <th>zhūmùlǎngmǎ</th>\n",
       "      <th>λόγος</th>\n",
       "      <th>τέχνη</th>\n",
       "      <th>τική</th>\n",
       "      <th>τόπος</th>\n",
       "      <th>सगरम</th>\n",
       "      <th>ἀριθμός</th>\n",
       "      <th>珠穆朗玛峰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   048  10  18  190  20  24  310  46  addition  africa  ...  winter  words  \\\n",
       "0  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "1  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "2  0    0   0   1    1   0   1    0   0         0       ...  0       0       \n",
       "3  0    0   0   0    0   0   0    0   1         0       ...  0       0       \n",
       "4  0    0   0   0    0   0   0    0   0         0       ...  0       1       \n",
       "5  1    1   1   0    0   1   0    1   0         0       ...  0       0       \n",
       "6  0    0   0   0    0   0   0    0   0         0       ...  1       0       \n",
       "7  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "8  0    0   0   0    0   0   0    0   0         1       ...  0       0       \n",
       "9  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "\n",
       "   zhūmùlǎngmǎ  λόγος  τέχνη  τική  τόπος  सगरम  ἀριθμός  珠穆朗玛峰  \n",
       "0  1            0      0      0     0      1     0        1      \n",
       "1  0            0      0      0     0      0     0        0      \n",
       "2  0            0      0      0     0      0     0        0      \n",
       "3  0            0      1      1     0      0     1        0      \n",
       "4  0            1      0      0     1      0     0        0      \n",
       "5  0            0      0      0     0      0     0        0      \n",
       "6  0            0      0      0     0      0     0        0      \n",
       "7  0            0      0      0     0      0     0        0      \n",
       "8  0            0      0      0     0      0     0        0      \n",
       "9  0            0      0      0     0      0     0        0      \n",
       "\n",
       "[10 rows x 169 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "bow_sents = vec.fit_transform(wiki_df[\"text\"]).todense()\n",
    "bow_df = pd.DataFrame(\n",
    "    data=bow_sents, columns=vec.get_feature_names_out(), index=wiki_df.index\n",
    ")\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39ccbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0  1    \n",
       "1  1    \n",
       "2  1    \n",
       "3  2    \n",
       "4  0    \n",
       "5  3    \n",
       "6  1    \n",
       "7  1    \n",
       "8  1    \n",
       "9  1    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(bow_sents)\n",
    "\n",
    "pd.DataFrame({\"label\":kmeans.labels_}, index=wiki_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11e84dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0', ['Topology'])\n",
      "('1', ['Mount Everests', 'Raspberry', 'Mount Denali', 'Hockey', 'Mango_fruit', 'Mount Kenya', 'Football'])\n",
      "('2', ['Arithmetic'])\n",
      "('3', ['Baseball'])\n"
     ]
    }
   ],
   "source": [
    "def print_cluster_assignments(kmeans, num_clusters):\n",
    "    labels = kmeans.labels_\n",
    "    clusters = {}\n",
    "    for i in range(num_clusters):\n",
    "        clusters[str(i)] = []\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        clusters[str(label)].append(queries[i])\n",
    "    for i in clusters.items():\n",
    "        print(i)\n",
    "print_cluster_assignments(kmeans, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f0b372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>048</th>\n",
       "      <th>10</th>\n",
       "      <th>18</th>\n",
       "      <th>190</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>310</th>\n",
       "      <th>46</th>\n",
       "      <th>addition</th>\n",
       "      <th>africa</th>\n",
       "      <th>...</th>\n",
       "      <th>winter</th>\n",
       "      <th>words</th>\n",
       "      <th>zhūmùlǎngmǎ</th>\n",
       "      <th>λόγος</th>\n",
       "      <th>τέχνη</th>\n",
       "      <th>τική</th>\n",
       "      <th>τόπος</th>\n",
       "      <th>सगरम</th>\n",
       "      <th>ἀριθμός</th>\n",
       "      <th>珠穆朗玛峰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   048  10  18  190  20  24  310  46  addition  africa  ...  winter  words  \\\n",
       "0  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "1  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "2  0    0   0   1    1   0   1    0   0         0       ...  0       0       \n",
       "3  0    0   0   0    0   0   0    0   1         0       ...  0       0       \n",
       "4  0    0   0   0    0   0   0    0   0         0       ...  0       1       \n",
       "5  1    1   1   0    0   1   0    1   0         0       ...  0       0       \n",
       "6  0    0   0   0    0   0   0    0   0         0       ...  1       0       \n",
       "7  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "8  0    0   0   0    0   0   0    0   0         1       ...  0       0       \n",
       "9  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "\n",
       "   zhūmùlǎngmǎ  λόγος  τέχνη  τική  τόπος  सगरम  ἀριθμός  珠穆朗玛峰  \n",
       "0  1            0      0      0     0      1     0        1      \n",
       "1  0            0      0      0     0      0     0        0      \n",
       "2  0            0      0      0     0      0     0        0      \n",
       "3  0            0      1      1     0      0     1        0      \n",
       "4  0            1      0      0     1      0     0        0      \n",
       "5  0            0      0      0     0      0     0        0      \n",
       "6  0            0      0      0     0      0     0        0      \n",
       "7  0            0      0      0     0      0     0        0      \n",
       "8  0            0      0      0     0      0     0        0      \n",
       "9  0            0      0      0     0      0     0        0      \n",
       "\n",
       "[10 rows x 169 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2\n",
    "vec_ignore_one = CountVectorizer(stop_words='english', min_df=2)\n",
    "bow_sents_ignore_one = vec_ignore_one.fit_transform(wiki_df[\"text\"]).todense()\n",
    "bow_df_ignore_one = pd.DataFrame(\n",
    "    data=bow_sents_ignore_one, columns=vec_ignore_one.get_feature_names_out(), index=wiki_df.index\n",
    ")\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a518090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0  1    \n",
       "1  0    \n",
       "2  1    \n",
       "3  3    \n",
       "4  3    \n",
       "5  2    \n",
       "6  2    \n",
       "7  0    \n",
       "8  1    \n",
       "9  2    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_ignore_one = KMeans(n_clusters=4)\n",
    "kmeans_ignore_one.fit(bow_sents_ignore_one)\n",
    "\n",
    "pd.DataFrame({\"label\":kmeans_ignore_one.labels_}, index=wiki_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0', ['Raspberry', 'Mango_fruit'])\n",
      "('1', ['Mount Everests', 'Mount Denali', 'Mount Kenya'])\n",
      "('2', ['Baseball', 'Hockey', 'Football'])\n",
      "('3', ['Arithmetic', 'Topology'])\n"
     ]
    }
   ],
   "source": [
    "print_cluster_assignments(kmeans_ignore_one, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6d97b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster assignments for k=3\n",
      "('0', ['Arithmetic', 'Topology'])\n",
      "('1', ['Raspberry', 'Baseball', 'Hockey', 'Mango_fruit', 'Football'])\n",
      "('2', ['Mount Everests', 'Mount Denali', 'Mount Kenya'])\n",
      "Cluster assignments for k=5\n",
      "('0', ['Raspberry', 'Mango_fruit'])\n",
      "('1', ['Mount Everests', 'Mount Denali', 'Mount Kenya'])\n",
      "('2', ['Arithmetic', 'Topology'])\n",
      "('3', ['Hockey', 'Football'])\n",
      "('4', ['Baseball'])\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "kmeans_3 = KMeans(n_clusters=3)\n",
    "kmeans_3.fit(bow_sents_ignore_one)\n",
    "kmeans_5 = KMeans(n_clusters=5)\n",
    "kmeans_5.fit(bow_sents_ignore_one)\n",
    "\n",
    "print(\"Cluster assignments for k=3\")\n",
    "print_cluster_assignments(kmeans_3, 3)\n",
    "print(\"Cluster assignments for k=5\")\n",
    "print_cluster_assignments(kmeans_5, 5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5e9174d-c281-4bcd-bd8f-8f1cb81e4bd9",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "**ANSWER:**\n",
    "\n",
    "`KMeans` does a good job of clustering when we ignore words in `CountVectorizer` that are only in one dataset. In fact, it clusters the queries exactly the same as how I manually classified them. However, without removing words that are only in one dataset, it does an extremely poor job of clustering from what's expected.\n",
    "\n",
    "When we decrease the number of clusters to `k = 3`, the clustering becomes quite incomprehensible again, with one cluster containing mountains, fruits, sports, and a field of study.\n",
    "\n",
    "When raising the number of clusters to `k = 5`, the clusters also become less sensible. Although the mountains are all clustered together, fields of study, fruits, and sports are clustered together or by themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02261e6d-8195-4248-9c21-5bc520baa89e",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e1b0b-faec-4b86-9e59-b45b3a133e2f",
   "metadata": {},
   "source": [
    "### 1.3 Sentence embedding representation\n",
    "rubric={points:10}\n",
    "\n",
    "Bag-of-words representation is limited in that it does not take into account word ordering and context. There are other richer representations of text, and we are going to use one such representation in this lab. \n",
    "\n",
    "The code below creates an alternative and a more expressive representation of sentences. We will call it *sentence embedding representation*. We'll use [sentence transformer](https://www.sbert.net/index.html) to extract these representations. At this point it's enough to know that this is an alternative representation of text which usually works better than simple bag-of-words representation. We will talk a bit more about embedding representations next week. You need to install `sentence-transformers` in the course conda environment to run the code below. \n",
    "\n",
    "```conda install -c conda-forge sentence-transformers```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following questions. \n",
    "\n",
    "1. How many dimensions (features associated with each example) are present in this representation? \n",
    "2. Run `KMeans` clustering with sentence embedding representation of text (`emb_sents`) and examine cluster labels. \n",
    "3. How well the sentences are clustered together? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a092544-58d7-418d-84ff-2e898ece2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20174ee5-9122-4c10-b112-4a675653fee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.532167</td>\n",
       "      <td>0.219127</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>-0.407121</td>\n",
       "      <td>-0.616050</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>-0.369831</td>\n",
       "      <td>-0.268620</td>\n",
       "      <td>0.284335</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049630</td>\n",
       "      <td>-0.063532</td>\n",
       "      <td>0.193070</td>\n",
       "      <td>0.345019</td>\n",
       "      <td>0.111516</td>\n",
       "      <td>-0.018490</td>\n",
       "      <td>0.062621</td>\n",
       "      <td>-0.105441</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.097068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.257144</td>\n",
       "      <td>0.279161</td>\n",
       "      <td>0.222628</td>\n",
       "      <td>0.190509</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.215431</td>\n",
       "      <td>0.124740</td>\n",
       "      <td>0.256541</td>\n",
       "      <td>-0.093520</td>\n",
       "      <td>0.304061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350746</td>\n",
       "      <td>-0.103448</td>\n",
       "      <td>0.188898</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.364525</td>\n",
       "      <td>0.270561</td>\n",
       "      <td>0.617305</td>\n",
       "      <td>0.565283</td>\n",
       "      <td>0.068011</td>\n",
       "      <td>0.210108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.153511</td>\n",
       "      <td>0.308003</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>-0.000984</td>\n",
       "      <td>-0.228809</td>\n",
       "      <td>0.145077</td>\n",
       "      <td>-0.189960</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345482</td>\n",
       "      <td>0.149472</td>\n",
       "      <td>-0.128204</td>\n",
       "      <td>0.069986</td>\n",
       "      <td>-0.049316</td>\n",
       "      <td>-0.122243</td>\n",
       "      <td>-0.520354</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>0.277886</td>\n",
       "      <td>-0.082411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.182560</td>\n",
       "      <td>0.174977</td>\n",
       "      <td>-0.142932</td>\n",
       "      <td>0.508398</td>\n",
       "      <td>-0.102793</td>\n",
       "      <td>0.314821</td>\n",
       "      <td>-0.028197</td>\n",
       "      <td>0.235509</td>\n",
       "      <td>0.293719</td>\n",
       "      <td>0.091492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>-0.220330</td>\n",
       "      <td>0.126606</td>\n",
       "      <td>0.091785</td>\n",
       "      <td>0.087272</td>\n",
       "      <td>0.279831</td>\n",
       "      <td>-0.328509</td>\n",
       "      <td>0.157604</td>\n",
       "      <td>0.439283</td>\n",
       "      <td>0.204193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.032420</td>\n",
       "      <td>0.043655</td>\n",
       "      <td>0.501373</td>\n",
       "      <td>0.442546</td>\n",
       "      <td>0.157427</td>\n",
       "      <td>0.082318</td>\n",
       "      <td>0.287892</td>\n",
       "      <td>0.322357</td>\n",
       "      <td>0.356958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267656</td>\n",
       "      <td>-0.337920</td>\n",
       "      <td>0.343273</td>\n",
       "      <td>0.429253</td>\n",
       "      <td>-0.042079</td>\n",
       "      <td>0.466611</td>\n",
       "      <td>-0.574508</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>0.150982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.042878</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>-0.187499</td>\n",
       "      <td>-0.020230</td>\n",
       "      <td>-0.260429</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>0.067830</td>\n",
       "      <td>0.296153</td>\n",
       "      <td>-0.020178</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178184</td>\n",
       "      <td>-0.003942</td>\n",
       "      <td>0.331448</td>\n",
       "      <td>-0.395468</td>\n",
       "      <td>0.025013</td>\n",
       "      <td>0.082307</td>\n",
       "      <td>-0.561699</td>\n",
       "      <td>0.560587</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>-0.373937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.071380</td>\n",
       "      <td>0.096587</td>\n",
       "      <td>0.055705</td>\n",
       "      <td>-0.525645</td>\n",
       "      <td>0.580350</td>\n",
       "      <td>0.096592</td>\n",
       "      <td>0.441484</td>\n",
       "      <td>0.257061</td>\n",
       "      <td>-0.054260</td>\n",
       "      <td>0.220842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457613</td>\n",
       "      <td>-0.331446</td>\n",
       "      <td>-0.066380</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.147649</td>\n",
       "      <td>0.034530</td>\n",
       "      <td>-0.095109</td>\n",
       "      <td>0.304422</td>\n",
       "      <td>0.327636</td>\n",
       "      <td>-0.197770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.141320</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>-0.219024</td>\n",
       "      <td>-0.277812</td>\n",
       "      <td>0.177240</td>\n",
       "      <td>0.191265</td>\n",
       "      <td>0.252725</td>\n",
       "      <td>-0.035201</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104466</td>\n",
       "      <td>-0.177960</td>\n",
       "      <td>0.088618</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>-0.089657</td>\n",
       "      <td>0.246048</td>\n",
       "      <td>-0.060229</td>\n",
       "      <td>0.500508</td>\n",
       "      <td>-0.045897</td>\n",
       "      <td>-0.046336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.291509</td>\n",
       "      <td>0.554150</td>\n",
       "      <td>0.115631</td>\n",
       "      <td>-0.188634</td>\n",
       "      <td>-0.074476</td>\n",
       "      <td>-0.277101</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>0.076826</td>\n",
       "      <td>0.199134</td>\n",
       "      <td>0.033996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055575</td>\n",
       "      <td>0.047854</td>\n",
       "      <td>0.214838</td>\n",
       "      <td>-0.086142</td>\n",
       "      <td>0.453633</td>\n",
       "      <td>0.021888</td>\n",
       "      <td>-0.143639</td>\n",
       "      <td>0.167839</td>\n",
       "      <td>-0.151438</td>\n",
       "      <td>-0.076444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.071756</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>-0.071761</td>\n",
       "      <td>0.306060</td>\n",
       "      <td>0.358961</td>\n",
       "      <td>-0.061443</td>\n",
       "      <td>0.167584</td>\n",
       "      <td>0.364614</td>\n",
       "      <td>0.323541</td>\n",
       "      <td>0.141398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404115</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.177493</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.232335</td>\n",
       "      <td>0.260556</td>\n",
       "      <td>0.168149</td>\n",
       "      <td>0.483963</td>\n",
       "      <td>0.121122</td>\n",
       "      <td>0.196881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.532167  0.219127  0.029919 -0.407121 -0.616050  0.339105 -0.369831   \n",
       "1 -0.257144  0.279161  0.222628  0.190509  0.057312  0.215431  0.124740   \n",
       "2 -0.153511  0.308003  0.042989 -0.000984 -0.228809  0.145077 -0.189960   \n",
       "3 -0.182560  0.174977 -0.142932  0.508398 -0.102793  0.314821 -0.028197   \n",
       "4  0.002731  0.032420  0.043655  0.501373  0.442546  0.157427  0.082318   \n",
       "5 -0.042878  0.029168 -0.187499 -0.020230 -0.260429 -0.120475  0.067830   \n",
       "6 -0.071380  0.096587  0.055705 -0.525645  0.580350  0.096592  0.441484   \n",
       "7 -0.141320  0.030474  0.261100 -0.219024 -0.277812  0.177240  0.191265   \n",
       "8 -0.291509  0.554150  0.115631 -0.188634 -0.074476 -0.277101 -0.000275   \n",
       "9 -0.071756  0.133156 -0.071761  0.306060  0.358961 -0.061443  0.167584   \n",
       "\n",
       "          7         8         9  ...       758       759       760       761  \\\n",
       "0 -0.268620  0.284335  0.154874  ...  0.049630 -0.063532  0.193070  0.345019   \n",
       "1  0.256541 -0.093520  0.304061  ... -0.350746 -0.103448  0.188898  0.002680   \n",
       "2  0.006522  0.346580  0.009805  ...  0.345482  0.149472 -0.128204  0.069986   \n",
       "3  0.235509  0.293719  0.091492  ...  0.153091 -0.220330  0.126606  0.091785   \n",
       "4  0.287892  0.322357  0.356958  ...  0.267656 -0.337920  0.343273  0.429253   \n",
       "5  0.296153 -0.020178  0.003125  ...  0.178184 -0.003942  0.331448 -0.395468   \n",
       "6  0.257061 -0.054260  0.220842  ...  0.457613 -0.331446 -0.066380 -0.019426   \n",
       "7  0.252725 -0.035201  0.198338  ...  0.104466 -0.177960  0.088618  0.289035   \n",
       "8  0.076826  0.199134  0.033996  ...  0.055575  0.047854  0.214838 -0.086142   \n",
       "9  0.364614  0.323541  0.141398  ...  0.404115  0.000236  0.177493  0.016162   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.111516 -0.018490  0.062621 -0.105441  0.084189  0.097068  \n",
       "1  0.364525  0.270561  0.617305  0.565283  0.068011  0.210108  \n",
       "2 -0.049316 -0.122243 -0.520354  0.052404  0.277886 -0.082411  \n",
       "3  0.087272  0.279831 -0.328509  0.157604  0.439283  0.204193  \n",
       "4 -0.042079  0.466611 -0.574508  0.004958  0.390041  0.150982  \n",
       "5  0.025013  0.082307 -0.561699  0.560587  0.141633 -0.373937  \n",
       "6 -0.147649  0.034530 -0.095109  0.304422  0.327636 -0.197770  \n",
       "7 -0.089657  0.246048 -0.060229  0.500508 -0.045897 -0.046336  \n",
       "8  0.453633  0.021888 -0.143639  0.167839 -0.151438 -0.076444  \n",
       "9  0.232335  0.260556  0.168149  0.483963  0.121122  0.196881  \n",
       "\n",
       "[10 rows x 768 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sents = embedder.encode(wiki_df[\"text\"])\n",
    "emb_sent_df = pd.DataFrame(emb_sents, index=wiki_df.index)\n",
    "emb_sent_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe69f2a3-8c0a-4e4d-b049-9709a4aa731e",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "**ANSWER:**\n",
    "\n",
    "There are `768` dimensions in this representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf1542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster assignments for k=3\n",
      "('0', ['Mount Everests', 'Mount Denali', 'Mount Kenya'])\n",
      "('1', ['Raspberry', 'Baseball', 'Hockey', 'Mango_fruit', 'Football'])\n",
      "('2', ['Arithmetic', 'Topology'])\n",
      "\n",
      "Cluster assignments for k=4\n",
      "('0', ['Mount Everests', 'Mount Denali', 'Mount Kenya'])\n",
      "('1', ['Baseball', 'Hockey', 'Football'])\n",
      "('2', ['Arithmetic', 'Topology'])\n",
      "('3', ['Raspberry', 'Mango_fruit'])\n",
      "\n",
      "Cluster assignments for k=5\n",
      "('0', ['Arithmetic', 'Topology'])\n",
      "('1', ['Mount Everests', 'Mount Denali', 'Mount Kenya'])\n",
      "('2', ['Baseball', 'Football'])\n",
      "('3', ['Raspberry', 'Mango_fruit'])\n",
      "('4', ['Hockey'])\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "kmeans_sen_embs = {}\n",
    "for i in range(3, 6):\n",
    "    kmeans_sen_emb = KMeans(n_clusters=i)\n",
    "    kmeans_sen_emb.fit(emb_sents)\n",
    "    kmeans_sen_embs[i] = kmeans_sen_emb\n",
    "    print(f\"\\nCluster assignments for k={i}\")\n",
    "    print_cluster_assignments(kmeans_sen_emb, i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f923b7b",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "**ANSWER:**\n",
    "\n",
    "The clusters using `SentneceTransformer` and `KMeans` are clustered better than using `CountVectorizer`. Their performance is identical when we choose `k=4`, however for `k=3` and `k=5`, the sentence embedding representation of our data produces more sensible clusters.\n",
    "\n",
    "For `k=3`, the fields of study and mountains are grouped together. The fruits and sports are all placed into one group.\n",
    "\n",
    "For `k=5`, clusters `1-4` all contains queries that fit into their clusters. The extra cluster `0` contains `Hockey` which `KMeans` has deemed most dissimilar to the other sports so it belongs in its own cluster, maybe because it doesn't use a ball. These clusters are all sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a67c7a-83a4-473a-b710-f31c01f4b6fc",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f7a64-57c5-4511-a2c7-bd319dfdc8b7",
   "metadata": {},
   "source": [
    "### 1.4 DBSCAN with cosine distance  \n",
    "rubric={points:10}\n",
    "\n",
    "Let's try `DBSCAN` on our toy dataset. K-Means is kind of bound to the Euclidean distance because it is based on the notion of means. With `DBSCAN` we can try different distance metrics. In the context of text (sparse data), [cosine similarities](https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity) or cosine distances tend to work better. Given vectors $u$ and $v$, the **cosine distance** between the vectors is defined as: \n",
    "\n",
    "$$distance_{cosine}(u,v) = 1 - (\\frac{u \\cdot v}{\\left\\lVert u\\right\\rVert_2 \\left\\lVert v\\right\\rVert_2})$$\n",
    "\n",
    "In this exercise, you'll use DBSCAN with cosine distances. \n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "1. Use DBSCAN to cluster our toy data using sentence embedding representation (`emb_sents`) and `metric='cosine'`. \n",
    "2. Briefly comment on the number of clusters identified and the cluster assignment given by the algorithm.\n",
    "\n",
    "> *Note: You will also have to set appropriate values for the hyperparamters `eps` and `min_samples` to get meaningful clusters, as default values for these hyperparameters won't work on this toy dataset. In order to set appropriate value for `eps`, you may want to examine the distances given by [sklearn's `cosine_distance`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_cosine_distances.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd7b8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import paired_cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd308e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931335</td>\n",
       "      <td>0.424351</td>\n",
       "      <td>0.827909</td>\n",
       "      <td>0.870119</td>\n",
       "      <td>0.925507</td>\n",
       "      <td>0.951119</td>\n",
       "      <td>0.841844</td>\n",
       "      <td>0.409439</td>\n",
       "      <td>0.991959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.931335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906466</td>\n",
       "      <td>0.847008</td>\n",
       "      <td>0.864609</td>\n",
       "      <td>0.869627</td>\n",
       "      <td>0.903234</td>\n",
       "      <td>0.522127</td>\n",
       "      <td>0.898712</td>\n",
       "      <td>0.839252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.424351</td>\n",
       "      <td>0.906466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.907096</td>\n",
       "      <td>0.854795</td>\n",
       "      <td>0.856470</td>\n",
       "      <td>0.815634</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>0.456956</td>\n",
       "      <td>0.904455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.827909</td>\n",
       "      <td>0.847008</td>\n",
       "      <td>0.907096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381103</td>\n",
       "      <td>0.772545</td>\n",
       "      <td>0.812594</td>\n",
       "      <td>0.902332</td>\n",
       "      <td>0.889986</td>\n",
       "      <td>0.816896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.870119</td>\n",
       "      <td>0.864609</td>\n",
       "      <td>0.854795</td>\n",
       "      <td>0.381103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755116</td>\n",
       "      <td>0.753566</td>\n",
       "      <td>0.842974</td>\n",
       "      <td>0.955045</td>\n",
       "      <td>0.792475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.925507</td>\n",
       "      <td>0.869627</td>\n",
       "      <td>0.856470</td>\n",
       "      <td>0.772545</td>\n",
       "      <td>0.755116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596294</td>\n",
       "      <td>0.951435</td>\n",
       "      <td>0.831017</td>\n",
       "      <td>0.528304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.951119</td>\n",
       "      <td>0.903234</td>\n",
       "      <td>0.815634</td>\n",
       "      <td>0.812594</td>\n",
       "      <td>0.753566</td>\n",
       "      <td>0.596294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916050</td>\n",
       "      <td>0.954532</td>\n",
       "      <td>0.526190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.841844</td>\n",
       "      <td>0.522127</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>0.902332</td>\n",
       "      <td>0.842974</td>\n",
       "      <td>0.951435</td>\n",
       "      <td>0.916050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806186</td>\n",
       "      <td>0.845019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.409439</td>\n",
       "      <td>0.898712</td>\n",
       "      <td>0.456956</td>\n",
       "      <td>0.889986</td>\n",
       "      <td>0.955045</td>\n",
       "      <td>0.831017</td>\n",
       "      <td>0.954532</td>\n",
       "      <td>0.806186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.991959</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.904455</td>\n",
       "      <td>0.816896</td>\n",
       "      <td>0.792475</td>\n",
       "      <td>0.528304</td>\n",
       "      <td>0.526190</td>\n",
       "      <td>0.845019</td>\n",
       "      <td>0.938582</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.931335  0.424351  0.827909  0.870119  0.925507  0.951119   \n",
       "1  0.931335  0.000000  0.906466  0.847008  0.864609  0.869627  0.903234   \n",
       "2  0.424351  0.906466  0.000000  0.907096  0.854795  0.856470  0.815634   \n",
       "3  0.827909  0.847008  0.907096  0.000000  0.381103  0.772545  0.812594   \n",
       "4  0.870119  0.864609  0.854795  0.381103  0.000000  0.755116  0.753566   \n",
       "5  0.925507  0.869627  0.856470  0.772545  0.755116  0.000000  0.596294   \n",
       "6  0.951119  0.903234  0.815634  0.812594  0.753566  0.596294  0.000000   \n",
       "7  0.841844  0.522127  0.853448  0.902332  0.842974  0.951435  0.916050   \n",
       "8  0.409439  0.898712  0.456956  0.889986  0.955045  0.831017  0.954532   \n",
       "9  0.991959  0.839252  0.904455  0.816896  0.792475  0.528304  0.526190   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.841844  0.409439  0.991959  \n",
       "1  0.522127  0.898712  0.839252  \n",
       "2  0.853448  0.456956  0.904455  \n",
       "3  0.902332  0.889986  0.816896  \n",
       "4  0.842974  0.955045  0.792475  \n",
       "5  0.951435  0.831017  0.528304  \n",
       "6  0.916050  0.954532  0.526190  \n",
       "7  0.000000  0.806186  0.845019  \n",
       "8  0.806186  0.000000  0.938582  \n",
       "9  0.845019  0.938582  0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "for i in range(10):\n",
    "    distances.append(paired_cosine_distances(np.array(([emb_sents[i]] * 10)), emb_sents))\n",
    "\n",
    "cos_dist_df = pd.DataFrame(distances)\n",
    "cos_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38110328\n",
      "0.991959\n"
     ]
    }
   ],
   "source": [
    "print(cos_dist_df[cos_dist_df > 0].min().min())\n",
    "print(cos_dist_df.max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d88e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Question 1\n",
    "\n",
    "min_samples_vs_eps = {\n",
    "    x: [] for x in (np.arange(1, 11) / 10)\n",
    "}\n",
    "min_samples_vs_eps[\"min_samples\"] = np.arange(1, 11)\n",
    "\n",
    "for i in min_samples_vs_eps[\"min_samples\"]:\n",
    "    for j in (np.arange(1, 11) / 10):\n",
    "        dbscan = DBSCAN(eps=j, min_samples=i, metric='cosine')\n",
    "        dbscan.fit(emb_sents)\n",
    "        min_samples_vs_eps[j].append(len(np.unique(dbscan.labels_)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c5aa952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>1.0</th>\n",
       "      <th>min_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.0  min_samples\n",
       "0  10   10   10   9    7    4    4    3    1    1    1          \n",
       "1  1    1    1    2    3    4    4    3    1    1    2          \n",
       "2  1    1    1    1    2    3    3    3    1    1    3          \n",
       "3  1    1    1    1    1    1    1    2    1    1    4          \n",
       "4  1    1    1    1    1    1    1    2    1    1    5          \n",
       "5  1    1    1    1    1    1    1    1    1    1    6          \n",
       "6  1    1    1    1    1    1    1    1    1    1    7          \n",
       "7  1    1    1    1    1    1    1    1    1    1    8          \n",
       "8  1    1    1    1    1    1    1    1    2    1    9          \n",
       "9  1    1    1    1    1    1    1    1    1    1    10         "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(min_samples_vs_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c8b3b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples = 1\n",
      "eps=1: [0 1 2 3 4 5 6 7 8 9]\n",
      "eps=2: [0 1 2 3 4 5 6 7 8 9]\n",
      "eps=3: [0 1 2 3 4 5 6 7 8 9]\n",
      "eps=4: [0 1 2 3 4 5 6 7 8]\n",
      "eps=5: [0 1 2 3 4 5 6]\n",
      "eps=6: [0 1 2 3]\n",
      "eps=7: [0 1 2 3]\n",
      "eps=8: [0 1 2]\n",
      "eps=9: [0]\n",
      "eps=10: [0]\n",
      "\n",
      "min_samples = 2\n",
      "eps=1: [-1]\n",
      "eps=2: [-1]\n",
      "eps=3: [-1]\n",
      "eps=4: [-1  0]\n",
      "eps=5: [-1  0  1]\n",
      "eps=6: [0 1 2 3]\n",
      "eps=7: [0 1 2 3]\n",
      "eps=8: [0 1 2]\n",
      "eps=9: [0]\n",
      "eps=10: [0]\n"
     ]
    }
   ],
   "source": [
    "print(\"min_samples = 1\")\n",
    "for i in range(1, 11):\n",
    "    dbscan = DBSCAN(eps=i/10, min_samples=1, metric='cosine')\n",
    "    dbscan.fit(emb_sents)\n",
    "    print(f'eps={i}: {np.unique(dbscan.labels_)}')\n",
    "print(\"\\nmin_samples = 2\")\n",
    "for i in range(1, 11):\n",
    "    dbscan = DBSCAN(eps=i/10, min_samples=2, metric='cosine')\n",
    "    dbscan.fit(emb_sents)\n",
    "    print(f'eps={i}: {np.unique(dbscan.labels_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e25e772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps=6: [0 1 0 2 2 3 3 1 0 3]\n",
      "eps=7: [0 1 0 2 2 3 3 1 0 3]\n"
     ]
    }
   ],
   "source": [
    "dbscan6 = DBSCAN(eps=0.6, min_samples=2, metric='cosine')\n",
    "dbscan6.fit(emb_sents)\n",
    "print(f'eps=6: {dbscan6.labels_}')\n",
    "dbscan7 = DBSCAN(eps=0.7, min_samples=2, metric='cosine')\n",
    "dbscan7.fit(emb_sents)\n",
    "print(f'eps=7: {dbscan7.labels_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0', ['Mount Everests', 'Mount Denali', 'Mount Kenya'])\n",
      "('1', ['Raspberry', 'Mango_fruit'])\n",
      "('2', ['Arithmetic', 'Topology'])\n",
      "('3', ['Baseball', 'Hockey', 'Football'])\n",
      "\n",
      "\n",
      "('0', ['Mount Everests', 'Mount Denali', 'Mount Kenya'])\n",
      "('1', ['Raspberry', 'Mango_fruit'])\n",
      "('2', ['Arithmetic', 'Topology'])\n",
      "('3', ['Baseball', 'Hockey', 'Football'])\n"
     ]
    }
   ],
   "source": [
    "print_cluster_assignments(dbscan6, 4)\n",
    "print('\\n')\n",
    "print_cluster_assignments(dbscan7, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97bf9ec1-010c-4a59-bd5a-2d9e9e6aced5",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "**ANSWER:**\n",
    "\n",
    "By analyzing the `cosine_distance`s and tuning `min_samples` and `eps`, `DBSCAN` is able to identify `4` clusters with assignments corresponding to my manual assignment. However, I was only able to tune and identify the best hyperparameters because of pre-existing knowledge of the number of clusters and assignments assuming my manual clustering is a correct interpretation.\n",
    "\n",
    "In my dataframe comparing `min_samples_vs_eps`, a `min_samples` from `1-3` could have been chosen, or `eps` from `0.5-0.8` may have been reasonable choices given no pre-existing knowledge on number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f359f90-e90c-4311-adb2-39b6f9a3433c",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30b339-3799-4d4c-b9d5-c0c048243c1f",
   "metadata": {},
   "source": [
    "### 1.5 Visualizing clusters \n",
    "rubric={points:5}\n",
    "\n",
    "One thing we could do with unlabeled data is visualizing it. That said, our data is high dimensional (each example is represented with 768 dimensions) and high-dimensional data is hard to visualize. One way to visualize high-dimensional data is applying dimensionality reduction to get the most important (2 or 3) components of the dataset and visualizing this low-dimensional data. \n",
    "\n",
    "Given data as a `numpy` array and cluster assignments, the `plot_pca_clusters` function below transforms the given data by applying dimensionality reduction and plots the transformed data into corresponding clusters. \n",
    "\n",
    "> *Note: At this point we are using this function only for visualization and you are not expected to understand the PCA part. Feel free to modify the function as you see fit.*\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Call the function `plot_pca_clusters` to visualize the clusters created by the three models above:\n",
    "    - KMeans with bag-of-words representation \n",
    "    - KMeans with sentence embedding representation \n",
    "    - DBSCAN with sentence embedding representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5531c582-11c4-4691-8110-4ccc7342fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Obtain the principal components\n",
    "\n",
    "def plot_pca_clusters(\n",
    "    data,\n",
    "    cluster_labels,\n",
    "    raw_sents=wiki_df[\"text\"],\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Carry out dimensionality reduction using PCA and plot 2-dimensional clusters.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : numpy array\n",
    "        data as a numpy array\n",
    "    cluster_labels : list\n",
    "        cluster labels for each row in the dataset\n",
    "    raw_sents : list\n",
    "        the original raw sentences for labeling datapoints\n",
    "    show_labels : boolean\n",
    "        whether you want to show labels for points or not (default: False)\n",
    "    size : int\n",
    "        size of points in the scatterplot\n",
    "    title : str\n",
    "        title for the visualization plot\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    None. Shows the clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_comp = pca.fit_transform(data)\n",
    "    pca_df = pd.DataFrame(data=principal_comp, columns=[\"pca1\", \"pca2\"])\n",
    "    pca_df[\"cluster\"] = cluster_labels\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(title)\n",
    "    ax = sns.scatterplot(\n",
    "        x=\"pca1\", y=\"pca2\", hue=\"cluster\", data=pca_df, palette=\"tab10\", s=size\n",
    "    )\n",
    "\n",
    "    x = pca_df[\"pca1\"].tolist()\n",
    "    y = pca_df[\"pca2\"].tolist()\n",
    "    if show_labels:\n",
    "        for i, txt in enumerate(raw_sents):\n",
    "            plt.annotate(\" \".join(txt.split()[:10]), (x[i], y[i]))\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b924f987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca_clusters(\n",
    "    bow_sents_ignore_one,\n",
    "    kmeans_ignore_one.labels_,\n",
    "    title=\"PCA visualization, KMeans BOW\"\n",
    ")\n",
    "\n",
    "plot_pca_clusters(\n",
    "    emb_sents,\n",
    "    kmeans_sen_embs[4].labels_,\n",
    "    title=\"PCA visualization, KMeans Sen Emb\"\n",
    ")\n",
    "\n",
    "plot_pca_clusters(\n",
    "    emb_sents,\n",
    "    dbscan6.labels_,\n",
    "    title=\"PCA visualization, DBSCAN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60195d0-3070-43e5-8d76-b59bf9796a6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0bf74a4-86f7-479f-ac54-4fbd0709b126",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d135d-cf62-4a8c-990d-631ee1662913",
   "metadata": {},
   "source": [
    "## Exercise 2: Movie recommendations\n",
    "<hr>\n",
    "\n",
    "Let's build simple movie recommendation systems using the [MovieLens dataset](https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data). The original source of the data is [here](https://grouplens.org/datasets/movielens/), and the structure of the data is described in the [README](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html) that comes with it. The code below reads the data as a CSV assuming that it's under `data/ml-100k/` directory under your lab folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41780f0a-8c8d-4baf-8059-cf428dad85cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0  196      242       3       881250949\n",
       "1  186      302       3       891717742\n",
       "2  22       377       1       878887116\n",
       "3  244      51        2       880606923\n",
       "4  166      346       1       886397596"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(\"data\", \"ml-100k\", \"u.data\"),\n",
    "    sep=\"\\t\",\n",
    "    names=r_cols,\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "206ca960-e598-48ba-b506-3710e3714047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using these keys later in the starter code\n",
    "user_key = \"user_id\"\n",
    "item_key = \"movie_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05efce7-bc1e-4ff1-888c-5053b4f57479",
   "metadata": {},
   "source": [
    "### 2.1 Terminology\n",
    "rubric={points:6}\n",
    "\n",
    "Here is some notation we will be using in this lab. \n",
    "\n",
    "**Constants**:\n",
    "\n",
    " - $N$: the number of users, indexed by $n$\n",
    " - $M$: the number of movies, indexed by $m$\n",
    " - $\\mathcal{R}$: the set of indices $(n,m)$ where we have ratings in the utility matrix $Y$\n",
    "    - Thus $|\\mathcal{R}|$ is the total number of ratings\n",
    " - $k$: the number of latent dimensions we use in collaborative filtering\n",
    " \n",
    "**The data**:\n",
    "\n",
    " - $Y$: the utility matrix containing ratings, with a lot of missing entries\n",
    " - $Z$: a matrix whose rows $z_m$ represent the features for movie $m$ (size $M\\times d$).\n",
    " - `train_mat` and `valid_mat`: Utility matrices for train and validation sets, respectively\n",
    " \n",
    "    \n",
    "**Your tasks:**    \n",
    "\n",
    "1. What are the values of $N$ and $M$ in movie ratings data?  \n",
    "2. What would be the shape of the dense utility matrix $Y$? \n",
    "3. What would be the fraction of observed ratings in the utility matrix $Y$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b785c0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ac6c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique users: 943\n",
      "unique movies: 1682\n"
     ]
    }
   ],
   "source": [
    "print(f\"unique users: {len(np.unique(ratings.user_id))}\")\n",
    "print(f\"unique movies: {len(np.unique(ratings.movie_id))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40744eb3-0f31-4237-934e-4694fa82192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06304669364224531"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 943\n",
    "M = 1682\n",
    "Y_shape = (943, 1682)\n",
    "Y_frac_observed = ratings.shape[0]/(943 * 1682)\n",
    "Y_frac_observed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2810fb2f-d56c-4869-8741-15da6fb265dc",
   "metadata": {},
   "source": [
    "**ANSWERS:**\n",
    "1. `N=943` and `M=1682` for each unique user and movie respectivley\n",
    "2. Shape of `Y=(943, 1682)`, a row for each user, and column for each movie\n",
    "3. Fraction of observed ratings in `Y` is `0.063` or `6.3%`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c433a44-37b9-4113-8102-10d918cc84ac",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68b939-60c8-4da8-a32e-384b887656b8",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the data\n",
    "rubric={points:5}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the ratings data with `test_size=0.2` and `random_state=42`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a9733c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "024717b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings.copy()\n",
    "y = ratings[user_key]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5627583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100000, 4)\n",
      "y shape: (100000,)\n",
      "X_train shape: (80000, 4)\n",
      "X_valid shape: (20000, 4)\n",
      "y_train shape: (80000,)\n",
      "y_valid shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152e2be-565c-4244-9e7c-84837bf1b35b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce1526cf-a7e5-425e-b8e5-dd8cadb53a50",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb483ab-ae9a-4d3d-a2d5-be404c422c14",
   "metadata": {},
   "source": [
    "### 2.3 Utility matrix \n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Create utility matrices for train and validation sets (similar to how we did in the class). \n",
    "2. Briefly explain the difference between the train and validation utility matrices. \n",
    "\n",
    "> You may use the code from lecture notes with appropriate attributions.  \n",
    "\n",
    "> You won't do it in real life but since our dataset is not that big, create a dense utility matrix in this assignment. You are welcome to try sparse matrix but then you may have to change some started code provided in the later exercises.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9b8d514-615a-4166-b597-eee2e53dbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db018fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From CPSC 330 Lec 15\n",
    "def create_Y_from_ratings(\n",
    "    data, N, M, user_mapper, item_mapper, user_key=\"user_id\", item_key=\"movie_id\"\n",
    "):  # Function to create a dense utility matrix\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "192d8a08-c194-45c2-83ca-63156311401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "train_mat = create_Y_from_ratings(X_train, N, M, user_mapper, item_mapper)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M, user_mapper, item_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5302fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(~np.isnan(train_mat)), np.count_nonzero(~np.isnan(valid_mat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec818617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943, 1682), (943, 1682))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat.shape, valid_mat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e16d54bf-dfbd-495d-97ac-d550658d4b80",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "**ANSWER:**\n",
    "\n",
    "The training and validation utility matrices have the same shape because they both have a row for every user and column for every movie. However, the observed ratings in the training utility matrix are from the training set, and similarly for validation set. This means the fraction of observed ratings is greater in the training set with `0.8` split than validation set `0.2` split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce90c62-f51b-4c35-a136-52176cbf8ea3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b8ac2-56be-4193-abda-fea9d4cefb4a",
   "metadata": {},
   "source": [
    "### 2.4 Evaluation and baseline\n",
    "rubric={points:4}\n",
    "\n",
    "To compare different models you build in this homework, let's write a couple of functions for evaluation. \n",
    "- The `error` function returns RMSE.\n",
    "- The `evaluate` function prints the train and validation RMSEs. \n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Briefly explain what exactly we are comparing to evaluate recommender systems. \n",
    "2. Implement the global average baseline, where you predict everything as the global average rating. What's the RMSE of the global average baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15c3c76a-5d5b-4773-a48c-0f26d5ec5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f757ffcd-be92-4cfb-a5a2-14299a6b7a8c",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "**ANSWER:**\n",
    "\n",
    "1. To evaluate recommender systems, we are comparing the `RMSE` between the actual ratings, and predicted ratings after the utility matrix has been filled in (ignoring `nan` that appear when one of the matrices has no rating in the corresponding cell). \n",
    "2. The global average baseline `train RMSE = 1.13` and `validation RMSE = 1.12`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56b17f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "1  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "2  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "3  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "4  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "\n",
       "          7         8         9  ...      1672      1673      1674      1675  \\\n",
       "0  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "1  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "2  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "3  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "4  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "\n",
       "       1676      1677      1678      1679      1680      1681  \n",
       "0  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "1  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "2  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "3  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "4  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "pd.DataFrame(pred_g).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bbf068e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 1.13\n",
      "Global average valid RMSE: 1.12\n"
     ]
    }
   ],
   "source": [
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a6ab6-62ef-4fdd-ba0d-5e7e920154a3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a02d5-bf63-428a-8bac-9fa6f2f38681",
   "metadata": {},
   "source": [
    "### (Optional) 2.5 $k$-nearest neighbours imputation\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Try [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html) to fill in the missing entries. Discuss your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce024675",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=10)\n",
    "train_mat_imp = imputer.fit_transform(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb7d62f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943, 1682), (943, 1653))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat.shape, train_mat_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8f811b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1643</th>\n",
       "      <th>1644</th>\n",
       "      <th>1645</th>\n",
       "      <th>1646</th>\n",
       "      <th>1647</th>\n",
       "      <th>1648</th>\n",
       "      <th>1649</th>\n",
       "      <th>1650</th>\n",
       "      <th>1651</th>\n",
       "      <th>1652</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  1643  1644  1645  \\\n",
       "0  4.0  3.0  4.0  3.7  3.0  3.8  4.0  3.3  5.0  3.0  ...  3.0   3.0   1.0    \n",
       "1  4.0  3.0  3.3  4.1  3.2  4.3  4.4  4.4  4.5  4.1  ...  3.0   3.0   1.0    \n",
       "2  3.8  3.2  2.8  3.1  3.5  3.5  4.0  3.7  3.7  4.3  ...  3.0   3.0   1.0    \n",
       "3  4.1  2.9  3.9  3.1  3.6  3.8  3.3  4.3  4.2  4.2  ...  3.0   3.0   1.0    \n",
       "4  4.0  3.0  3.3  3.8  3.3  4.1  4.0  3.8  3.8  4.1  ...  3.0   3.0   1.0    \n",
       "\n",
       "   1646  1647  1648  1649  1650  1651  1652  \n",
       "0  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "1  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "2  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "3  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "4  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "\n",
       "[5 rows x 1653 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_mat_imp).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71b908cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (943,1653) (943,1682) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(train_mat_imp, train_mat, valid_mat, model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mKNN imputer\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(pred_Y, train_mat, valid_mat, model_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(pred_Y, train_mat, valid_mat, model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGlobal average\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m train RMSE: \u001b[39m\u001b[39m%0.2f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (model_name, error(pred_Y, train_mat)))\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m valid RMSE: \u001b[39m\u001b[39m%0.2f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (model_name, error(pred_Y, valid_mat)))\n",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m, in \u001b[0;36merror\u001b[0;34m(Y1, Y2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror\u001b[39m(Y1, Y2):\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    Returns the root mean squared error (RMSE).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mnanmean((Y1 \u001b[39m-\u001b[39;49m Y2) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (943,1653) (943,1682) "
     ]
    }
   ],
   "source": [
    "evaluate(train_mat_imp, train_mat, valid_mat, model_name=\"KNN imputer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8567e44d-bf19-4664-b4bf-9dfd4234add2",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "`sklearn`'s imputers remove features that are `np.nan` on every training sample. [source](https://github.com/scikit-learn/scikit-learn/issues/16426). However, we cannot fill `np.nan` values with zeros because `0` is an actual rating value which would skew our results.\n",
    "\n",
    "I am unsure how to deal with this so I will ignore the `KNNImputer` baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65bf17-79e9-4b85-9739-bfc9faf540fa",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d2e8f-e22a-4377-9110-fff8d041289e",
   "metadata": {},
   "source": [
    "### 2.6 Use collaborative filtering with the `surprise` package\n",
    "rubric={points:6}\n",
    "\n",
    "Use the [`surprise`](https://surprise.readthedocs.io/en/stable/) package which has implementation of SVD algorithm for collaborative filtering. You can install it as follows in your conda environment. \n",
    "\n",
    "```\n",
    ">> conda activate cpsc330\n",
    ">> conda install -c conda-forge scikit-surprise\n",
    "or \n",
    ">> pip install scikit-surprise\n",
    "```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out cross-validation using SVD algorithm in the package, similar to how we did it in the lecture on Jester dataset. Report mean RMSE and compare it with global baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fa6276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6275e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_svd = ratings.drop(columns=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b61b168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.932839700199596"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From CSPC 330 lecture 15\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings_svd, reader)  # Load the data\n",
    "\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.2, random_state=42\n",
    ")  \n",
    "\n",
    "k = 10\n",
    "algo = SVD(n_factors=k, random_state=42)\n",
    "algo.fit(trainset)\n",
    "svd_preds = algo.test(validset)\n",
    "accuracy.rmse(svd_preds, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be63c1f7-82d3-4532-82d7-2d55c8f596d5",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "The global baseline test `RMSE=1.12`, and the collaborative filtering `RMSE=0.9328`. Although we do see an improvement, it is not a major improvement from the global baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044157f-1236-4cb9-8c76-82647f23cc99",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d184a9-7fad-4e34-8fa7-b10443d83911",
   "metadata": {},
   "source": [
    "### 2.7 Clustering based recommendation system?\n",
    "rubric={points:2}\n",
    "\n",
    "How would you apply `K-Means` clustering to build a recommendation systems? What could be challenging with this approach?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43410bc8-d121-4da6-997b-b84cbf419e16",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "For each user, I would \n",
    "\n",
    "1. cluster the items that the user rated highly (e.g. above `3.5`) to find clusters of item types that the user likes. \n",
    "    - I would not cluster every item rated by the user, because then clusters could contain both highly rated, and low rated items. \n",
    "2. Then I would predict how much a user likes other items by calculating the similarity measure of new items to the cluster centers of the highly rated movies. \n",
    "3. I wouuld order these similarity measures and recommend to the user items that are the most similar to their pre-existing highly rated items.\n",
    "\n",
    "Challenges of this approach include\n",
    "\n",
    "1. determining what is a good threshold for a movie to be considered \"highly rated\"\n",
    "2. `Diversity`, since all recommendations will be very similar to what a user has already rated, additionally this system would not work for new users.\n",
    "3. `Freshness` is difficult to control with this system, as movies are recommended based only on similarity of provided movie features with highly-rated movies. May influence trustability of recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea9c37-34c9-4b3e-a2df-e00cedd3e8ae",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab723dc5-4ea6-4c44-ace9-bf345bf8c120",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e07e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
